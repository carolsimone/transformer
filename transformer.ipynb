{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Attention Is All You Need\n",
    "\n",
    "<a href=\"https://nlp.seas.harvard.edu/2018/04/03/attention.html#encoder-and-decoder-stacks\" target=\"_blank\">Harvard Notebook</a>\n",
    "\n",
    "<a href=\"https://towardsdatascience.com/how-to-code-the-transformer-in-pytorch-24db27c8f9ec\">Towardsdatascience Notebook</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transorfmer\n",
    "\n",
    "Transformer, a bit better: <a href=\"https://glassboxmedicine.com/2019/08/15/the-transformer-attention-is-all-you-need/\"> article</a>.\n",
    "\n",
    "Embedding weight matrix $W$ has shape: number of embeddings x embedding dimension.\n",
    "\n",
    "number of embedding = `vocab_size`, each word has an embedding.\n",
    "\n",
    "embedding dimension = `d_model`, it's your choice, in the paper it is 512.\n",
    "\n",
    "In `pytorch` you use `nn.Embedding` function. You can use pre-trained embeddings (e.g. GloVe), or you can randomly initialize them and train them. `Transformer` learns its own word embeddings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Type, List\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Encoding\n",
    "In transformer all the words of a sentence are processed simultaneously, so there is no inherent word ordering that you have on a RNN. The authors of the Transformer propose adding a \"positional encoding\" to address this problem. There were 2 options for Positional encoding vectors:\n",
    "1. learning the positional encoding vectors (add trainable parameters).\n",
    "2. calculating the positional encoding vectors using an equation (requires no trainable parameters).\n",
    "\n",
    "Opted for option 2. Formulas:\n",
    "\n",
    "$PE_{(pos, 2i)} = sin(pos / 10000^{2i/d_{model}})$\n",
    "\n",
    "$PE_{(pos, 2i+i)} = cos(pos / 10000^{2i/d_{model}})$\n",
    "\n",
    "where `pos` is the position of the word in the sentence, and `i` is the index into the embedding dimension. If model = `d_model=512`, then than `i` range from 0 to 512 / 2.\n",
    "\n",
    "This means that an english sentence: \"I like trees\" will be converted to 3 vectors (one vector for each word): <img src='../img/transformer/wordembedding_positional.png' width=\"500\" height=\"500\">\n",
    "We do exactely the same thing also for the correct output target sequence \"Me gustas los arboles\".\n",
    "\n",
    "\n",
    "The shape of the input Tensors (and output Tensor) with embedding and positional encoder considered is: `n_batches`, `L` and `512`. `nbatches` is the batch size, `L` is the lenght of the sequence, in this case would be 3 for the input and output, and `512` is the emedding dimensions (number of columns representing the vectors column of the word).\n",
    "\n",
    "\n",
    "## Encoder\n",
    "The encoder has 6 identical layers. What goes in is an English sentence, e.g. \"I like trees\", represented in the \"word embeddings + positional encodigns\" format we just talked about. What comes out is a different representation of the sentence.\n",
    "\n",
    "Each layer contains 2 sub-layers:\n",
    "1. Multi-head attention\n",
    "2. feed-forward network\n",
    "\n",
    "<img src=\"../img/transformer/encoder.png\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"Encoder stacked with 6 layers.\"\"\"\n",
    "    \n",
    "    def __init__(self, layer: Type[nn.Module], N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = layerNorm(layer.size)\n",
    "    def forward(self, x, mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)\n",
    "    \n",
    "class EncoderLayer(nn.Module):\n",
    "    \"\"\"Self-attention and feed forward.\"\"\"\n",
    "    def __init__(self, size: int = 512, self_attn: Type[nn.Module] = None,\n",
    "                 feed_forward: Type[nn.Module] = None, dropout = 0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`EncoderLayer` has `size = d_model`, columns of the embeddings. `size = d_model = 512`.\n",
    "\n",
    "### Multi-head attention\n",
    "`x`, as embedding + position_encoder, is taken up by the first `EncoderLayer`. After, the others 5 layers will pick up a different representation of `x`, which came out from the previous `EncoderLayer`.\n",
    "\n",
    "$$Attention(Q,K,V) = softmax( \\frac{QK^T}{ \\sqrt{dk}})  V$$\n",
    "\n",
    "In the attention mechanism we split the `d_model` into `heads`. Originally `heads=8`. This means that the dimensionality of the `Tensor` is different compare the `size` they come in.\n",
    "\n",
    "$Q = Tensor(n_{batches}, 8, L_q, 64)$\n",
    "\n",
    "$K = Tensor(n_{batches}, 8, L_k, 64)$\n",
    "\n",
    "$V = Tensor(n_{batches}, 8, L_v, 64)$\n",
    "\n",
    "$Q$, $K$, $V$ do have different weights. They initially have been randomly defined (or better using Xavier Initialization). \n",
    "\n",
    "_Note_\n",
    "\n",
    "_You need to think to the Q, K, V dimensions as if you have a `batch` of sentences, these sentences will be needed to further split into 8 `heads`, these heads have the lenght of the sentence but with `d_model / 8 = 64` columns._\n",
    "\n",
    "`mask` is a `Tensor` but I don't know the size. `unsqueeze` add a third dimension, for example `unsqueeze(1)` add a 3rd dimension to the second position e.g. [1,4], [1,1,4].\n",
    "\n",
    "What enter the `MultiHeadedAttention` need also to come out in the same `shape`. `shape = n_batches, L, 512`.\n",
    "\n",
    "In the 8 `heads` we did a different matrix multiplication for each of the eight heads, this is what is meant by _multi-headed_ attention. The extra _heads_ dimension allows us to have multiple _representation subspaces_. It gives us 8 different ways of considering the same sentence.\n",
    "\n",
    "\n",
    "<a href=\"https://www.lesswrong.com/posts/qscAeYE67GoSffDDA/walkthrough-the-transformer-architecture-part-1-2\">Article about transformer</a>: Heart of the Transformer is the attention mechanism. The way majority of the people show attention is through a matrix with words. If the connected words, therefore the sentence, is the same in rows and columns, then we have the self-attention mechanism:\n",
    "\n",
    "<img src='../img/transformer/self_attention.png' width=\"500\" height=\"500\">\n",
    "\n",
    "With it we see which parts of the sentence are relevant to the other parts.\n",
    "Also in case of CNN, for instance, we frequently describe neural networks as having some sort of structured model for the images we are classifying. This is why authors sometimes talk about the model recognizing smaller pieces of the picture, like wheels, and then combining these smaller features into a coherent whole, such as a car. \n",
    "\n",
    "The way I think of attention is similar. The hope is that the neural network will be able to capture those parts of the text that are related to each other.\n",
    "\n",
    "## Decoder\n",
    "The `Decoder` has 3 sublayers:\n",
    "1. Masked multi head attention: mask future positions.\n",
    "2. multi-head attention: encoder-decoder multi-head attention.\n",
    "3. Feed-forward network: linear layer and softmax\n",
    "\n",
    "__Masked multi-head attention__\n",
    "\n",
    "We prevent positions from attending to subsequente positions.\n",
    "\n",
    "__Encoder-Decoder multi-head attention__\n",
    "\n",
    "`x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask`\n",
    "\n",
    "`x` comes from the previous `DecoderLayer`, `m` comes from the `Encoder` output (`encoderLayer6`).\n",
    "In the `Encoder-Decoder attention`  layers, ther queries come from the previous decoder layer, and the memory keys and values come from the output of the encoder. This allows every position in the decoder to attend over all positions in the input sequence (because indeed the encoder has attend all the positions of the input sequence with mask only over the padded words).\n",
    "\n",
    "### _Important notes_\n",
    "We run the `Encoder` once to get the output of the encoder stack, which is the representation of the sentence \"I like trees\". Now we need to run the decoder multiple times so it can predict the words in Spanish \"Me gustas los arboles\".\n",
    "\n",
    "The last layer expands the output of the decoder stack into a huge vector whose length is the `vocab-size`. The _softmax_ means that we'll select the one element of this huge vector with the highest probaility (_greedy decoding_).\n",
    "\n",
    "During training the decoder might be not very good so it can produce incorrect predictions of the next word. If the decoder produces junk, we don't want to feed that junk back into the decoder for the next step. So, during training, we use a process called _teacher forcing_. With _teacher forcing_ we feed in the right translation till the previous point. The loss is then calculated using the probability distribution over possible next words that the decoder actually produced versus the probability distribution it should have produced, this means the loss is calculated based on the actual prediction of the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(0,10).reshape(2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 5])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.unsqueeze(1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (5): Linear(in_features=512, out_features=512, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model = 512\n",
    "N = 6\n",
    "linear = get_clones(nn.Linear(d_model, d_model), N); linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.png                  wordembedding_positional.png\r\n"
     ]
    }
   ],
   "source": [
    "path = '../img/transformer/'\n",
    "\n",
    "!ls {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([555, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, 555).unsqueeze(-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([555, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, 555).unsqueeze(1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, copy, time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from typing import Type\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "seaborn.set_context(context='talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Norm(nn.Module):\n",
    "    \"\"\"Residual connection around each of the two sub-layers, followed by layer normalization\"\"\"\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(Norm, self).__init__()\n",
    "        self.a = nn.Parameter(torch.ones(features))\n",
    "        self.bias = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a * (x - mean) / (std + self.eps) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([2,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 6])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = x.mean(axis=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.,  2.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x - mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code\n",
    "## _Attention_\n",
    "Amazing explanation at: https://www.tensorflow.org/tutorials/text/transformer\n",
    "\n",
    "\n",
    "Attention mechanism is the result of a few operations:\n",
    "\n",
    "1. the dot product between Query $Q$ and Key $K$. \n",
    "\n",
    "$$Q \\bullet K^T$$\n",
    "\n",
    "2. It is then divided/scaled by the number of element $d$ in $K$ (or $Q$).\n",
    "\n",
    "$$\\frac{Q \\bullet K^T}{\\sqrt{d_k}}$$\n",
    "\n",
    "3. After this we apply a softmax and multiply by $V$.\n",
    "\n",
    "$$Attention(Q, K, V) = softmax(\\frac{Q \\bullet K^T}{\\sqrt{d_k}}) \\bullet V$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query: Type[torch.Tensor], key: Type[torch.tensor],\n",
    "              value: Type[torch.Tensor], mask=None, dropout=None):\n",
    "    \"\"\"Compute the scaled dot product attention\"\"\"\n",
    "    \n",
    "    d_k = query.size(-1)  # column size\n",
    "    print(f'd_k value {d_k}')\n",
    "    print(f'{query.size()} , {key.size()}, {value.size()}')\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    print(f'Score shape -- {scores.size()}')\n",
    "    if mask is not None:\n",
    "        print(f'Mask ---> {mask.size()}')\n",
    "        mask = mask.unsqueeze(1)\n",
    "        print(f'Mask new --> {mask.size()}')\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    \n",
    "    p_attn = F.softmax(scores, dim = -1)\n",
    "\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, heads, d_model = 512, dropout=0.1):\n",
    "        \"\"\"\n",
    "        :params\n",
    "        -------\n",
    "        heads : int\n",
    "            Number of heads. Heads = 8, in the original paper.\n",
    "        d_model : int\n",
    "            Number of sentences in the set. The `d_model` = 512 in the original paper \n",
    "            \"Attention is all you need\". \n",
    "        dropout : float\n",
    "            Dropout value.\n",
    "        \n",
    "        :return\n",
    "        -------\n",
    "        output : torch.Tensor\n",
    "            Tensor with attention matrix.\n",
    "        \"\"\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        \n",
    "        assert d_model % heads == 0, 'There must be no remainder!'\n",
    "        # Split the dimensionality into `h` heads. 512 / 8 = 64\n",
    "        self.d_k = d_model // heads\n",
    "        self.h = heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # 4 layers: `Q`, `K`, `V`, `O`\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.output = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def forward(self, q, k, v, mask):\n",
    "        \n",
    "        batch_size = q.size(0)  # number of rows in the `q` matrix\n",
    "        \n",
    "        # linear transformation and split into h heads\n",
    "        q = self.q_linear(q).view(batch_size, -1, self.h, self.d_k).transpose(1, 2)\n",
    "        k = self.k_linear(k).view(batch_size, -1, self.h, self.d_k).transpose(1, 2)\n",
    "        v = self.v_linear(v).view(batch_size, -1, self.h, self.d_k).transpose(1, 2)\n",
    "        \n",
    "        # calculate attention\n",
    "        # Attention tells you which words are important and to which we have to give more \n",
    "        # value: https://www.tensorflow.org/tutorials/text/transformer\n",
    "        attention_weights = attention(q, k, v, mask=mask, dropout=self.dropout)\n",
    "        \n",
    "        # concatenate heads\n",
    "        concat = attention_weights.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
    "        # The output represents the multiplication of the attention weights and the V (value)\n",
    "        # vector. This ensures that the words you want to focus on are kept as-is and the\n",
    "        # irrelevant words are flushed out.\n",
    "        return self.output(concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Positional Encoding_\n",
    "\n",
    "At the very beginning of the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len = 200, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # create constant 'pe' matrix with values dependant on \n",
    "        # pos and i\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = \\\n",
    "                math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                pe[pos, i + 1] = \\\n",
    "                math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # make embeddings relatively larger\n",
    "        x = x * math.sqrt(self.d_model)\n",
    "        #add constant to embedding\n",
    "        seq_len = x.size(1)\n",
    "        pe = Variable(self.pe[:,:seq_len], requires_grad=False)\n",
    "        if x.is_cuda:\n",
    "            pe.cuda()\n",
    "        x = x + pe\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Masks_\n",
    "\n",
    "We use masks in 2 cases:\n",
    "1. in the encoder-decoder: to zero attention ouputs wherever there is just padding in the input sentences.\n",
    "2. In the decoder: to prevent the decoder to peak ahead at the rest of the translated sentence when predicting next word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Torchtext_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "europarl-v7.fr-en.en europarl-v7.fr-en.fr\r\n"
     ]
    }
   ],
   "source": [
    "path = '../data/nlp/transformer/fr-en'\n",
    "!ls {path}\n",
    "\n",
    "europarl_en = open(f'{path}/europarl-v7.fr-en.en', encoding='utf-8').read().split('\\n')\n",
    "europarl_fr = open(f'{path}/europarl-v7.fr-en.fr', encoding='utf-8').read().split('\\n')\n",
    "\n",
    "#!python3 -m spacy download en\n",
    "#!python3 -m spacy download fr\n",
    "#!pip install torchtext==0.6.0\n",
    "import spacy\n",
    "import torchtext\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "en = spacy.load('en')\n",
    "fr = spacy.load('fr')\n",
    "\n",
    "def tokenize_en(sentence):\n",
    "    return [tok.text for tok in en.tokenizer(sentence)]\n",
    "\n",
    "def tokenize_fr(sentence):\n",
    "    return [tok.text for tok in fr.tokenizer(sentence)]\n",
    "\n",
    "# Before you create the field, and at then end you build the vocab from these two Fields\n",
    "EN_TEXT = Field(tokenize=tokenize_en)\n",
    "FR_TEXT = Field(tokenize=tokenize_fr, init_token='<sos>', eos_token='<eos>')\n",
    "\n",
    "# csv format\n",
    "raw_data = {'English' : [line for line in europarl_en[:5000]], 'French': [line for line in europarl_fr[:5000]]}\n",
    "\n",
    "df = pd.DataFrame(raw_data, columns=[\"English\", \"French\"])\n",
    "\n",
    "# remove very long sentences and sentences where translations are \n",
    "# not of roughly equal length\n",
    "df['eng_len'] = df['English'].str.count(' ')\n",
    "df['fr_len'] = df['French'].str.count(' ')\n",
    "df = df.query('fr_len < 80 & eng_len < 80')\n",
    "df = df.query('fr_len < eng_len * 1.5 & fr_len * 1.5 > eng_len')\n",
    "\n",
    "# create train and validation set\n",
    "train, val = train_test_split(df, test_size=0.1)\n",
    "\n",
    "train.to_csv('train.csv', index=False)\n",
    "val.to_csv('val.csv', index=False)\n",
    "\n",
    "data_fields = [('English', EN_TEXT), ('French', FR_TEXT)]\n",
    "train, val = TabularDataset.splits(path='./', train='train.csv', validation='val.csv', \n",
    "                                   format='csv', fields=data_fields)\n",
    "\n",
    "FR_TEXT.build_vocab(train, val)\n",
    "EN_TEXT.build_vocab(train, val)\n",
    "\n",
    "train_iter = BucketIterator(train, batch_size=512, \n",
    "                            sort_key=lambda x: len(x.French), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see we split in batches the sentences and from there `pytorch` creates the vocab size of your embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 512]\n",
      "\t[.English]:[torch.LongTensor of size 83x512]\n",
      "\t[.French]:[torch.LongTensor of size 87x512]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 512]\n",
      "\t[.English]:[torch.LongTensor of size 87x512]\n",
      "\t[.French]:[torch.LongTensor of size 92x512]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 512]\n",
      "\t[.English]:[torch.LongTensor of size 88x512]\n",
      "\t[.French]:[torch.LongTensor of size 92x512]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 512]\n",
      "\t[.English]:[torch.LongTensor of size 92x512]\n",
      "\t[.French]:[torch.LongTensor of size 96x512]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 3]\n",
      "\t[.English]:[torch.LongTensor of size 37x3]\n",
      "\t[.French]:[torch.LongTensor of size 41x3]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 512]\n",
      "\t[.English]:[torch.LongTensor of size 88x512]\n",
      "\t[.French]:[torch.LongTensor of size 92x512]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 512]\n",
      "\t[.English]:[torch.LongTensor of size 89x512]\n",
      "\t[.French]:[torch.LongTensor of size 87x512]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 512]\n",
      "\t[.English]:[torch.LongTensor of size 91x512]\n",
      "\t[.French]:[torch.LongTensor of size 95x512]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 512]\n",
      "\t[.English]:[torch.LongTensor of size 87x512]\n",
      "\t[.French]:[torch.LongTensor of size 91x512]\n"
     ]
    }
   ],
   "source": [
    "for i in train_iter:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 512]\n",
      "\t[.English]:[torch.LongTensor of size 83x512]\n",
      "\t[.French]:[torch.LongTensor of size 88x512]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 512]\n",
      "\t[.English]:[torch.LongTensor of size 92x512]\n",
      "\t[.French]:[torch.LongTensor of size 96x512]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 512]\n",
      "\t[.English]:[torch.LongTensor of size 89x512]\n",
      "\t[.French]:[torch.LongTensor of size 93x512]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 512]\n",
      "\t[.English]:[torch.LongTensor of size 88x512]\n",
      "\t[.French]:[torch.LongTensor of size 95x512]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 512]\n",
      "\t[.English]:[torch.LongTensor of size 87x512]\n",
      "\t[.French]:[torch.LongTensor of size 91x512]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 3]\n",
      "\t[.English]:[torch.LongTensor of size 25x3]\n",
      "\t[.French]:[torch.LongTensor of size 30x3]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 512]\n",
      "\t[.English]:[torch.LongTensor of size 91x512]\n",
      "\t[.French]:[torch.LongTensor of size 88x512]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 512]\n",
      "\t[.English]:[torch.LongTensor of size 87x512]\n",
      "\t[.French]:[torch.LongTensor of size 92x512]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 512]\n",
      "\t[.English]:[torch.LongTensor of size 83x512]\n",
      "\t[.French]:[torch.LongTensor of size 83x512]\n"
     ]
    }
   ],
   "source": [
    "for i in iter(train_iter):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in iter(train_iter):\n",
    "    print(batch.English.transpose(0, 1).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8181"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(EN_TEXT.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10242"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(FR_TEXT.vocab.itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Encoder_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODER MASKS\n",
    "batch = next(iter(train_iter))\n",
    "input_seq = batch.English.transpose(0,1)\n",
    "input_pad = EN_TEXT.vocab.stoi['<pad>']\n",
    "input_msk = (input_seq != input_pad).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 1, 91])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_msk.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Decoder_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECODER MASKS\n",
    "target_seq = batch.French.transpose(0,1)\n",
    "target_pad = FR_TEXT.vocab.stoi['<pad>']\n",
    "target_msk = (target_seq != target_pad).unsqueeze(1)\n",
    "size = target_seq.size(1) # get seq_len for matrix\n",
    "nopeak_mask = np.triu(np.ones((1, size, size)), k=1).astype('uint8')\n",
    "nopeak_mask = Variable(torch.from_numpy(nopeak_mask) == 0)\n",
    "target_msk = target_msk & nopeak_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 91, 91])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_msk.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Embedder_\n",
    "The `Embedder` has as parameters `vocab_size` and `d_model`. The `vocab_size` is defined by the number of unique words the encoded text has. In this case you can use `len(EN_TEXT.vocab.itos)` to understand what this parameter will be. The same will happen also for the French language in the decoder. The `d_model` is set to 512 in the paper and here too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Feed-Forward_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \"\"\"Linear transformation and a ReLU\"\"\"\n",
    "    def __init__(self, d_model: int = 512, d_ff: int = 2048, dropout: float = 0.1):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.linear_1(x)))\n",
    "        return self.linear_2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers _Encoder - Decoder_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, dropout=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.norm_1 = Norm(d_model)\n",
    "        self.norm_2 = Norm(d_model)\n",
    "        self.attn = MultiHeadedAttention(heads, d_model)\n",
    "        self.ff = FeedForward(d_model)\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        print(f'this is x in EncoderLayer-----> {x}')\n",
    "        x2 = self.norm_1(x)\n",
    "        x = x + self.dropout_1(self.attn(x2, x2, x2, mask))\n",
    "        x2 = self.norm_2(x)\n",
    "        x = x + self.dropout_2(self.ff(x2))\n",
    "        return x\n",
    "        \n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm_1 = Norm(d_model)\n",
    "        self.norm_2 = Norm(d_model)\n",
    "        self.norm_3 = Norm(d_model)\n",
    "        \n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        self.dropout_3 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.attn_1 = MultiHeadedAttention(heads, d_model)\n",
    "        self.attn_2 = MultiHeadedAttention(heads, d_model)\n",
    "        self.ff = FeedForward(d_model)\n",
    "        \n",
    "    def forward(self, x, e_outputs, src_mask, trg_mask):\n",
    "        x2 = self.norm_1(x)\n",
    "        x = x + self.dropout_1(self.attn_1(x2, x2, x2, trg_mask))\n",
    "        x2 = self.norm_2(x)\n",
    "        x = x + self.dropout_2(self.attn_2(x2, e_outputs, e_outputs, src_mask))\n",
    "        x2 = self.norm_3(x)\n",
    "        x = x + self.dropout_3(self.ff(x2))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, N, heads, dropout):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.embed = Embedder(vocab_size, d_model)\n",
    "        self.pe = PositionalEncoder(d_model, dropout=dropout)\n",
    "        self.layers = get_clones(EncoderLayer(d_model, heads, dropout), N)\n",
    "        self.norm = Norm(d_model)\n",
    "    def forward(self, src, mask):\n",
    "        x = self.embed(src)\n",
    "        \n",
    "        x = self.pe(x)\n",
    "        print(f'--Encoder x after PE : {x}')\n",
    "        for i in range(self.N):\n",
    "            print(f'loop within encoder. Iteration -- {i}')\n",
    "            x = self.layers[i](x, mask)\n",
    "        return self.norm(x)\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, N, heads, dropout):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.embed = Embedder(vocab_size, d_model)\n",
    "        self.pe = PositionalEncoder(d_model, dropout=dropout)\n",
    "        self.layers = get_clones(DecoderLayer(d_model, heads, dropout), N)\n",
    "        self.norm = Norm(d_model)\n",
    "    def forward(self, trg, e_outputs, src_mask, trg_mask):\n",
    "        x = self.embed(trg)\n",
    "        x = self.pe(x)\n",
    "        for i in range(self.N):\n",
    "            x = self.layers[i](x, e_outputs, src_mask, trg_mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Transformer_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \"\"\"Transformer architecture with encoder, decoder and Linear layer of the output.\"\"\"\n",
    "    def __init__(self, src_vocab, trg_vocab, d_model, N, heads, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(src_vocab, d_model, N, heads, dropout)\n",
    "        self.decoder = Decoder(trg_vocab, d_model, N, heads, dropout)\n",
    "        self.out = nn.Linear(d_model, trg_vocab)\n",
    "    \n",
    "    def forward(self, src, trg, src_mask, trg_mask):\n",
    "        e_outputs = self.encoder(src, src_mask)\n",
    "        d_output = self.decoder(trg, e_outputs, src_mask, trg_mask)\n",
    "        output = self.out(d_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nopeak_mask(size):\n",
    "    np_mask = np.triu(np.ones((1, size, size)), k=1).astype('uint8')\n",
    "    np_mask =  Variable(torch.from_numpy(np_mask) == 0)\n",
    "    return np_mask\n",
    "\n",
    "def create_masks(src, trg):\n",
    "    \n",
    "    source_pad = EN_TEXT.vocab.stoi['<pad>']\n",
    "    src_mask = (src != source_pad).unsqueeze(-2)\n",
    "\n",
    "    if trg is not None:\n",
    "        target_pad = FR_TEXT.vocab.stoi['<pad>']\n",
    "        trg_mask = (trg != target_pad).unsqueeze(-2)\n",
    "        size = trg.size(1) # get seq_len for matrix\n",
    "        np_mask = nopeak_mask(size)\n",
    "        trg_mask = trg_mask & np_mask\n",
    "    else:\n",
    "        trg_mask = None\n",
    "    return src_mask, trg_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512\n",
    "heads = 8\n",
    "N = 6\n",
    "src_vocab = len(EN_TEXT.vocab)\n",
    "trg_vocab = len(FR_TEXT.vocab)\n",
    "\n",
    "model = Transformer(src_vocab, trg_vocab, d_model, N, heads, dropout = 0.1)\n",
    "\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "        \n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "def train_model(epochs, print_every=100):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    start = time.time()\n",
    "    temp = start\n",
    "    \n",
    "    total_loss = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch - {epoch}')\n",
    "        for i, batch in enumerate(train_iter):\n",
    "            src = batch.English.transpose(0,1)\n",
    "            trg = batch.French.transpose(0,1)\n",
    "            # the French sentence we input has all words except\n",
    "            # the last, as it is using each word to predict the next\n",
    "            trg_input = trg[:, :-1]\n",
    "            \n",
    "            # the words we are trying to predict\n",
    "            targets = trg[:, 1:].contiguous().view(-1)\n",
    "            \n",
    "            # create function to make masks using mask code above\n",
    "            src_mask, trg_mask = create_masks(src, trg_input)\n",
    "            \n",
    "            preds = model(src, trg_input, src_mask, trg_mask)\n",
    "            \n",
    "            optim.zero_grad()\n",
    "            print(f'predictions size : {preds.view(-1, preds.size(-1)).size()}')\n",
    "            print(f'targets size : {targets.size()}')\n",
    "            loss = F.cross_entropy(preds.view(-1, preds.size(-1)), targets, \n",
    "                                   ignore_index=target_pad)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            print(f'Loss.data ----> = {loss.item()}')\n",
    "            total_loss += loss.item()\n",
    "            if (i + 1) % print_every == 0:\n",
    "                loss_avg = total_loss / print_every\n",
    "                print(\"time = %dm, epoch %d, iter = %d, loss = %.3f, %ds per %d iters\" % ((time.time() - start) // 60, epoch + 1, i + 1, loss_avg, time.time() - temp, print_every))\n",
    "                total_loss = 0\n",
    "                temp = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 0\n",
      "--Encoder x after PE : tensor([[[-0.0851,  0.9312, -0.2281,  ...,  1.0702, -0.1880,  1.0272],\n",
      "         [ 0.4032,  0.4439,  1.3056,  ...,  0.5143, -0.6426,  0.7896],\n",
      "         [ 1.6677, -0.8952,  1.6084,  ...,  0.0000, -0.2544,  0.0000],\n",
      "         ...,\n",
      "         [-0.2319,  0.5529, -0.4102,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [-0.8427, -0.4381, -0.2582,  ...,  1.0595,  0.0000,  0.0000],\n",
      "         [-0.4383, -1.2356,  0.0000,  ...,  1.0595,  0.1775,  0.0000]],\n",
      "\n",
      "        [[ 0.3753,  0.5082, -0.4723,  ...,  1.5692, -0.3355,  0.8619],\n",
      "         [ 0.6853,  0.2364,  0.0000,  ...,  0.0000, -0.6110,  0.5476],\n",
      "         [ 1.4878, -0.0000,  1.2968,  ...,  1.5232,  0.5940,  1.3578],\n",
      "         ...,\n",
      "         [-0.2319,  0.0000, -0.4102,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.8427, -0.4381, -0.2582,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [-0.4383, -1.2356,  0.6229,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.5318,  0.9221,  0.4146,  ...,  0.5143, -0.6426,  0.7896],\n",
      "         [ 1.0165,  1.1168,  0.4711,  ...,  0.7886,  0.0000,  0.5896],\n",
      "         [ 1.1318, -0.6990,  0.7166,  ...,  0.7443,  0.4369,  1.3568],\n",
      "         ...,\n",
      "         [-0.2319,  0.5529, -0.4102,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.8427, -0.0000, -0.2582,  ...,  0.0000,  0.1775,  0.5406],\n",
      "         [-0.4383, -1.2356,  0.6229,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.5753,  1.2714,  0.1786,  ...,  0.8943, -0.2610,  0.5646],\n",
      "         [ 0.3533,  1.0008,  0.4287,  ...,  0.0000,  0.0684,  1.2179],\n",
      "         [ 0.0000, -0.7164,  1.3852,  ...,  1.4455,  0.3299,  0.8169],\n",
      "         ...,\n",
      "         [-0.2319,  0.0000, -0.4102,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.8427, -0.4381, -0.2582,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.4383, -1.2356,  0.0000,  ...,  0.0000,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.0000,  1.6951, -0.0504,  ...,  0.7673, -0.1542,  0.7974],\n",
      "         [ 1.2688,  0.6926,  0.4025,  ...,  1.1464,  0.2149,  0.0000],\n",
      "         [ 0.4287, -0.0220,  0.6022,  ...,  1.1074,  0.0684,  1.2179],\n",
      "         ...,\n",
      "         [-0.2319,  0.5529, -0.4102,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.8427, -0.4381, -0.2582,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.4383, -1.2356,  0.6229,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.5536,  1.7371,  0.1077,  ...,  1.3131,  0.4809,  1.2170],\n",
      "         [ 0.0000,  1.2451,  1.1398,  ...,  0.6084, -0.0578,  1.6338],\n",
      "         [ 1.0894,  0.2332,  0.7136,  ...,  0.5219,  0.2669,  1.5763],\n",
      "         ...,\n",
      "         [-0.2319,  0.5529, -0.4102,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.8427, -0.0000, -0.2582,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.4383, -1.2356,  0.6229,  ...,  1.0595,  0.1775,  0.5406]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "loop within encoder. Iteration -- 0\n",
      "this is x in EncoderLayer-----> tensor([[[-0.0851,  0.9312, -0.2281,  ...,  1.0702, -0.1880,  1.0272],\n",
      "         [ 0.4032,  0.4439,  1.3056,  ...,  0.5143, -0.6426,  0.7896],\n",
      "         [ 1.6677, -0.8952,  1.6084,  ...,  0.0000, -0.2544,  0.0000],\n",
      "         ...,\n",
      "         [-0.2319,  0.5529, -0.4102,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [-0.8427, -0.4381, -0.2582,  ...,  1.0595,  0.0000,  0.0000],\n",
      "         [-0.4383, -1.2356,  0.0000,  ...,  1.0595,  0.1775,  0.0000]],\n",
      "\n",
      "        [[ 0.3753,  0.5082, -0.4723,  ...,  1.5692, -0.3355,  0.8619],\n",
      "         [ 0.6853,  0.2364,  0.0000,  ...,  0.0000, -0.6110,  0.5476],\n",
      "         [ 1.4878, -0.0000,  1.2968,  ...,  1.5232,  0.5940,  1.3578],\n",
      "         ...,\n",
      "         [-0.2319,  0.0000, -0.4102,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.8427, -0.4381, -0.2582,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [-0.4383, -1.2356,  0.6229,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.5318,  0.9221,  0.4146,  ...,  0.5143, -0.6426,  0.7896],\n",
      "         [ 1.0165,  1.1168,  0.4711,  ...,  0.7886,  0.0000,  0.5896],\n",
      "         [ 1.1318, -0.6990,  0.7166,  ...,  0.7443,  0.4369,  1.3568],\n",
      "         ...,\n",
      "         [-0.2319,  0.5529, -0.4102,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.8427, -0.0000, -0.2582,  ...,  0.0000,  0.1775,  0.5406],\n",
      "         [-0.4383, -1.2356,  0.6229,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.5753,  1.2714,  0.1786,  ...,  0.8943, -0.2610,  0.5646],\n",
      "         [ 0.3533,  1.0008,  0.4287,  ...,  0.0000,  0.0684,  1.2179],\n",
      "         [ 0.0000, -0.7164,  1.3852,  ...,  1.4455,  0.3299,  0.8169],\n",
      "         ...,\n",
      "         [-0.2319,  0.0000, -0.4102,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.8427, -0.4381, -0.2582,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.4383, -1.2356,  0.0000,  ...,  0.0000,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.0000,  1.6951, -0.0504,  ...,  0.7673, -0.1542,  0.7974],\n",
      "         [ 1.2688,  0.6926,  0.4025,  ...,  1.1464,  0.2149,  0.0000],\n",
      "         [ 0.4287, -0.0220,  0.6022,  ...,  1.1074,  0.0684,  1.2179],\n",
      "         ...,\n",
      "         [-0.2319,  0.5529, -0.4102,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.8427, -0.4381, -0.2582,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.4383, -1.2356,  0.6229,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.5536,  1.7371,  0.1077,  ...,  1.3131,  0.4809,  1.2170],\n",
      "         [ 0.0000,  1.2451,  1.1398,  ...,  0.6084, -0.0578,  1.6338],\n",
      "         [ 1.0894,  0.2332,  0.7136,  ...,  0.5219,  0.2669,  1.5763],\n",
      "         ...,\n",
      "         [-0.2319,  0.5529, -0.4102,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.8427, -0.0000, -0.2582,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.4383, -1.2356,  0.6229,  ...,  1.0595,  0.1775,  0.5406]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 82, 64]) , torch.Size([512, 8, 82, 64]), torch.Size([512, 8, 82, 64])\n",
      "Score shape -- torch.Size([512, 8, 82, 82])\n",
      "Mask ---> torch.Size([512, 1, 82])\n",
      "Mask new --> torch.Size([512, 1, 1, 82])\n",
      "loop within encoder. Iteration -- 1\n",
      "this is x in EncoderLayer-----> tensor([[[ 5.1529e-01,  2.5878e+00,  6.8542e-01,  ..., -3.0642e-01,\n",
      "           4.4899e-01,  5.0655e-01],\n",
      "         [ 3.7058e-01,  1.5361e+00,  1.7451e+00,  ..., -7.6626e-01,\n",
      "          -6.0651e-01,  5.6141e-01],\n",
      "         [ 2.4660e+00, -5.1661e-01,  2.0810e+00,  ..., -5.9620e-01,\n",
      "           1.6333e+00, -8.8153e-01],\n",
      "         ...,\n",
      "         [ 7.5152e-01,  1.9626e+00, -4.6836e-01,  ...,  4.1747e-01,\n",
      "           1.2703e+00, -2.3141e-01],\n",
      "         [-5.0546e-01,  5.1021e-01,  6.7530e-03,  ..., -7.5297e-02,\n",
      "           1.3099e+00, -4.3425e-01],\n",
      "         [-8.6806e-01,  8.3987e-01, -2.9353e-01,  ..., -7.0981e-01,\n",
      "           1.2824e+00, -7.3753e-01]],\n",
      "\n",
      "        [[-3.0175e-01,  1.2236e+00, -7.4662e-01,  ...,  6.9185e-01,\n",
      "           1.3599e+00, -5.9170e-01],\n",
      "         [ 2.7969e-01,  1.6247e+00, -3.1331e-01,  ..., -9.3432e-01,\n",
      "           1.0011e+00, -5.2064e-01],\n",
      "         [ 1.6349e+00,  1.0496e+00,  2.3609e+00,  ...,  7.4552e-01,\n",
      "           2.4401e+00,  7.1678e-01],\n",
      "         ...,\n",
      "         [-2.8560e-01,  2.2903e+00,  6.3783e-01,  ...,  2.6672e-02,\n",
      "           1.7988e+00, -5.2081e-01],\n",
      "         [-1.8853e+00,  1.0512e+00,  7.0808e-01,  ...,  1.1398e-01,\n",
      "          -5.2099e-01, -3.5153e-01],\n",
      "         [-4.2685e-01,  9.6192e-01,  1.3836e+00,  ...,  1.7290e-01,\n",
      "           1.3146e+00, -2.4273e-02]],\n",
      "\n",
      "        [[-6.3389e-01,  1.7308e+00,  9.0854e-01,  ...,  8.8142e-01,\n",
      "          -3.6809e-02, -3.4745e-01],\n",
      "         [ 2.4021e-01,  3.3163e+00,  4.4636e-01,  ..., -4.4529e-01,\n",
      "           1.4132e+00,  1.8885e-01],\n",
      "         [ 8.8293e-01,  9.7751e-01,  9.9327e-01,  ...,  8.6600e-01,\n",
      "           2.0933e+00,  5.9866e-01],\n",
      "         ...,\n",
      "         [-1.0269e+00,  2.5353e+00, -3.0240e-01,  ..., -1.2311e+00,\n",
      "           9.9676e-01,  1.8603e-01],\n",
      "         [-1.5799e+00,  1.8386e+00, -9.3153e-02,  ..., -1.5679e+00,\n",
      "           1.2195e+00, -1.1892e-01],\n",
      "         [-1.4831e+00,  6.2844e-01,  1.0881e+00,  ..., -1.6140e-01,\n",
      "           1.0410e+00, -4.1549e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.5700e-01,  3.1536e+00,  2.7265e-01,  ..., -4.1534e-01,\n",
      "           7.3750e-01, -9.8776e-02],\n",
      "         [ 2.0803e-01,  2.3573e+00,  4.2706e-01,  ..., -7.6394e-01,\n",
      "           8.3724e-01,  3.8114e-01],\n",
      "         [-1.1628e+00,  3.5700e-01,  1.9063e+00,  ...,  7.0151e-01,\n",
      "           1.6556e+00, -1.8240e-03],\n",
      "         ...,\n",
      "         [-4.5042e-01,  1.4352e+00, -5.4534e-01,  ..., -9.0815e-01,\n",
      "           1.4162e+00,  5.8205e-02],\n",
      "         [-1.5073e+00,  1.8702e+00,  1.2269e-01,  ..., -7.3505e-01,\n",
      "           8.3114e-01,  4.0916e-01],\n",
      "         [-5.0866e-01,  1.0957e+00,  5.2872e-01,  ..., -1.8099e+00,\n",
      "           6.8627e-01, -3.8698e-01]],\n",
      "\n",
      "        [[-2.5232e-01,  3.3980e+00, -1.0489e-01,  ...,  1.4537e+00,\n",
      "           2.3065e-02,  3.3827e-01],\n",
      "         [ 1.1746e+00,  2.4425e+00,  1.0231e+00,  ..., -5.5845e-01,\n",
      "           1.7996e+00, -1.2787e+00],\n",
      "         [ 1.0078e+00,  1.5637e+00,  4.8910e-01,  ...,  2.0630e-01,\n",
      "           1.6661e+00, -8.0603e-02],\n",
      "         ...,\n",
      "         [ 2.1907e-01,  2.2490e+00, -1.1891e-02,  ..., -2.7009e-01,\n",
      "           1.7477e+00,  1.4582e-01],\n",
      "         [-5.6086e-01,  7.0720e-01,  5.0618e-01,  ..., -1.3398e+00,\n",
      "           1.0236e-01, -7.1061e-01],\n",
      "         [-1.3036e+00,  6.1651e-01, -2.7653e-01,  ..., -1.4012e-01,\n",
      "           1.5493e+00,  4.6685e-03]],\n",
      "\n",
      "        [[-2.0941e+00,  3.3357e+00,  1.0150e+00,  ..., -1.1985e-01,\n",
      "           1.9149e+00,  1.1438e+00],\n",
      "         [-7.4142e-01,  3.1652e+00,  1.9109e+00,  ...,  9.0324e-01,\n",
      "           1.3147e+00,  1.4414e+00],\n",
      "         [-6.8188e-01,  1.9087e+00,  1.8056e+00,  ..., -8.7028e-01,\n",
      "           2.1390e+00,  3.9633e-01],\n",
      "         ...,\n",
      "         [ 6.7854e-01,  1.9963e+00,  2.4302e-02,  ..., -5.6010e-01,\n",
      "           1.3880e+00, -3.4890e-01],\n",
      "         [-1.9702e+00,  1.3431e+00,  2.1544e-01,  ...,  3.2743e-01,\n",
      "           1.1812e+00, -5.6084e-01],\n",
      "         [-1.1506e+00,  4.0701e-01,  9.4182e-01,  ..., -3.4698e-01,\n",
      "           8.4188e-01, -5.7367e-01]]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 82, 64]) , torch.Size([512, 8, 82, 64]), torch.Size([512, 8, 82, 64])\n",
      "Score shape -- torch.Size([512, 8, 82, 82])\n",
      "Mask ---> torch.Size([512, 1, 82])\n",
      "Mask new --> torch.Size([512, 1, 1, 82])\n",
      "loop within encoder. Iteration -- 2\n",
      "this is x in EncoderLayer-----> tensor([[[ 1.2373,  2.3735,  1.1324,  ..., -2.2191,  0.6009, -0.5536],\n",
      "         [ 1.7796,  0.2496,  0.9270,  ..., -1.8907, -0.7796, -0.0823],\n",
      "         [ 3.6477, -1.6047,  2.9605,  ..., -2.2155,  1.5546, -1.9528],\n",
      "         ...,\n",
      "         [ 1.7254,  1.0542, -0.1385,  ..., -0.8589,  1.2703, -1.6588],\n",
      "         [ 0.2856, -0.4140, -0.2438,  ..., -0.9472,  1.7512, -1.1925],\n",
      "         [ 0.2425,  0.7415, -0.1423,  ..., -2.3492,  1.3482, -1.8761]],\n",
      "\n",
      "        [[ 1.0044,  0.9614,  0.1505,  ..., -0.2430,  2.1106, -1.6201],\n",
      "         [ 0.8209,  0.7809,  0.1609,  ..., -2.1277,  1.1611, -2.1375],\n",
      "         [ 2.6876, -0.1629,  3.0896,  ..., -0.2157,  3.3580,  0.1907],\n",
      "         ...,\n",
      "         [ 0.5951,  1.6866,  1.0686,  ..., -0.8885,  2.3968,  0.0519],\n",
      "         [-0.7211,  0.9035,  1.4717,  ..., -1.0776,  0.3769, -0.5265],\n",
      "         [ 0.8825,  0.0810,  1.4687,  ..., -0.7668,  1.3618, -0.4585]],\n",
      "\n",
      "        [[-0.1001, -0.0337,  1.3423,  ..., -0.2965,  0.5162, -2.0410],\n",
      "         [ 1.3199,  1.7619,  0.9719,  ..., -1.6650,  1.5580, -0.3210],\n",
      "         [ 2.0310, -0.6384,  1.2367,  ..., -0.2110,  2.6039, -0.1048],\n",
      "         ...,\n",
      "         [-0.3743,  2.5353, -0.2280,  ..., -2.6301,  1.2450, -0.6104],\n",
      "         [-0.7068,  1.0649, -0.1348,  ..., -3.0254,  2.0489, -0.4380],\n",
      "         [-0.3315, -0.8080,  0.1389,  ..., -0.9219,  1.2718, -1.3455]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.7435,  2.3079,  0.3285,  ..., -1.6716,  0.6870, -0.9689],\n",
      "         [ 1.6383,  2.1543,  1.2809,  ..., -1.8917,  0.6978, -1.2777],\n",
      "         [ 0.1107, -0.3471,  2.7005,  ...,  0.2889,  1.6896, -1.0394],\n",
      "         ...,\n",
      "         [ 0.8995,  0.0729, -1.6262,  ..., -1.6419,  0.8475, -0.9431],\n",
      "         [-0.5784,  1.6308,  0.3575,  ..., -1.5056,  0.9483, -0.2161],\n",
      "         [ 0.7218,  0.8963,  0.9950,  ..., -2.1456,  0.3269, -0.7052]],\n",
      "\n",
      "        [[ 0.8964,  2.5952,  0.5530,  ...,  0.2943, -0.1066, -1.0925],\n",
      "         [ 1.6863,  1.8855,  1.1897,  ..., -1.6739,  2.4065, -2.2587],\n",
      "         [ 1.6614,  0.9536,  1.0880,  ..., -0.8848,  1.2345, -1.0534],\n",
      "         ...,\n",
      "         [ 0.8632,  1.3111,  0.6984,  ..., -1.6723,  1.9239, -0.9150],\n",
      "         [-0.1621, -0.0721,  1.1166,  ..., -2.9798,  0.4778, -1.5890],\n",
      "         [-0.9303, -0.4414, -0.2109,  ..., -1.6105,  2.0512, -0.4089]],\n",
      "\n",
      "        [[-1.3202,  3.2616,  1.7228,  ..., -1.0586,  2.3796,  0.0372],\n",
      "         [-0.1322,  2.4486,  1.6990,  ...,  0.8925,  1.0061,  0.6857],\n",
      "         [ 0.2294,  1.4943,  2.2709,  ..., -2.2447,  2.9031, -0.3349],\n",
      "         ...,\n",
      "         [ 1.2563,  1.2293, -0.1379,  ..., -1.3603,  1.3855, -0.7784],\n",
      "         [-1.2973,  0.9320,  0.6919,  ..., -1.1141,  1.5336, -0.9670],\n",
      "         [-0.8646, -0.6048,  1.5322,  ..., -1.2264,  0.6614, -1.5247]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 82, 64]) , torch.Size([512, 8, 82, 64]), torch.Size([512, 8, 82, 64])\n",
      "Score shape -- torch.Size([512, 8, 82, 82])\n",
      "Mask ---> torch.Size([512, 1, 82])\n",
      "Mask new --> torch.Size([512, 1, 1, 82])\n",
      "loop within encoder. Iteration -- 3\n",
      "this is x in EncoderLayer-----> tensor([[[ 2.0769,  2.3133,  2.1577,  ..., -3.4060, -1.4944, -0.6098],\n",
      "         [ 1.7796, -0.0621,  0.1663,  ..., -2.6753, -3.1263, -0.7021],\n",
      "         [ 3.7836, -1.8737,  4.2245,  ..., -2.6318, -0.5902, -1.5799],\n",
      "         ...,\n",
      "         [ 1.6647,  0.8171,  1.3584,  ..., -1.2364, -0.7795, -1.7261],\n",
      "         [ 0.5954,  0.1031,  0.7643,  ..., -2.0710, -0.7394, -1.2027],\n",
      "         [ 0.1671,  1.1398,  0.6381,  ..., -3.3882, -0.9248, -1.4587]],\n",
      "\n",
      "        [[ 1.2226,  0.3024, -0.5505,  ..., -2.6880, -0.1707, -2.2642],\n",
      "         [ 1.8092,  0.4050,  1.4708,  ..., -4.0706, -0.9783, -3.0359],\n",
      "         [ 2.8137, -0.8286,  4.5129,  ..., -2.1836,  0.7815, -0.4805],\n",
      "         ...,\n",
      "         [ 1.6353,  1.4745,  2.9309,  ..., -1.9932,  0.1456, -0.4575],\n",
      "         [-0.2631, -0.0686,  2.7765,  ..., -2.0244, -1.6537, -0.8733],\n",
      "         [ 1.3655, -0.0565,  2.5574,  ..., -0.7609, -1.4861, -0.5875]],\n",
      "\n",
      "        [[-0.3219, -0.4037,  1.9303,  ..., -1.3522, -1.8400, -2.8010],\n",
      "         [ 1.7982,  2.1943,  1.5196,  ..., -3.1703, -0.0294, -1.5163],\n",
      "         [ 2.6310, -0.2323,  1.8661,  ..., -1.7405,  0.1474, -1.4866],\n",
      "         ...,\n",
      "         [ 0.4777,  2.8270,  0.8785,  ..., -3.7816, -0.4188, -1.0136],\n",
      "         [-0.4929,  1.5595,  0.1499,  ..., -4.6623, -0.4925, -0.9729],\n",
      "         [-0.4607, -0.4373,  0.9926,  ..., -2.5237, -1.2269, -1.7521]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.4111,  2.5630,  0.6737,  ..., -3.2211, -1.8342, -1.4307],\n",
      "         [ 2.3126,  2.5127,  1.9350,  ..., -3.7139, -2.3538, -2.1616],\n",
      "         [ 1.0719,  0.0061,  3.3503,  ..., -1.2319, -0.6626, -1.7218],\n",
      "         ...,\n",
      "         [ 1.2996,  1.1302, -0.8460,  ..., -3.5182, -1.4733, -1.9155],\n",
      "         [-0.6991,  1.9279,  1.1147,  ..., -2.3478, -2.5152, -0.5680],\n",
      "         [ 1.9714,  1.5277,  1.7199,  ..., -3.4815, -2.3503, -0.9227]],\n",
      "\n",
      "        [[ 0.8875,  2.9995,  1.0926,  ..., -0.9635, -1.8534, -1.7834],\n",
      "         [ 1.3788,  2.4963,  2.0524,  ..., -3.1179,  0.6318, -2.8150],\n",
      "         [ 0.8394,  1.5574,  1.8467,  ..., -2.1798, -0.7825, -1.7547],\n",
      "         ...,\n",
      "         [ 0.3431,  1.5602,  1.4429,  ..., -2.9436, -0.6066, -1.6938],\n",
      "         [ 0.0887,  0.0839,  2.3820,  ..., -4.1851,  0.2571, -1.5890],\n",
      "         [-1.3593, -0.4247,  0.9096,  ..., -3.2307, -0.7134, -0.3307]],\n",
      "\n",
      "        [[-0.1815,  4.0434,  1.7228,  ..., -2.1148,  2.6544,  0.1367],\n",
      "         [-0.1003,  2.9215,  2.6229,  ...,  0.0151, -0.6739, -0.0209],\n",
      "         [ 1.4405,  1.8504,  3.4285,  ..., -2.9419,  0.5238, -1.5878],\n",
      "         ...,\n",
      "         [ 1.7838,  1.7831,  0.8464,  ..., -2.2382, -0.6613, -0.7834],\n",
      "         [-0.5954,  1.9719,  1.0656,  ..., -1.2622, -0.6873, -1.5169],\n",
      "         [ 0.0280, -0.1230,  2.2969,  ..., -2.6030, -1.5409, -1.5790]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 82, 64]) , torch.Size([512, 8, 82, 64]), torch.Size([512, 8, 82, 64])\n",
      "Score shape -- torch.Size([512, 8, 82, 82])\n",
      "Mask ---> torch.Size([512, 1, 82])\n",
      "Mask new --> torch.Size([512, 1, 1, 82])\n",
      "loop within encoder. Iteration -- 4\n",
      "this is x in EncoderLayer-----> tensor([[[ 1.9520,  2.8185,  1.2578,  ..., -4.3368, -0.7099, -0.5499],\n",
      "         [ 1.3489,  0.1651, -0.3972,  ..., -2.8945, -3.2466,  0.0584],\n",
      "         [ 3.5613, -2.2394,  4.7500,  ..., -3.2363, -0.3151, -0.6535],\n",
      "         ...,\n",
      "         [ 1.2702,  0.9724,  0.7370,  ..., -1.7494, -0.2450, -2.1228],\n",
      "         [ 0.4068,  0.4050,  0.6190,  ..., -2.9846, -0.7685,  0.2837],\n",
      "         [ 0.7222,  0.9977,  0.0424,  ..., -3.4858, -0.4131, -0.3215]],\n",
      "\n",
      "        [[ 0.7235,  1.0249, -0.8468,  ..., -2.6387,  0.4475, -2.0554],\n",
      "         [ 1.9769,  0.1582,  0.9624,  ..., -4.2531, -1.6300, -2.9086],\n",
      "         [ 2.4281, -0.1278,  4.6962,  ..., -1.9479,  0.2594, -1.3440],\n",
      "         ...,\n",
      "         [ 1.3781,  1.9515,  2.9237,  ..., -2.6603, -0.7301,  0.5443],\n",
      "         [-0.7333,  0.2424,  2.6032,  ..., -2.1652, -2.1607, -0.5945],\n",
      "         [ 0.9769, -0.0565,  2.5639,  ..., -0.6909, -1.8998, -0.6631]],\n",
      "\n",
      "        [[-0.6365,  0.3684,  1.4884,  ..., -2.2469, -2.7839, -2.8697],\n",
      "         [ 2.4630,  2.7497,  0.8781,  ..., -3.4256, -0.4128, -1.8879],\n",
      "         [ 2.6632, -0.0435,  0.7161,  ..., -3.0110, -0.7045, -1.5823],\n",
      "         ...,\n",
      "         [ 0.6662,  2.8998,  0.6865,  ..., -4.3991,  0.2822, -1.0136],\n",
      "         [-0.5841,  1.2013,  0.1340,  ..., -5.2511, -1.1218, -1.6950],\n",
      "         [-0.6515, -0.6924, -0.1078,  ..., -3.3981, -1.7603, -1.7337]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.2739,  2.8508, -0.0110,  ..., -4.7997, -2.5937, -0.7009],\n",
      "         [ 2.0767,  2.2957,  0.9272,  ..., -5.2255, -2.7523, -2.4818],\n",
      "         [ 0.7783,  0.3069,  3.0587,  ..., -2.1562, -1.0930, -1.1583],\n",
      "         ...,\n",
      "         [ 0.9919,  1.7918, -1.1959,  ..., -4.7462, -1.9052, -1.2358],\n",
      "         [-0.6484,  1.6646,  0.3194,  ..., -3.7168, -2.4799,  0.2198],\n",
      "         [ 1.5847,  2.4200,  1.2723,  ..., -2.8889, -3.1476,  0.5073]],\n",
      "\n",
      "        [[ 1.0243,  3.6582,  0.7278,  ..., -0.9635, -2.4505, -2.2115],\n",
      "         [ 1.0291,  3.5854,  1.7910,  ..., -4.9354, -0.1403, -1.6780],\n",
      "         [ 0.6825,  2.0545,  2.2401,  ..., -2.7650, -1.8640, -1.8407],\n",
      "         ...,\n",
      "         [ 0.2540,  2.1823,  1.8358,  ..., -4.6264, -1.8598, -1.6938],\n",
      "         [-0.3730,  0.0140,  2.4378,  ..., -5.1128, -0.2837, -2.2834],\n",
      "         [-2.0657, -0.1249,  0.4807,  ..., -3.8530, -1.4220, -0.1958]],\n",
      "\n",
      "        [[-0.1506,  4.8112,  1.4950,  ..., -1.3186,  2.8454, -0.4238],\n",
      "         [ 0.2378,  2.5472,  2.4721,  ..., -0.6531, -1.4852,  0.6810],\n",
      "         [ 1.2334,  1.8060,  3.0097,  ..., -3.9243, -0.2972, -2.0149],\n",
      "         ...,\n",
      "         [ 2.0505,  1.9266,  1.3228,  ..., -2.8193, -1.2340, -0.1083],\n",
      "         [-0.0481,  2.1788,  0.4947,  ..., -2.1245, -1.3571, -1.7983],\n",
      "         [-0.2147,  0.1004,  2.5350,  ..., -3.5571, -2.3641, -1.7251]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 82, 64]) , torch.Size([512, 8, 82, 64]), torch.Size([512, 8, 82, 64])\n",
      "Score shape -- torch.Size([512, 8, 82, 82])\n",
      "Mask ---> torch.Size([512, 1, 82])\n",
      "Mask new --> torch.Size([512, 1, 1, 82])\n",
      "loop within encoder. Iteration -- 5\n",
      "this is x in EncoderLayer-----> tensor([[[ 2.3736, -1.0162,  0.3866,  ..., -1.9666, -1.3029, -0.2442],\n",
      "         [ 1.9583, -3.2455, -1.9080,  ..., -0.1589, -3.6666,  0.8351],\n",
      "         [ 3.8433, -2.2394,  3.1165,  ..., -0.8794, -0.7147, -0.0499],\n",
      "         ...,\n",
      "         [ 1.3359, -0.6574, -0.4339,  ...,  0.7388, -0.1017, -2.0900],\n",
      "         [ 1.1404, -2.7856, -0.8308,  ..., -0.8665, -1.4210, -0.2405],\n",
      "         [ 0.6618, -2.0113, -1.9549,  ..., -0.8180, -1.5113, -0.4708]],\n",
      "\n",
      "        [[ 0.9547, -1.3453, -1.3675,  ..., -0.8117, -0.0519, -0.9876],\n",
      "         [ 2.4575, -3.6740,  0.1999,  ..., -2.2720, -2.2707, -1.7620],\n",
      "         [ 3.5713, -3.5491,  4.1238,  ..., -0.1193, -0.2347, -0.6394],\n",
      "         ...,\n",
      "         [ 2.5983, -2.4574,  1.8107,  ...,  0.0708, -1.3899,  1.6436],\n",
      "         [-0.3971, -2.0213,  1.4924,  ..., -0.5565, -3.2033,  0.1745],\n",
      "         [ 0.9769, -2.2068,  2.4315,  ..., -0.1548, -3.0714,  0.1489]],\n",
      "\n",
      "        [[-0.1904, -2.0337,  0.9010,  ..., -1.0072, -3.2902, -1.9416],\n",
      "         [ 3.3135, -0.3918,  1.1868,  ..., -1.9871, -0.9906, -2.1230],\n",
      "         [ 3.1019, -3.3312,  0.9000,  ..., -1.9735, -1.6237, -1.4577],\n",
      "         ...,\n",
      "         [ 1.2888, -0.2999,  0.1061,  ..., -3.1138, -0.7930, -0.5003],\n",
      "         [ 0.2378, -0.2002,  0.4582,  ..., -3.7559, -2.1050, -2.0408],\n",
      "         [ 0.5305, -3.1625, -0.6214,  ..., -1.8757, -2.7458, -1.3976]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.5937, -0.3575, -1.0769,  ..., -3.2339, -3.3818, -0.1885],\n",
      "         [ 2.3634, -0.7403, -0.2938,  ..., -3.8267, -4.2823, -1.7821],\n",
      "         [ 1.7350, -3.7147,  1.4723,  ..., -0.6422, -1.4640,  0.3984],\n",
      "         ...,\n",
      "         [ 1.1691, -0.9597, -3.2494,  ..., -2.9118, -3.5256, -0.7179],\n",
      "         [-0.5542, -1.6845, -1.0104,  ..., -3.4075, -4.0408,  0.8207],\n",
      "         [ 2.0278, -0.8359, -0.8759,  ..., -1.2485, -4.1604,  1.3895]],\n",
      "\n",
      "        [[ 1.6677,  2.4435, -0.2751,  ...,  0.7017, -2.5416, -1.7355],\n",
      "         [ 1.7561,  2.3248,  1.3446,  ..., -3.6022, -0.5933, -1.8536],\n",
      "         [ 1.6702,  2.0545,  1.5507,  ..., -1.0824, -2.1408, -1.1343],\n",
      "         ...,\n",
      "         [ 1.0466, -0.4148,  0.9879,  ..., -3.2696, -2.7246, -1.9769],\n",
      "         [-0.2851, -1.2711,  2.0905,  ..., -2.8773, -0.2356, -1.7730],\n",
      "         [-1.7831, -1.5545, -0.7493,  ..., -2.4761, -1.0552,  0.2209]],\n",
      "\n",
      "        [[ 0.3176,  2.7139,  0.7471,  ...,  1.5208,  1.9381, -0.6266],\n",
      "         [ 1.5134,  1.1704,  1.2795,  ...,  0.7780, -2.2493,  1.0834],\n",
      "         [ 2.2045, -1.0707,  2.0946,  ..., -2.2302, -0.8920, -2.3272],\n",
      "         ...,\n",
      "         [ 2.7972, -0.5720,  0.0232,  ..., -1.3537, -0.6660,  0.3353],\n",
      "         [ 0.0983, -0.6602, -1.0689,  ...,  0.1309, -2.3917, -1.4828],\n",
      "         [ 0.3418, -2.6685,  1.4972,  ..., -1.9554, -3.5951, -1.4818]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 82, 64]) , torch.Size([512, 8, 82, 64]), torch.Size([512, 8, 82, 64])\n",
      "Score shape -- torch.Size([512, 8, 82, 82])\n",
      "Mask ---> torch.Size([512, 1, 82])\n",
      "Mask new --> torch.Size([512, 1, 1, 82])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 86, 64]) , torch.Size([512, 8, 86, 64]), torch.Size([512, 8, 86, 64])\n",
      "Score shape -- torch.Size([512, 8, 86, 86])\n",
      "Mask ---> torch.Size([512, 86, 86])\n",
      "Mask new --> torch.Size([512, 1, 86, 86])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 86, 64]) , torch.Size([512, 8, 82, 64]), torch.Size([512, 8, 82, 64])\n",
      "Score shape -- torch.Size([512, 8, 86, 82])\n",
      "Mask ---> torch.Size([512, 1, 82])\n",
      "Mask new --> torch.Size([512, 1, 1, 82])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 86, 64]) , torch.Size([512, 8, 86, 64]), torch.Size([512, 8, 86, 64])\n",
      "Score shape -- torch.Size([512, 8, 86, 86])\n",
      "Mask ---> torch.Size([512, 86, 86])\n",
      "Mask new --> torch.Size([512, 1, 86, 86])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 86, 64]) , torch.Size([512, 8, 82, 64]), torch.Size([512, 8, 82, 64])\n",
      "Score shape -- torch.Size([512, 8, 86, 82])\n",
      "Mask ---> torch.Size([512, 1, 82])\n",
      "Mask new --> torch.Size([512, 1, 1, 82])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 86, 64]) , torch.Size([512, 8, 86, 64]), torch.Size([512, 8, 86, 64])\n",
      "Score shape -- torch.Size([512, 8, 86, 86])\n",
      "Mask ---> torch.Size([512, 86, 86])\n",
      "Mask new --> torch.Size([512, 1, 86, 86])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 86, 64]) , torch.Size([512, 8, 82, 64]), torch.Size([512, 8, 82, 64])\n",
      "Score shape -- torch.Size([512, 8, 86, 82])\n",
      "Mask ---> torch.Size([512, 1, 82])\n",
      "Mask new --> torch.Size([512, 1, 1, 82])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 86, 64]) , torch.Size([512, 8, 86, 64]), torch.Size([512, 8, 86, 64])\n",
      "Score shape -- torch.Size([512, 8, 86, 86])\n",
      "Mask ---> torch.Size([512, 86, 86])\n",
      "Mask new --> torch.Size([512, 1, 86, 86])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 86, 64]) , torch.Size([512, 8, 82, 64]), torch.Size([512, 8, 82, 64])\n",
      "Score shape -- torch.Size([512, 8, 86, 82])\n",
      "Mask ---> torch.Size([512, 1, 82])\n",
      "Mask new --> torch.Size([512, 1, 1, 82])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 86, 64]) , torch.Size([512, 8, 86, 64]), torch.Size([512, 8, 86, 64])\n",
      "Score shape -- torch.Size([512, 8, 86, 86])\n",
      "Mask ---> torch.Size([512, 86, 86])\n",
      "Mask new --> torch.Size([512, 1, 86, 86])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 86, 64]) , torch.Size([512, 8, 82, 64]), torch.Size([512, 8, 82, 64])\n",
      "Score shape -- torch.Size([512, 8, 86, 82])\n",
      "Mask ---> torch.Size([512, 1, 82])\n",
      "Mask new --> torch.Size([512, 1, 1, 82])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 86, 64]) , torch.Size([512, 8, 86, 64]), torch.Size([512, 8, 86, 64])\n",
      "Score shape -- torch.Size([512, 8, 86, 86])\n",
      "Mask ---> torch.Size([512, 86, 86])\n",
      "Mask new --> torch.Size([512, 1, 86, 86])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 86, 64]) , torch.Size([512, 8, 82, 64]), torch.Size([512, 8, 82, 64])\n",
      "Score shape -- torch.Size([512, 8, 86, 82])\n",
      "Mask ---> torch.Size([512, 1, 82])\n",
      "Mask new --> torch.Size([512, 1, 1, 82])\n",
      "predictions size : tensor([[ 0.5184,  0.0149,  0.5647,  ..., -0.0255, -0.1300,  0.0728],\n",
      "        [ 0.2517,  0.0533,  0.2760,  ...,  0.1810, -0.4616, -0.1884],\n",
      "        [ 0.2029, -0.2104,  0.3014,  ...,  0.0061, -0.7376, -0.1804],\n",
      "        ...,\n",
      "        [ 0.4390,  0.3134,  0.2636,  ...,  0.0440, -0.3168,  0.0783],\n",
      "        [ 0.5509,  0.3216,  0.3619,  ..., -0.1462, -0.1955, -0.0551],\n",
      "        [ 0.5730, -0.0895,  0.4219,  ..., -0.1906, -0.1511,  0.1150]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "targets size : torch.Size([44032])\n",
      "Loss.data ----> = 9.274407386779785\n",
      "--Encoder x after PE : tensor([[[-0.5392,  1.2745, -0.2396,  ...,  1.1090,  0.6122,  1.4040],\n",
      "         [ 0.9505,  0.0000,  0.8651,  ...,  1.3705, -0.4923,  1.0330],\n",
      "         [ 0.8370, -1.0167,  0.7137,  ...,  0.0000,  0.1588,  1.1652],\n",
      "         ...,\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2549,  0.2458,  1.6227,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.3794,  0.0000,  0.8033,  ...,  1.0595,  0.0000,  0.5406]],\n",
      "\n",
      "        [[ 0.5728,  1.2739,  0.1811,  ...,  0.8918, -0.2585,  0.5620],\n",
      "         [ 0.7384,  0.0923,  0.5207,  ...,  0.0000,  0.0134,  1.5796],\n",
      "         [ 1.0543, -0.9073,  0.5850,  ...,  1.4878,  0.4076,  1.7705],\n",
      "         ...,\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2549,  0.0000,  1.6227,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.3794,  0.8800,  0.8033,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.3059,  1.3000,  0.2898,  ...,  1.0278,  0.2005,  1.2486],\n",
      "         [ 1.0426,  0.6268,  1.4408,  ...,  1.3351,  0.4430,  0.5859],\n",
      "         [ 1.3736, -0.7865,  1.6771,  ...,  0.8368,  0.2607,  1.3549],\n",
      "         ...,\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0000,  0.2458,  0.0000,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.3794,  0.8800,  0.8033,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.4262,  1.3606, -0.2182,  ...,  0.8971,  0.2762,  1.6336],\n",
      "         [ 0.7617,  0.0061,  0.5402,  ...,  1.2132,  0.0000,  1.1652],\n",
      "         [ 0.4517, -0.6294,  1.4396,  ...,  1.6042,  0.5631,  1.0780],\n",
      "         ...,\n",
      "         [ 1.2172, -0.7834,  0.0000,  ...,  0.0000,  0.1775,  0.0000],\n",
      "         [ 1.2549,  0.2458,  1.6227,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.3794,  0.8800,  0.8033,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.5728,  1.2739,  0.1811,  ...,  0.8918, -0.2585,  0.5620],\n",
      "         [ 0.7533,  0.0220,  1.0582,  ...,  1.7544,  0.0350,  1.6472],\n",
      "         [ 0.0000, -0.0000,  1.1113,  ...,  1.7435,  0.0039,  0.0000],\n",
      "         ...,\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2549,  0.2458,  1.6227,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [ 0.3794,  0.8800,  0.8033,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.5462,  1.2344,  0.1622,  ...,  0.9307, -0.0000,  1.6993],\n",
      "         [ 0.3508,  0.9983,  0.4312,  ...,  1.1099,  0.0709,  1.2154],\n",
      "         [ 1.3736, -0.7865,  1.6771,  ...,  0.8368,  0.2607,  1.3549],\n",
      "         ...,\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2549,  0.2458,  1.6227,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [ 0.3794,  0.8800,  0.8033,  ...,  0.0000,  0.1775,  0.5406]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "loop within encoder. Iteration -- 0\n",
      "this is x in EncoderLayer-----> tensor([[[-0.5392,  1.2745, -0.2396,  ...,  1.1090,  0.6122,  1.4040],\n",
      "         [ 0.9505,  0.0000,  0.8651,  ...,  1.3705, -0.4923,  1.0330],\n",
      "         [ 0.8370, -1.0167,  0.7137,  ...,  0.0000,  0.1588,  1.1652],\n",
      "         ...,\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2549,  0.2458,  1.6227,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.3794,  0.0000,  0.8033,  ...,  1.0595,  0.0000,  0.5406]],\n",
      "\n",
      "        [[ 0.5728,  1.2739,  0.1811,  ...,  0.8918, -0.2585,  0.5620],\n",
      "         [ 0.7384,  0.0923,  0.5207,  ...,  0.0000,  0.0134,  1.5796],\n",
      "         [ 1.0543, -0.9073,  0.5850,  ...,  1.4878,  0.4076,  1.7705],\n",
      "         ...,\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2549,  0.0000,  1.6227,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.3794,  0.8800,  0.8033,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.3059,  1.3000,  0.2898,  ...,  1.0278,  0.2005,  1.2486],\n",
      "         [ 1.0426,  0.6268,  1.4408,  ...,  1.3351,  0.4430,  0.5859],\n",
      "         [ 1.3736, -0.7865,  1.6771,  ...,  0.8368,  0.2607,  1.3549],\n",
      "         ...,\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0000,  0.2458,  0.0000,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.3794,  0.8800,  0.8033,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.4262,  1.3606, -0.2182,  ...,  0.8971,  0.2762,  1.6336],\n",
      "         [ 0.7617,  0.0061,  0.5402,  ...,  1.2132,  0.0000,  1.1652],\n",
      "         [ 0.4517, -0.6294,  1.4396,  ...,  1.6042,  0.5631,  1.0780],\n",
      "         ...,\n",
      "         [ 1.2172, -0.7834,  0.0000,  ...,  0.0000,  0.1775,  0.0000],\n",
      "         [ 1.2549,  0.2458,  1.6227,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.3794,  0.8800,  0.8033,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.5728,  1.2739,  0.1811,  ...,  0.8918, -0.2585,  0.5620],\n",
      "         [ 0.7533,  0.0220,  1.0582,  ...,  1.7544,  0.0350,  1.6472],\n",
      "         [ 0.0000, -0.0000,  1.1113,  ...,  1.7435,  0.0039,  0.0000],\n",
      "         ...,\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2549,  0.2458,  1.6227,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [ 0.3794,  0.8800,  0.8033,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.5462,  1.2344,  0.1622,  ...,  0.9307, -0.0000,  1.6993],\n",
      "         [ 0.3508,  0.9983,  0.4312,  ...,  1.1099,  0.0709,  1.2154],\n",
      "         [ 1.3736, -0.7865,  1.6771,  ...,  0.8368,  0.2607,  1.3549],\n",
      "         ...,\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2549,  0.2458,  1.6227,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [ 0.3794,  0.8800,  0.8033,  ...,  0.0000,  0.1775,  0.5406]]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 92])\n",
      "Mask ---> torch.Size([512, 1, 92])\n",
      "Mask new --> torch.Size([512, 1, 1, 92])\n",
      "loop within encoder. Iteration -- 1\n",
      "this is x in EncoderLayer-----> tensor([[[-2.5324,  3.7967,  0.0216,  ...,  0.1651,  1.2800,  0.3328],\n",
      "         [-0.2523,  2.2308,  1.2020,  ..., -0.2065,  1.0067,  0.0549],\n",
      "         [ 1.6817, -0.0502,  0.7137,  ...,  0.4918,  1.3011,  0.5103],\n",
      "         ...,\n",
      "         [-0.0726,  0.3920,  2.4521,  ..., -0.1285,  1.1017, -0.8300],\n",
      "         [-0.0763,  2.1565,  2.3440,  ..., -0.8168,  0.0890, -0.9893],\n",
      "         [-0.9927,  2.3537,  0.8408,  ..., -0.2144,  1.4347, -0.3247]],\n",
      "\n",
      "        [[-0.8982,  2.7631,  1.0055,  ..., -0.0910,  0.8583,  0.5200],\n",
      "         [ 0.1012,  1.8462,  1.1131,  ..., -1.1167,  0.2531,  0.8317],\n",
      "         [-0.3562,  1.0680,  1.5284,  ..., -0.5806,  1.5817,  1.5641],\n",
      "         ...,\n",
      "         [-0.0596,  1.1810,  2.2705,  ..., -0.0638,  1.4483, -0.6495],\n",
      "         [ 1.3244,  2.3790,  2.2389,  ..., -0.7699,  1.4851, -1.2131],\n",
      "         [-0.6287,  2.4644,  1.6726,  ...,  0.4651,  1.2959, -0.9529]],\n",
      "\n",
      "        [[-0.0864,  3.8529,  0.4710,  ...,  1.2670,  2.1021,  0.3898],\n",
      "         [ 0.0079,  2.6915,  1.6299,  ..., -0.5082,  0.8561, -0.3629],\n",
      "         [ 0.4624,  1.5802,  1.5928,  ..., -1.3222,  2.1525,  1.3549],\n",
      "         ...,\n",
      "         [ 0.5492,  1.8524,  2.0638,  ..., -1.0167,  2.2058, -0.8679],\n",
      "         [ 1.2071,  2.9474,  0.5760,  ..., -0.0417,  1.3158, -0.8522],\n",
      "         [-0.7785,  3.4142,  1.8986,  ..., -0.8837,  1.9711, -0.9189]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.0439,  2.2064,  0.7507,  ..., -0.2511,  2.1121,  0.7337],\n",
      "         [-0.4102,  2.1752,  0.3623,  ...,  0.1560,  1.9744,  0.7850],\n",
      "         [-0.4116,  1.0842,  2.1820,  ...,  0.1915,  2.2365,  0.2416],\n",
      "         ...,\n",
      "         [ 0.0964,  1.6910,  0.4917,  ..., -1.3931,  2.1219, -0.9888],\n",
      "         [ 0.2773,  2.7566,  2.4378,  ...,  0.8804,  1.4428, -0.8936],\n",
      "         [-0.3512,  3.2518,  1.5005,  ..., -1.1415,  0.1943, -0.6995]],\n",
      "\n",
      "        [[-0.7993,  3.7345,  0.9896,  ..., -0.7084,  0.6779, -0.6373],\n",
      "         [-0.9479,  1.8089,  1.3752,  ...,  1.0640,  1.2661, -0.1248],\n",
      "         [-1.6214,  1.3979,  1.5652,  ...,  1.0325,  1.0432, -0.2330],\n",
      "         ...,\n",
      "         [ 0.0251,  1.0420,  1.8417,  ..., -0.5046,  1.6980, -0.2806],\n",
      "         [ 0.0802,  1.4022,  1.5991,  ..., -0.4639,  0.7210, -1.4460],\n",
      "         [-1.1950,  2.7650,  1.9992,  ...,  0.0623,  1.0350,  0.4861]],\n",
      "\n",
      "        [[-0.7966,  2.3794,  0.0322,  ...,  0.0861,  2.6082,  1.2160],\n",
      "         [-1.0913,  2.1396,  0.5670,  ..., -0.6545,  2.1183,  0.6766],\n",
      "         [ 0.2562,  0.4201,  1.7283,  ..., -0.1367,  2.4747,  0.2239],\n",
      "         ...,\n",
      "         [-0.4393,  0.8706,  2.0781,  ..., -0.9444,  1.4447,  0.4228],\n",
      "         [ 0.6857,  2.3241,  2.5451,  ..., -0.4147,  0.9097,  0.4258],\n",
      "         [-0.4650,  2.3033,  1.7660,  ..., -0.8665,  0.6609,  0.3563]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 92])\n",
      "Mask ---> torch.Size([512, 1, 92])\n",
      "Mask new --> torch.Size([512, 1, 1, 92])\n",
      "loop within encoder. Iteration -- 2\n",
      "this is x in EncoderLayer-----> tensor([[[-2.2191e+00,  3.4807e+00, -6.0752e-01,  ..., -1.5183e+00,\n",
      "           1.6658e+00, -7.5816e-01],\n",
      "         [ 7.1408e-01,  2.1782e+00,  2.2109e+00,  ..., -1.6016e+00,\n",
      "           1.0138e+00, -8.5201e-01],\n",
      "         [ 2.7278e+00,  6.0366e-01,  1.0143e+00,  ..., -1.0119e+00,\n",
      "           9.5383e-01,  1.0092e-01],\n",
      "         ...,\n",
      "         [ 1.5640e-01,  5.5358e-01,  1.9865e+00,  ..., -1.4950e+00,\n",
      "           9.7555e-01, -1.2484e+00],\n",
      "         [ 2.1905e-01,  2.4444e+00,  2.8788e+00,  ..., -1.9152e+00,\n",
      "           1.1244e-01, -1.3253e+00],\n",
      "         [-7.1270e-01,  3.1130e+00,  4.0280e-01,  ..., -2.0938e+00,\n",
      "           1.2388e+00, -9.3730e-01]],\n",
      "\n",
      "        [[-3.3067e-03,  2.6457e+00,  9.9062e-01,  ..., -1.9287e+00,\n",
      "           9.3717e-01,  1.0620e-01],\n",
      "         [ 4.7738e-01,  2.5026e+00,  1.2546e+00,  ..., -3.0164e+00,\n",
      "           6.6190e-01,  1.0452e-01],\n",
      "         [-1.6938e-02,  1.2644e+00,  9.5633e-01,  ..., -1.7091e+00,\n",
      "           1.7881e+00,  7.2573e-01],\n",
      "         ...,\n",
      "         [-7.9586e-02,  1.2993e+00,  2.2077e+00,  ..., -1.1816e+00,\n",
      "           1.9733e+00, -1.2888e+00],\n",
      "         [ 1.4206e+00,  1.7214e+00,  1.6880e+00,  ..., -2.5101e+00,\n",
      "           2.3793e+00, -1.8493e+00],\n",
      "         [-1.2789e-01,  2.3421e+00,  1.1811e+00,  ..., -9.5605e-01,\n",
      "           1.6547e+00, -1.3652e+00]],\n",
      "\n",
      "        [[ 8.8691e-01,  4.0438e+00,  1.6901e+00,  ..., -1.0279e+00,\n",
      "           2.1301e+00,  3.8975e-01],\n",
      "         [ 1.0438e+00,  2.5732e+00,  2.0869e+00,  ..., -2.3001e+00,\n",
      "           3.8183e-01, -1.6733e+00],\n",
      "         [ 1.2250e+00,  1.7589e+00,  3.0632e+00,  ..., -3.6325e+00,\n",
      "           2.2262e+00, -2.7048e-01],\n",
      "         ...,\n",
      "         [ 1.3114e+00,  1.8524e+00,  2.7015e+00,  ..., -2.8295e+00,\n",
      "           2.6020e+00, -1.8727e+00],\n",
      "         [ 2.1402e+00,  3.1593e+00,  2.1858e+00,  ..., -2.2616e+00,\n",
      "           1.5658e+00, -1.8345e+00],\n",
      "         [-5.3146e-02,  3.9398e+00,  2.3445e+00,  ..., -3.0768e+00,\n",
      "           1.9094e+00, -2.4761e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.9767e-02,  1.4691e+00,  1.6120e+00,  ..., -7.8064e-01,\n",
      "           2.3079e+00, -5.5603e-01],\n",
      "         [ 2.3002e-01,  2.4411e+00,  2.1829e+00,  ..., -1.2125e+00,\n",
      "           2.3749e+00,  7.8499e-01],\n",
      "         [ 5.2772e-01,  7.7215e-01,  2.5884e+00,  ..., -4.7686e-01,\n",
      "           2.2326e+00, -1.1962e+00],\n",
      "         ...,\n",
      "         [ 1.1565e-01,  1.1030e+00,  1.1802e+00,  ..., -3.3352e+00,\n",
      "           2.3151e+00, -1.8544e+00],\n",
      "         [ 1.5617e+00,  3.0577e+00,  2.8681e+00,  ..., -9.6581e-01,\n",
      "           1.5226e+00, -1.5850e+00],\n",
      "         [ 1.7144e-01,  3.3556e+00,  2.1256e+00,  ..., -2.4138e+00,\n",
      "           7.5898e-01, -1.6160e+00]],\n",
      "\n",
      "        [[-5.4313e-02,  4.0288e+00,  1.7394e+00,  ..., -1.7770e+00,\n",
      "           6.0365e-01, -1.9582e+00],\n",
      "         [-1.9151e-01,  2.9272e+00,  1.4634e+00,  ...,  1.0737e+00,\n",
      "           7.4054e-01, -1.1325e+00],\n",
      "         [-7.8799e-01,  1.9380e+00,  2.1358e+00,  ...,  3.0014e-01,\n",
      "           1.0024e+00, -1.6297e+00],\n",
      "         ...,\n",
      "         [ 1.5751e-01,  1.4191e+00,  1.2505e+00,  ..., -1.5946e+00,\n",
      "           1.2098e+00, -1.6630e+00],\n",
      "         [ 5.7501e-01,  2.1271e+00,  1.8727e+00,  ..., -2.0440e+00,\n",
      "           3.4938e-01, -2.9380e+00],\n",
      "         [-6.7225e-01,  2.6487e+00,  1.1234e+00,  ..., -4.1026e-01,\n",
      "           4.0482e-01, -3.2141e-02]],\n",
      "\n",
      "        [[-2.1635e-01,  2.2840e+00, -1.6890e-01,  ..., -2.1065e+00,\n",
      "           2.8556e+00, -1.3645e+00],\n",
      "         [ 2.7165e-01,  1.6135e+00,  4.4241e-01,  ..., -3.1181e+00,\n",
      "           2.5623e+00, -1.4000e+00],\n",
      "         [ 1.6381e+00, -5.9100e-01,  1.0248e+00,  ..., -2.8199e+00,\n",
      "           2.3437e+00, -1.6596e+00],\n",
      "         ...,\n",
      "         [-1.0867e-01, -1.1190e-01,  1.7739e+00,  ..., -2.6828e+00,\n",
      "           6.8950e-01, -1.5615e+00],\n",
      "         [ 1.8579e+00,  1.4089e+00,  1.8122e+00,  ..., -2.1539e+00,\n",
      "          -2.2978e-01, -1.5227e+00],\n",
      "         [-2.2571e-01,  1.6665e+00,  1.3823e+00,  ..., -3.7762e+00,\n",
      "           1.4301e-01, -1.0442e+00]]], grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 92])\n",
      "Mask ---> torch.Size([512, 1, 92])\n",
      "Mask new --> torch.Size([512, 1, 1, 92])\n",
      "loop within encoder. Iteration -- 3\n",
      "this is x in EncoderLayer-----> tensor([[[-1.2248,  3.9066, -0.1066,  ..., -2.7550,  0.0578, -2.1167],\n",
      "         [ 1.8706,  2.3330,  2.7382,  ..., -3.5163, -1.1366, -2.9214],\n",
      "         [ 3.4092,  1.7304,  0.9500,  ..., -2.8641, -0.1180, -1.5504],\n",
      "         ...,\n",
      "         [ 1.3656,  1.2227,  2.7694,  ..., -3.0617, -0.5228, -1.8959],\n",
      "         [ 0.4661,  2.5428,  3.3079,  ..., -3.9655, -2.2590, -2.2514],\n",
      "         [ 0.3845,  3.6002,  0.6977,  ..., -3.8668,  0.1552, -0.9373]],\n",
      "\n",
      "        [[ 0.3441,  3.2375,  0.6142,  ..., -3.4632,  0.0668, -1.3571],\n",
      "         [ 1.6014,  3.0088,  1.1596,  ..., -4.8081, -0.4345, -1.1237],\n",
      "         [ 1.4308,  1.4349,  1.4133,  ..., -2.8124,  0.2652, -0.8514],\n",
      "         ...,\n",
      "         [ 1.2341,  1.4777,  2.4858,  ..., -2.8017, -0.1229, -1.9179],\n",
      "         [ 2.4652,  1.7567,  1.7830,  ..., -2.5101,  0.7516, -2.3793],\n",
      "         [ 0.3066,  1.9635,  1.2426,  ..., -2.7930,  1.2939, -1.9998]],\n",
      "\n",
      "        [[ 1.3165,  4.8694,  1.7172,  ..., -2.3782,  0.7059,  0.0914],\n",
      "         [ 2.6974,  3.2262,  2.3078,  ..., -3.6754, -0.2935, -2.2092],\n",
      "         [ 2.0373,  2.4692,  3.3856,  ..., -5.2836,  1.1657,  0.1311],\n",
      "         ...,\n",
      "         [ 2.1871,  2.4421,  3.6320,  ..., -4.2101,  0.8192, -1.5306],\n",
      "         [ 3.1589,  3.2368,  3.2476,  ..., -3.3395, -0.1022, -1.5505],\n",
      "         [ 1.7731,  4.1557,  2.6783,  ..., -4.6396, -0.1188, -2.7222]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2345,  1.3494,  2.0926,  ..., -2.7030,  0.1688, -0.4263],\n",
      "         [ 0.3206,  3.0583,  2.7933,  ..., -2.8588,  0.3537,  0.3832],\n",
      "         [ 0.5971,  1.0735,  2.7988,  ..., -1.6472,  2.0774, -1.7451],\n",
      "         ...,\n",
      "         [ 0.3786,  1.7410,  2.0638,  ..., -4.6539, -0.0148, -2.1383],\n",
      "         [ 2.3865,  3.2707,  3.5442,  ..., -3.3731,  0.0488, -1.7344],\n",
      "         [ 1.1923,  3.6969,  2.6323,  ..., -4.1812, -1.1060, -2.1467]],\n",
      "\n",
      "        [[ 1.2887,  5.0830,  2.1293,  ..., -3.4404, -0.7049, -3.2064],\n",
      "         [ 0.5466,  3.9367,  1.6653,  ..., -0.8142, -0.7511, -2.9304],\n",
      "         [-0.7799,  2.0968,  2.0271,  ..., -0.9609, -0.5273, -3.1003],\n",
      "         ...,\n",
      "         [ 0.8908,  1.1043,  2.0138,  ..., -2.5109, -0.5481, -2.7726],\n",
      "         [ 1.6248,  2.1404,  2.3659,  ..., -4.3125, -2.4019, -3.5281],\n",
      "         [-0.0427,  2.7315,  1.2808,  ..., -2.5238, -1.7830, -0.9695]],\n",
      "\n",
      "        [[-0.1292,  3.0293, -1.3880,  ..., -4.6643,  0.7952, -1.7913],\n",
      "         [ 1.1183,  1.9194,  0.3745,  ..., -5.0579,  0.9453, -1.3931],\n",
      "         [ 3.0937, -0.6565,  0.8930,  ..., -5.2170,  1.0382, -2.0633],\n",
      "         ...,\n",
      "         [ 0.2337,  0.4314,  1.7336,  ..., -4.5410, -1.5583, -1.3001],\n",
      "         [ 2.7993,  2.3355,  2.1393,  ..., -4.8335, -2.5857, -1.5894],\n",
      "         [-0.2257,  2.5329,  0.7440,  ..., -5.5872, -2.3901, -0.8443]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 92])\n",
      "Mask ---> torch.Size([512, 1, 92])\n",
      "Mask new --> torch.Size([512, 1, 1, 92])\n",
      "loop within encoder. Iteration -- 4\n",
      "this is x in EncoderLayer-----> tensor([[[-1.1884,  5.1994,  0.1242,  ..., -3.6180, -1.2333, -2.5598],\n",
      "         [ 1.5916,  2.8187,  1.3063,  ..., -4.1959, -1.9222, -3.3988],\n",
      "         [ 3.3879,  3.3241, -0.2021,  ..., -3.9558, -0.1180, -3.2054],\n",
      "         ...,\n",
      "         [ 1.3802,  1.4840,  0.7675,  ..., -3.8833, -1.3094, -2.0298],\n",
      "         [ 0.4350,  2.9146,  2.1709,  ..., -4.7154, -3.6078, -2.8101],\n",
      "         [-0.1253,  4.4905, -1.2041,  ..., -4.4684, -0.4421, -0.9889]],\n",
      "\n",
      "        [[-0.2393,  4.2441, -0.2232,  ..., -4.4183, -0.4282, -2.1799],\n",
      "         [ 1.0243,  3.6881, -0.1542,  ..., -5.6110, -1.0574, -2.0070],\n",
      "         [ 1.0418,  1.5724,  0.4145,  ..., -3.3089,  0.1020, -1.5662],\n",
      "         ...,\n",
      "         [ 0.6121,  2.1321,  0.8328,  ..., -3.2397, -1.1421, -2.5825],\n",
      "         [ 2.5433,  2.4656,  0.7334,  ..., -3.4610,  0.0756, -2.5445],\n",
      "         [-0.4493,  2.8230, -0.2284,  ..., -3.4925,  1.2939, -2.6103]],\n",
      "\n",
      "        [[ 1.3847,  6.0353, -0.1609,  ..., -3.4333, -0.0844, -0.3001],\n",
      "         [ 2.7738,  4.5082,  1.0230,  ..., -4.5152, -1.2855, -1.6497],\n",
      "         [ 2.0812,  3.6346,  2.7669,  ..., -6.1299,  0.3639,  1.1151],\n",
      "         ...,\n",
      "         [ 1.9264,  3.5333,  1.8520,  ..., -3.9467, -0.1737, -1.4740],\n",
      "         [ 3.0882,  4.0473,  1.2972,  ..., -3.6436, -1.5292, -0.3512],\n",
      "         [ 2.2053,  4.6787, -0.1835,  ..., -5.3939, -1.1318, -2.3066]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0669,  2.1971,  2.0487,  ..., -2.9035, -0.3491, -0.7440],\n",
      "         [-0.5772,  3.9260,  1.6260,  ..., -4.4399, -0.3317, -0.4584],\n",
      "         [ 1.0253,  1.5479,  1.3788,  ..., -2.3524,  2.2707, -2.5593],\n",
      "         ...,\n",
      "         [ 1.2361,  2.9451,  0.4362,  ..., -5.5508,  0.1764, -2.1821],\n",
      "         [ 1.8951,  3.6368,  1.7156,  ..., -4.1305,  0.4465, -1.4301],\n",
      "         [ 0.7289,  4.0854,  1.2840,  ..., -4.6364, -1.0033, -2.7962]],\n",
      "\n",
      "        [[ 0.7611,  5.7769,  0.5648,  ..., -5.0187, -1.7042, -4.3361],\n",
      "         [ 0.5466,  4.6212,  1.3271,  ..., -1.6370, -1.3383, -3.3046],\n",
      "         [-0.6231,  3.5347,  1.0042,  ..., -1.7622, -1.6569, -3.9609],\n",
      "         ...,\n",
      "         [ 0.6421,  1.9899,  0.4196,  ..., -3.8724, -0.1809, -2.9918],\n",
      "         [ 1.6647,  2.8790,  0.4251,  ..., -4.2994, -3.2293, -4.0707],\n",
      "         [-0.0222,  3.0309, -0.4253,  ..., -4.1142, -2.3475, -1.2594]],\n",
      "\n",
      "        [[-1.1814,  4.5431, -3.2192,  ..., -5.2960, -0.2315, -2.2771],\n",
      "         [ 0.3078,  3.2904, -0.5186,  ..., -4.9547,  1.4692, -0.9420],\n",
      "         [ 2.5789,  1.0776, -1.3158,  ..., -5.9681,  0.8763, -2.9543],\n",
      "         ...,\n",
      "         [-0.3027,  2.4258,  0.7559,  ..., -5.4619, -2.2468, -1.3222],\n",
      "         [ 1.9949,  3.9402,  0.3151,  ..., -5.4836, -3.1914, -1.4362],\n",
      "         [-1.0965,  5.1084, -1.1303,  ..., -5.8578, -3.1802, -0.7449]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 92])\n",
      "Mask ---> torch.Size([512, 1, 92])\n",
      "Mask new --> torch.Size([512, 1, 1, 92])\n",
      "loop within encoder. Iteration -- 5\n",
      "this is x in EncoderLayer-----> tensor([[[ 3.9590e-01,  2.6666e+00, -5.8449e-01,  ..., -3.5515e+00,\n",
      "          -2.3346e+00, -1.5206e+00],\n",
      "         [ 2.8388e+00, -4.0700e-01,  1.0426e+00,  ..., -3.2337e+00,\n",
      "          -3.1176e+00, -2.0966e+00],\n",
      "         [ 4.6714e+00,  4.2134e-01, -4.2898e-01,  ..., -3.1853e+00,\n",
      "          -9.4118e-01, -2.1526e+00],\n",
      "         ...,\n",
      "         [ 1.9155e+00,  4.3959e-01,  4.1155e-01,  ..., -3.7071e+00,\n",
      "          -2.6264e+00, -1.3968e+00],\n",
      "         [ 9.2419e-01, -4.2772e-02,  2.2240e+00,  ..., -4.5069e+00,\n",
      "          -4.8491e+00, -2.4080e+00],\n",
      "         [ 1.1203e+00,  2.4501e+00, -1.5947e+00,  ..., -3.8004e+00,\n",
      "          -1.1246e+00,  4.3203e-01]],\n",
      "\n",
      "        [[ 3.6414e-01,  1.1064e+00, -3.4721e-01,  ..., -4.2645e+00,\n",
      "          -1.5097e+00, -1.1335e+00],\n",
      "         [ 2.1965e+00,  6.7491e-01,  3.2489e-01,  ..., -4.3534e+00,\n",
      "          -1.9790e+00, -1.3981e+00],\n",
      "         [ 2.7737e+00,  3.4093e-01,  6.0224e-01,  ..., -3.3780e+00,\n",
      "          -1.3301e+00, -1.2134e-01],\n",
      "         ...,\n",
      "         [ 2.0309e+00, -1.2216e-01,  1.9143e+00,  ..., -2.3763e+00,\n",
      "          -2.0185e+00, -1.6245e+00],\n",
      "         [ 3.9560e+00,  9.9961e-01,  6.2499e-01,  ..., -3.4756e+00,\n",
      "           5.5816e-01, -2.0254e+00],\n",
      "         [ 1.1660e-02,  6.6271e-01, -1.5179e-01,  ..., -2.6718e+00,\n",
      "           4.0389e-02, -2.2995e+00]],\n",
      "\n",
      "        [[ 3.0006e+00,  5.0403e+00, -1.9673e-02,  ..., -2.7526e+00,\n",
      "          -1.3347e+00,  9.4738e-01],\n",
      "         [ 3.9863e+00,  2.9557e+00,  9.7765e-01,  ..., -4.1838e+00,\n",
      "          -2.7749e+00, -2.6459e-01],\n",
      "         [ 3.7349e+00,  1.0183e+00,  2.0924e+00,  ..., -5.2926e+00,\n",
      "          -6.4935e-01,  3.0587e+00],\n",
      "         ...,\n",
      "         [ 3.8062e+00,  1.9584e-01,  9.1315e-01,  ..., -2.9954e+00,\n",
      "          -1.2716e+00,  3.7944e-01],\n",
      "         [ 5.7918e+00,  3.4682e+00,  4.2598e-01,  ..., -3.4005e+00,\n",
      "          -2.4286e+00,  1.6739e+00],\n",
      "         [ 3.2081e+00,  2.1265e+00, -1.4967e+00,  ..., -5.2750e+00,\n",
      "          -2.3677e+00, -7.6642e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 6.1024e-01,  1.0060e+00,  1.4696e+00,  ..., -2.2127e+00,\n",
      "          -2.3266e+00,  9.2583e-01],\n",
      "         [ 3.1316e-01,  2.0994e+00,  1.0728e+00,  ..., -4.0271e+00,\n",
      "          -1.9697e+00,  5.5183e-01],\n",
      "         [ 1.8635e+00, -1.0824e+00,  6.5257e-01,  ..., -2.2192e+00,\n",
      "           1.1429e+00, -1.2118e+00],\n",
      "         ...,\n",
      "         [ 1.7746e+00, -2.2306e-01, -5.4989e-01,  ..., -5.2250e+00,\n",
      "          -1.3124e+00, -1.5304e+00],\n",
      "         [ 2.5761e+00,  2.2288e+00,  1.0357e+00,  ..., -3.4875e+00,\n",
      "          -1.2578e+00, -3.0323e-01],\n",
      "         [ 1.5949e+00,  1.5739e+00,  1.1218e-01,  ..., -4.0097e+00,\n",
      "          -2.4631e+00, -2.0512e+00]],\n",
      "\n",
      "        [[ 2.2235e+00,  2.6164e+00,  1.0443e+00,  ..., -4.6454e+00,\n",
      "          -3.3898e+00, -3.4026e+00],\n",
      "         [ 1.6238e+00,  1.7330e+00,  1.8738e+00,  ..., -1.2103e+00,\n",
      "          -2.4124e+00, -2.1680e+00],\n",
      "         [-5.0743e-01,  6.6111e-01,  5.2185e-01,  ..., -1.4350e+00,\n",
      "          -3.0743e+00, -2.5954e+00],\n",
      "         ...,\n",
      "         [ 1.8653e+00, -9.4818e-01, -1.5259e-01,  ..., -3.5529e+00,\n",
      "          -1.6582e+00, -1.3108e+00],\n",
      "         [ 2.7990e+00,  1.3109e+00,  7.9364e-02,  ..., -4.0247e+00,\n",
      "          -4.8316e+00, -2.6656e+00],\n",
      "         [ 5.0734e-01,  3.5160e-01,  5.5955e-02,  ..., -3.7903e+00,\n",
      "          -3.6600e+00, -6.5645e-01]],\n",
      "\n",
      "        [[ 1.8104e-01,  2.9064e+00, -3.0088e+00,  ..., -4.8444e+00,\n",
      "          -1.0905e+00, -1.4539e-03],\n",
      "         [ 1.4044e+00,  1.0052e+00, -9.7465e-01,  ..., -4.2991e+00,\n",
      "           3.9601e-01,  1.0307e+00],\n",
      "         [ 3.6112e+00, -1.6924e+00, -5.8271e-01,  ..., -5.2092e+00,\n",
      "          -2.9423e-01, -3.1086e-01],\n",
      "         ...,\n",
      "         [ 7.3881e-01, -8.9070e-02,  5.1265e-01,  ..., -5.0540e+00,\n",
      "          -3.4746e+00,  9.2077e-01],\n",
      "         [ 2.3733e+00,  1.5702e+00, -3.2519e-01,  ..., -5.9065e+00,\n",
      "          -4.6450e+00,  6.9443e-01],\n",
      "         [-5.2668e-01,  2.4135e+00, -1.7880e+00,  ..., -5.8578e+00,\n",
      "          -4.2471e+00,  1.3311e+00]]], grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 92])\n",
      "Mask ---> torch.Size([512, 1, 92])\n",
      "Mask new --> torch.Size([512, 1, 1, 92])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 95, 64]) , torch.Size([512, 8, 95, 64]), torch.Size([512, 8, 95, 64])\n",
      "Score shape -- torch.Size([512, 8, 95, 95])\n",
      "Mask ---> torch.Size([512, 95, 95])\n",
      "Mask new --> torch.Size([512, 1, 95, 95])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 95, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 95, 92])\n",
      "Mask ---> torch.Size([512, 1, 92])\n",
      "Mask new --> torch.Size([512, 1, 1, 92])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 95, 64]) , torch.Size([512, 8, 95, 64]), torch.Size([512, 8, 95, 64])\n",
      "Score shape -- torch.Size([512, 8, 95, 95])\n",
      "Mask ---> torch.Size([512, 95, 95])\n",
      "Mask new --> torch.Size([512, 1, 95, 95])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 95, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 95, 92])\n",
      "Mask ---> torch.Size([512, 1, 92])\n",
      "Mask new --> torch.Size([512, 1, 1, 92])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 95, 64]) , torch.Size([512, 8, 95, 64]), torch.Size([512, 8, 95, 64])\n",
      "Score shape -- torch.Size([512, 8, 95, 95])\n",
      "Mask ---> torch.Size([512, 95, 95])\n",
      "Mask new --> torch.Size([512, 1, 95, 95])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 95, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 95, 92])\n",
      "Mask ---> torch.Size([512, 1, 92])\n",
      "Mask new --> torch.Size([512, 1, 1, 92])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 95, 64]) , torch.Size([512, 8, 95, 64]), torch.Size([512, 8, 95, 64])\n",
      "Score shape -- torch.Size([512, 8, 95, 95])\n",
      "Mask ---> torch.Size([512, 95, 95])\n",
      "Mask new --> torch.Size([512, 1, 95, 95])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 95, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 95, 92])\n",
      "Mask ---> torch.Size([512, 1, 92])\n",
      "Mask new --> torch.Size([512, 1, 1, 92])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 95, 64]) , torch.Size([512, 8, 95, 64]), torch.Size([512, 8, 95, 64])\n",
      "Score shape -- torch.Size([512, 8, 95, 95])\n",
      "Mask ---> torch.Size([512, 95, 95])\n",
      "Mask new --> torch.Size([512, 1, 95, 95])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 95, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 95, 92])\n",
      "Mask ---> torch.Size([512, 1, 92])\n",
      "Mask new --> torch.Size([512, 1, 1, 92])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 95, 64]) , torch.Size([512, 8, 95, 64]), torch.Size([512, 8, 95, 64])\n",
      "Score shape -- torch.Size([512, 8, 95, 95])\n",
      "Mask ---> torch.Size([512, 95, 95])\n",
      "Mask new --> torch.Size([512, 1, 95, 95])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 95, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 95, 92])\n",
      "Mask ---> torch.Size([512, 1, 92])\n",
      "Mask new --> torch.Size([512, 1, 1, 92])\n",
      "predictions size : tensor([[-3.7912e-01,  6.7344e-02,  4.0029e-01,  ..., -7.1557e-02,\n",
      "         -4.3867e-01,  1.4063e-03],\n",
      "        [-1.7180e-01,  1.1374e-01,  4.5881e-01,  ..., -2.3943e-01,\n",
      "         -2.7906e-01, -1.0106e-01],\n",
      "        [-9.8864e-02, -8.0130e-03,  3.7229e-01,  ...,  8.6806e-03,\n",
      "         -4.4259e-01, -1.4090e-01],\n",
      "        ...,\n",
      "        [-1.8642e-01, -2.9258e-01,  3.5053e-01,  ...,  4.5119e-05,\n",
      "         -1.0950e-01, -2.2979e-01],\n",
      "        [-2.0310e-01, -3.2525e-01,  3.1990e-01,  ...,  1.5252e-02,\n",
      "         -2.2850e-01, -2.7071e-01],\n",
      "        [-3.3316e-01, -2.1023e-01,  1.6539e-01,  ...,  1.0806e-01,\n",
      "         -2.4245e-01, -1.1793e-01]], grad_fn=<ViewBackward>)\n",
      "targets size : torch.Size([48640])\n",
      "Loss.data ----> = 8.897245407104492\n",
      "--Encoder x after PE : tensor([[[ 0.3524,  1.5930,  0.4210,  ...,  0.7243, -0.4160,  1.1252],\n",
      "         [ 0.7595,  0.0085,  0.5377,  ...,  0.0000,  0.0000,  1.1631],\n",
      "         [ 1.5820, -0.2258,  1.2482,  ...,  0.0000, -0.2560,  0.5599],\n",
      "         ...,\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.0000,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.6515, -0.9060, -0.0868,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.0199,  1.6904, -0.0454,  ...,  0.0000, -0.1493,  0.7934],\n",
      "         [ 0.0000,  0.0000,  1.5450,  ...,  1.5756,  0.2081,  1.6617],\n",
      "         [ 0.5660, -0.0159,  0.4586,  ...,  1.7487, -0.0000,  0.5747],\n",
      "         ...,\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.6515, -0.9060, -0.0000,  ...,  1.0595,  0.1775,  0.0000]],\n",
      "\n",
      "        [[ 0.5717,  1.2752,  0.1836,  ...,  0.8923, -0.2560,  0.5599],\n",
      "         [ 0.7513,  0.0000,  1.0582,  ...,  1.7537,  0.0372,  1.6452],\n",
      "         [ 0.8645, -0.0000,  1.1130,  ...,  1.7425,  0.0064,  1.3682],\n",
      "         ...,\n",
      "         [ 0.0000,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  0.0000,  0.1775,  0.5406],\n",
      "         [-0.6515, -0.0000, -0.0868,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0000,  0.8780,  0.2529,  ...,  0.8452, -0.0000,  1.0924],\n",
      "         [ 0.6812,  0.2319,  0.8099,  ...,  0.0000, -0.6067,  0.5431],\n",
      "         [ 0.4498, -0.6308,  1.4397,  ...,  1.6025,  0.5643,  1.0760],\n",
      "         ...,\n",
      "         [ 0.0660,  0.0000,  0.0581,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  0.0000,  0.1775,  0.5406],\n",
      "         [-0.6515, -0.9060, -0.0868,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.5064,  0.0000,  0.6577,  ...,  1.1539,  0.0416,  1.1738],\n",
      "         [ 0.4768,  0.9079,  1.1322,  ...,  1.3882,  0.4717,  0.9925],\n",
      "         [ 0.0000, -1.0144,  0.7113,  ...,  1.2131,  0.0000,  1.1631],\n",
      "         ...,\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  0.0000,  0.0000,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.6515, -0.9060, -0.0000,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.1709,  1.5343,  0.0648,  ...,  0.7025, -0.5887,  1.3097],\n",
      "         [ 0.3898,  0.9627,  1.0664,  ...,  1.3920, -0.0635,  1.5265],\n",
      "         [ 0.0000, -0.0361,  0.7251,  ...,  0.8567, -0.3143,  1.3239],\n",
      "         ...,\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.0000,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.6515, -0.9060, -0.0868,  ...,  1.0595,  0.1775,  0.5406]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "loop within encoder. Iteration -- 0\n",
      "this is x in EncoderLayer-----> tensor([[[ 0.3524,  1.5930,  0.4210,  ...,  0.7243, -0.4160,  1.1252],\n",
      "         [ 0.7595,  0.0085,  0.5377,  ...,  0.0000,  0.0000,  1.1631],\n",
      "         [ 1.5820, -0.2258,  1.2482,  ...,  0.0000, -0.2560,  0.5599],\n",
      "         ...,\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.0000,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.6515, -0.9060, -0.0868,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.0199,  1.6904, -0.0454,  ...,  0.0000, -0.1493,  0.7934],\n",
      "         [ 0.0000,  0.0000,  1.5450,  ...,  1.5756,  0.2081,  1.6617],\n",
      "         [ 0.5660, -0.0159,  0.4586,  ...,  1.7487, -0.0000,  0.5747],\n",
      "         ...,\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.6515, -0.9060, -0.0000,  ...,  1.0595,  0.1775,  0.0000]],\n",
      "\n",
      "        [[ 0.5717,  1.2752,  0.1836,  ...,  0.8923, -0.2560,  0.5599],\n",
      "         [ 0.7513,  0.0000,  1.0582,  ...,  1.7537,  0.0372,  1.6452],\n",
      "         [ 0.8645, -0.0000,  1.1130,  ...,  1.7425,  0.0064,  1.3682],\n",
      "         ...,\n",
      "         [ 0.0000,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  0.0000,  0.1775,  0.5406],\n",
      "         [-0.6515, -0.0000, -0.0868,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0000,  0.8780,  0.2529,  ...,  0.8452, -0.0000,  1.0924],\n",
      "         [ 0.6812,  0.2319,  0.8099,  ...,  0.0000, -0.6067,  0.5431],\n",
      "         [ 0.4498, -0.6308,  1.4397,  ...,  1.6025,  0.5643,  1.0760],\n",
      "         ...,\n",
      "         [ 0.0660,  0.0000,  0.0581,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  0.0000,  0.1775,  0.5406],\n",
      "         [-0.6515, -0.9060, -0.0868,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.5064,  0.0000,  0.6577,  ...,  1.1539,  0.0416,  1.1738],\n",
      "         [ 0.4768,  0.9079,  1.1322,  ...,  1.3882,  0.4717,  0.9925],\n",
      "         [ 0.0000, -1.0144,  0.7113,  ...,  1.2131,  0.0000,  1.1631],\n",
      "         ...,\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  0.0000,  0.0000,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.6515, -0.9060, -0.0000,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.1709,  1.5343,  0.0648,  ...,  0.7025, -0.5887,  1.3097],\n",
      "         [ 0.3898,  0.9627,  1.0664,  ...,  1.3920, -0.0635,  1.5265],\n",
      "         [ 0.0000, -0.0361,  0.7251,  ...,  0.8567, -0.3143,  1.3239],\n",
      "         ...,\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.0000,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.6515, -0.9060, -0.0868,  ...,  1.0595,  0.1775,  0.5406]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 88, 64]) , torch.Size([512, 8, 88, 64]), torch.Size([512, 8, 88, 64])\n",
      "Score shape -- torch.Size([512, 8, 88, 88])\n",
      "Mask ---> torch.Size([512, 1, 88])\n",
      "Mask new --> torch.Size([512, 1, 1, 88])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop within encoder. Iteration -- 1\n",
      "this is x in EncoderLayer-----> tensor([[[-0.9212,  2.9854,  0.7876,  ..., -0.2346,  0.7811, -0.0275],\n",
      "         [ 0.7595,  2.1049,  0.6342,  ...,  0.4106,  2.0050,  0.7623],\n",
      "         [-0.0246,  1.6343,  0.9550,  ..., -1.6762,  0.8438, -0.9817],\n",
      "         ...,\n",
      "         [-1.2049,  2.1306, -0.1078,  ..., -0.3383,  1.3275, -0.5474],\n",
      "         [-1.0445,  2.5198, -0.4640,  ..., -0.3621,  1.4420, -0.4822],\n",
      "         [-1.6986,  1.2432,  0.2937,  ..., -0.3456,  1.2754, -0.8856]],\n",
      "\n",
      "        [[-1.4204,  3.0450, -0.5899,  ..., -0.8554,  1.6811, -0.1548],\n",
      "         [-0.7509,  1.5633,  1.6354,  ...,  0.6904,  2.3747,  0.7515],\n",
      "         [-0.1989,  1.5467,  0.8351,  ...,  0.9388,  1.9755, -0.2252],\n",
      "         ...,\n",
      "         [-0.6955,  2.6723,  0.4140,  ..., -0.3296,  1.5581,  0.3699],\n",
      "         [-0.6544,  1.8320, -0.8550,  ..., -0.3681,  1.4773,  0.4093],\n",
      "         [-1.3406,  0.9330, -0.0635,  ..., -0.4743,  0.1170, -1.0938]],\n",
      "\n",
      "        [[ 0.7598,  3.3448,  0.0450,  ..., -1.0324,  1.1448,  0.4464],\n",
      "         [-0.6664,  1.1229,  0.7836,  ...,  0.0620,  2.1715,  0.8637],\n",
      "         [-0.6090,  1.9801,  0.7284,  ...,  1.0818,  2.6799,  0.8054],\n",
      "         ...,\n",
      "         [-1.0493,  2.6277,  0.5814,  ..., -0.0215,  1.7542,  0.0420],\n",
      "         [-0.9902,  2.1897, -0.7206,  ..., -1.6426,  1.9360,  0.0716],\n",
      "         [-2.0135,  1.8426, -0.0267,  ..., -0.4967,  2.0354, -0.0843]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.9265,  3.3665,  0.3660,  ...,  0.2576,  1.6658,  1.2221],\n",
      "         [-0.1936,  2.7011,  1.0636,  ...,  0.0000,  2.7754,  0.5476],\n",
      "         [ 1.2610,  0.7365,  2.0246,  ..., -0.2274,  2.9660,  1.0617],\n",
      "         ...,\n",
      "         [-1.4472,  2.9476,  0.1642,  ..., -0.1178,  2.1372, -0.4871],\n",
      "         [-1.3692,  2.5965, -0.4675,  ..., -1.8990,  0.9720, -0.1466],\n",
      "         [-1.3156,  1.4567, -0.3811,  ..., -0.4195,  1.9077, -0.4835]],\n",
      "\n",
      "        [[-1.8253,  2.1656,  1.0549,  ..., -0.0121,  0.8812,  0.6353],\n",
      "         [ 0.0430,  3.2669,  1.5655,  ...,  0.1009,  1.8322, -0.0127],\n",
      "         [ 0.0000,  0.9694,  0.4423,  ..., -0.0294,  1.5786,  0.0680],\n",
      "         ...,\n",
      "         [-0.6881,  2.5658,  0.6653,  ..., -1.3079,  1.4401,  0.5297],\n",
      "         [-2.1632,  1.8047, -0.3309,  ...,  1.1664,  0.5893, -0.1799],\n",
      "         [-1.8478,  1.2253, -0.2739,  ..., -0.2199,  1.6102, -0.2593]],\n",
      "\n",
      "        [[-0.9258,  3.1050, -0.5778,  ..., -0.5042,  1.2260,  0.8531],\n",
      "         [-0.9922,  1.4486,  1.2944,  ..., -0.7946,  2.1412,  1.1737],\n",
      "         [-1.1026,  1.9166,  0.2351,  ..., -0.3841,  1.3470, -0.3447],\n",
      "         ...,\n",
      "         [-0.6459,  1.5360,  0.3391,  ..., -0.3720,  1.3883, -0.5335],\n",
      "         [-2.0469,  1.7459, -0.0776,  ..., -1.0503,  0.5443, -0.9131],\n",
      "         [-2.2701,  0.7759,  0.0113,  ..., -0.6588,  1.3490, -0.6524]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 88, 64]) , torch.Size([512, 8, 88, 64]), torch.Size([512, 8, 88, 64])\n",
      "Score shape -- torch.Size([512, 8, 88, 88])\n",
      "Mask ---> torch.Size([512, 1, 88])\n",
      "Mask new --> torch.Size([512, 1, 1, 88])\n",
      "loop within encoder. Iteration -- 2\n",
      "this is x in EncoderLayer-----> tensor([[[-0.5540,  3.9395,  1.5733,  ..., -1.5389,  0.9015, -0.5883],\n",
      "         [ 1.4320,  3.1306,  1.1548,  ..., -1.0793,  1.9912,  0.3550],\n",
      "         [ 1.2147,  2.4633,  1.1314,  ..., -3.8428,  0.9502, -1.4577],\n",
      "         ...,\n",
      "         [-0.4544,  3.1966, -0.7802,  ..., -1.5995,  1.5506, -1.1557],\n",
      "         [-0.4466,  3.5750, -1.2860,  ..., -2.1490,  1.8223, -0.8142],\n",
      "         [-0.9903,  2.2467, -0.1648,  ..., -2.3461,  1.4498, -0.5825]],\n",
      "\n",
      "        [[-0.3751,  4.5146, -0.5194,  ..., -2.3648,  1.7348, -1.2730],\n",
      "         [ 0.1186,  2.6467,  2.5783,  ..., -0.3123,  1.9953, -0.1061],\n",
      "         [ 0.4379,  2.6280,  1.0201,  ..., -0.9058,  2.1011, -1.8745],\n",
      "         ...,\n",
      "         [-0.2480,  3.4592,  0.9361,  ..., -1.7812,  1.5255, -0.3794],\n",
      "         [-0.0222,  2.9327, -1.4455,  ..., -1.5916,  1.4190, -0.5257],\n",
      "         [-0.8101,  1.0333, -0.4808,  ..., -1.7123,  0.4023, -1.9285]],\n",
      "\n",
      "        [[ 1.7381,  3.3485,  0.3809,  ..., -1.8119,  1.0671, -0.6500],\n",
      "         [ 0.3185,  1.1808,  0.9578,  ..., -0.8908,  2.5264, -0.0892],\n",
      "         [-0.1032,  3.0183,  0.6142,  ..., -0.3110,  2.4853,  0.4026],\n",
      "         ...,\n",
      "         [-0.8224,  3.2598, -0.4329,  ..., -1.4163,  1.5420, -0.6585],\n",
      "         [-0.8058,  2.8513, -1.1820,  ..., -2.6798,  1.7751, -0.3417],\n",
      "         [-0.8285,  2.7185, -0.6420,  ..., -1.4946,  1.9804, -0.8115]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.5939,  3.7062, -0.2444,  ...,  0.0635,  2.2498, -0.1403],\n",
      "         [ 1.1310,  3.8389,  0.8401,  ..., -1.6697,  2.4958, -0.7042],\n",
      "         [ 2.8402,  1.8302,  2.3082,  ..., -1.8851,  3.4928,  0.3224],\n",
      "         ...,\n",
      "         [-0.2030,  4.1565,  0.6962,  ..., -1.0830,  2.1389, -0.5175],\n",
      "         [-0.7950,  3.3075, -0.8105,  ..., -3.4238,  1.0738, -1.6230],\n",
      "         [-0.4254,  2.3152, -0.6595,  ..., -1.8709,  1.8028, -0.8655]],\n",
      "\n",
      "        [[-1.6584,  2.9776,  1.6936,  ..., -0.4492,  1.0913,  1.0255],\n",
      "         [ 0.2009,  3.8960,  2.1117,  ..., -1.6577,  2.3518, -1.0735],\n",
      "         [ 0.8455,  1.9100,  0.9797,  ..., -0.9101,  1.1516, -1.0110],\n",
      "         ...,\n",
      "         [-0.7616,  3.0582,  0.9034,  ..., -3.0541,  1.5220, -0.3377],\n",
      "         [-1.8123,  2.4797, -0.3309,  ..., -0.4839,  0.8974, -0.9810],\n",
      "         [-1.2387,  0.1260, -0.7865,  ..., -1.6371,  1.5991, -1.2241]],\n",
      "\n",
      "        [[-0.6669,  4.9752, -0.2616,  ..., -1.9511,  1.5091, -0.2519],\n",
      "         [-0.0383,  2.5196,  1.4234,  ..., -1.3972,  2.6007,  0.3385],\n",
      "         [-1.0915,  1.9166,  0.5057,  ..., -1.3427,  1.4114, -0.9040],\n",
      "         ...,\n",
      "         [-0.0957,  2.5477,  0.1121,  ..., -1.0058,  1.6899, -1.1807],\n",
      "         [-1.2670,  3.0704, -0.0128,  ..., -2.1889,  0.7017, -1.2211],\n",
      "         [-1.6491,  2.0767, -0.0261,  ..., -2.2961,  1.7681, -1.3600]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 88, 64]) , torch.Size([512, 8, 88, 64]), torch.Size([512, 8, 88, 64])\n",
      "Score shape -- torch.Size([512, 8, 88, 88])\n",
      "Mask ---> torch.Size([512, 1, 88])\n",
      "Mask new --> torch.Size([512, 1, 1, 88])\n",
      "loop within encoder. Iteration -- 3\n",
      "this is x in EncoderLayer-----> tensor([[[ 0.6158,  4.7013,  1.0879,  ..., -1.7728, -0.1214, -1.2830],\n",
      "         [ 2.0380,  3.8490,  1.4687,  ..., -3.1280,  0.5367, -1.2823],\n",
      "         [ 1.9643,  3.2851,  1.0773,  ..., -6.1846,  0.1843, -3.1576],\n",
      "         ...,\n",
      "         [ 0.2402,  4.5607, -0.3855,  ..., -1.5995, -0.2126, -1.8347],\n",
      "         [ 0.6796,  4.5639, -1.1722,  ..., -2.8033,  0.6471, -1.2503],\n",
      "         [-0.4041,  2.7625,  0.5607,  ..., -4.9673,  0.1720, -1.6345]],\n",
      "\n",
      "        [[ 0.3025,  5.3329, -0.8480,  ..., -3.9982,  0.5352, -2.6811],\n",
      "         [ 0.6590,  3.5551,  2.4137,  ..., -2.4961,  0.7780, -1.1038],\n",
      "         [ 1.0361,  3.3968,  1.2739,  ..., -2.4294,  1.5373, -3.2093],\n",
      "         ...,\n",
      "         [ 0.2021,  3.7135,  1.6168,  ..., -3.9876,  0.1427, -1.4330],\n",
      "         [ 1.0022,  4.0398, -1.0917,  ..., -3.4431,  0.3506, -0.8058],\n",
      "         [ 0.1863,  1.6322, -0.5137,  ..., -3.8697, -0.5046, -2.9441]],\n",
      "\n",
      "        [[ 2.4825,  3.9673, -0.1343,  ..., -3.7415, -0.5195, -2.0251],\n",
      "         [ 1.3216,  1.8351,  0.9726,  ..., -3.7898,  1.7270, -1.5097],\n",
      "         [ 0.6995,  3.0996,  0.5528,  ..., -2.4312,  1.3919, -0.9527],\n",
      "         ...,\n",
      "         [ 0.3278,  3.6658, -0.4101,  ..., -4.2440,  0.3056, -1.4249],\n",
      "         [ 0.1086,  3.4988, -1.1116,  ..., -5.8322,  1.8133, -2.2660],\n",
      "         [-0.1543,  3.8111, -0.5290,  ..., -4.2911,  0.4716, -1.2073]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.1347,  4.3983,  0.1793,  ..., -2.3680,  1.5435, -0.6367],\n",
      "         [ 1.9712,  4.6834,  1.2249,  ..., -4.7470,  1.3199, -1.7102],\n",
      "         [ 3.7943,  2.6686,  2.8051,  ..., -4.5119,  3.1280, -0.5188],\n",
      "         ...,\n",
      "         [ 1.0500,  5.0963,  2.1408,  ..., -3.0470,  1.2209, -0.8296],\n",
      "         [-0.4919,  3.0961,  0.7854,  ..., -6.2780,  1.1584, -1.8149],\n",
      "         [ 0.4507,  2.3877,  0.3610,  ..., -4.8891,  0.3557, -1.7978]],\n",
      "\n",
      "        [[-1.7289,  4.3128,  0.8703,  ..., -1.8771, -0.1503, -0.0669],\n",
      "         [ 0.3032,  4.5813,  2.2664,  ..., -3.8008,  1.5343, -2.5883],\n",
      "         [ 0.8796,  1.9307,  0.9936,  ..., -2.0375, -0.5176, -1.8214],\n",
      "         ...,\n",
      "         [ 0.1226,  3.9458,  1.3034,  ..., -5.5619,  0.1123, -1.0823],\n",
      "         [-1.7914,  3.2022,  0.0566,  ..., -2.3209, -0.3080, -1.3078],\n",
      "         [-0.6406,  1.0322, -0.3372,  ..., -3.2953,  0.5436, -2.6763]],\n",
      "\n",
      "        [[ 0.4173,  5.8765, -0.0165,  ..., -4.4587,  0.8092, -1.5675],\n",
      "         [ 0.9042,  3.3550,  0.6107,  ..., -3.6190,  1.4187, -0.1488],\n",
      "         [-0.7762,  2.4092,  0.6216,  ..., -3.6142,  0.1566, -2.8269],\n",
      "         ...,\n",
      "         [ 0.6609,  3.4027,  0.3423,  ..., -3.4233,  0.1493, -1.7396],\n",
      "         [-0.6532,  3.5902,  0.4730,  ..., -4.9834,  0.7017, -1.2773],\n",
      "         [-0.8349,  2.8689, -0.0098,  ..., -2.9657,  0.8220, -1.7091]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 88, 64]) , torch.Size([512, 8, 88, 64]), torch.Size([512, 8, 88, 64])\n",
      "Score shape -- torch.Size([512, 8, 88, 88])\n",
      "Mask ---> torch.Size([512, 1, 88])\n",
      "Mask new --> torch.Size([512, 1, 1, 88])\n",
      "loop within encoder. Iteration -- 4\n",
      "this is x in EncoderLayer-----> tensor([[[ 0.4230,  5.3170, -1.2567,  ..., -3.0115, -0.2290, -2.6088],\n",
      "         [ 1.3656,  5.0687, -0.8841,  ..., -4.8667, -0.4553, -2.2197],\n",
      "         [ 1.6236,  4.1512, -0.8767,  ..., -7.7559, -1.3243, -4.4726],\n",
      "         ...,\n",
      "         [ 0.1264,  5.8278, -1.1133,  ..., -2.7081, -0.9205, -3.0394],\n",
      "         [ 0.5023,  5.7114, -2.9146,  ..., -4.0175, -0.1017, -2.4068],\n",
      "         [-0.7948,  4.1885, -1.9223,  ..., -6.0852,  0.7595, -2.7241]],\n",
      "\n",
      "        [[ 0.1012,  6.6271, -3.3067,  ..., -3.7281, -0.7016, -3.8786],\n",
      "         [ 0.7379,  5.0841,  0.1455,  ..., -2.4506, -0.3192, -2.6866],\n",
      "         [ 0.8000,  4.8496, -0.9287,  ..., -2.4407,  2.4267, -4.5445],\n",
      "         ...,\n",
      "         [-0.5350,  3.3730, -0.6320,  ..., -3.9235, -0.5349, -2.7026],\n",
      "         [ 0.6002,  5.4719, -4.2228,  ..., -3.2392,  0.0857, -2.6897],\n",
      "         [-0.0492,  3.0759, -3.4569,  ..., -3.0890, -1.7666, -4.3503]],\n",
      "\n",
      "        [[ 2.9101,  4.6442, -2.8373,  ..., -5.7980,  0.0858, -2.6767],\n",
      "         [ 2.2464,  2.4059, -1.0538,  ..., -4.0076,  1.6625, -2.0041],\n",
      "         [ 0.8083,  4.0409, -1.7493,  ..., -3.7453,  1.1177, -0.5791],\n",
      "         ...,\n",
      "         [-0.5117,  4.7291, -2.8159,  ..., -5.6129, -0.5974, -2.2337],\n",
      "         [-0.7118,  4.0387, -4.0188,  ..., -7.1491,  0.8933, -2.6725],\n",
      "         [-0.6817,  3.2811, -2.7838,  ..., -5.5133,  0.1396, -0.8293]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.3884,  5.5775, -1.1878,  ..., -2.5934,  1.7912, -1.6241],\n",
      "         [ 1.7785,  5.0446, -1.1705,  ..., -4.9972,  0.7506, -1.3227],\n",
      "         [ 2.9295,  3.5016,  0.5447,  ..., -5.5039,  2.8834, -1.4973],\n",
      "         ...,\n",
      "         [ 1.1125,  6.4100, -0.1429,  ..., -2.4568,  0.6805, -1.8729],\n",
      "         [-0.0636,  4.4224, -1.2160,  ..., -7.2598,  0.2925, -2.4806],\n",
      "         [-0.1144,  3.1765, -1.0192,  ..., -5.2327,  0.1520, -1.7023]],\n",
      "\n",
      "        [[-1.8549,  5.0183, -1.7391,  ..., -2.6148, -1.5167, -0.9021],\n",
      "         [ 0.0642,  4.9611,  1.9906,  ..., -4.7975,  0.8140, -3.9934],\n",
      "         [ 0.4868,  2.8532, -1.8282,  ..., -2.9034, -2.0066, -3.0146],\n",
      "         ...,\n",
      "         [-0.0345,  4.9995, -0.9084,  ..., -6.5076, -0.5535, -2.1761],\n",
      "         [-1.3329,  4.1392, -1.8954,  ..., -2.6717, -0.8065, -2.5999],\n",
      "         [-1.1621,  1.8498, -2.1205,  ..., -4.1947,  0.0811, -3.5222]],\n",
      "\n",
      "        [[-0.5467,  7.2128, -2.8465,  ..., -5.1372,  0.4905, -2.3663],\n",
      "         [ 0.6137,  4.5251, -1.8709,  ..., -4.8563,  1.2160, -1.1656],\n",
      "         [-1.2360,  3.1473, -1.9817,  ..., -4.1665,  0.1728, -3.8997],\n",
      "         ...,\n",
      "         [-0.0566,  4.8262, -0.9971,  ..., -4.0526,  1.7558, -2.4901],\n",
      "         [-0.6855,  4.3820, -1.7259,  ..., -5.5552, -0.3884, -1.7461],\n",
      "         [-1.0723,  4.1326, -1.6807,  ..., -2.9026,  0.6121, -2.7543]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 88, 64]) , torch.Size([512, 8, 88, 64]), torch.Size([512, 8, 88, 64])\n",
      "Score shape -- torch.Size([512, 8, 88, 88])\n",
      "Mask ---> torch.Size([512, 1, 88])\n",
      "Mask new --> torch.Size([512, 1, 1, 88])\n",
      "loop within encoder. Iteration -- 5\n",
      "this is x in EncoderLayer-----> tensor([[[ 1.6150,  3.3205, -0.7948,  ..., -3.6234, -1.0648, -0.1438],\n",
      "         [ 3.0643,  2.9527, -0.1663,  ..., -5.7491, -0.4553, -0.4332],\n",
      "         [ 3.3314,  1.3091, -0.3461,  ..., -8.8110, -2.5251, -2.1702],\n",
      "         ...,\n",
      "         [ 0.9128,  3.4885, -0.4889,  ..., -3.4328, -2.2226, -2.0315],\n",
      "         [ 1.1477,  3.2379, -2.4083,  ..., -4.4955, -2.0078, -0.7480],\n",
      "         [ 1.0244,  1.2169, -1.8542,  ..., -7.6310, -0.5492, -1.3052]],\n",
      "\n",
      "        [[ 0.8695,  4.0900, -2.4929,  ..., -4.3474, -2.3245, -2.8642],\n",
      "         [ 2.2331,  3.0184,  0.7798,  ..., -3.4758, -1.5008, -1.5782],\n",
      "         [ 2.6522,  2.1105, -0.4502,  ..., -3.2349,  0.6765, -4.0011],\n",
      "         ...,\n",
      "         [ 0.3984,  1.0901,  0.0925,  ..., -4.7860, -1.5825, -0.9348],\n",
      "         [ 2.4033,  4.8525, -3.1744,  ..., -4.3506, -1.3125, -1.1063],\n",
      "         [ 0.8652,  0.2922, -2.9279,  ..., -3.6714, -2.7279, -4.3503]],\n",
      "\n",
      "        [[ 3.8954,  1.7144, -2.3549,  ..., -7.5577, -0.8361, -0.9199],\n",
      "         [ 3.2243, -0.0349, -0.7955,  ..., -5.3844,  0.8570, -0.0490],\n",
      "         [ 1.5950,  1.2577, -1.7399,  ..., -4.8641, -0.0975,  1.0893],\n",
      "         ...,\n",
      "         [ 0.5014,  3.6265, -2.7345,  ..., -6.7928, -2.1875, -0.2785],\n",
      "         [ 1.2529,  1.5633, -3.5444,  ..., -8.4184, -0.6969, -1.6353],\n",
      "         [ 0.8719,  0.9741, -2.9151,  ..., -6.6156, -1.0138,  1.1520]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 3.0802,  4.0317, -1.8287,  ..., -3.4904,  1.1667, -0.5747],\n",
      "         [ 4.3490,  2.6736, -2.0535,  ..., -6.1015,  0.6343,  0.8315],\n",
      "         [ 5.5057,  2.9222,  0.9705,  ..., -6.0238,  2.3911,  0.8404],\n",
      "         ...,\n",
      "         [ 2.2677,  4.2845, -0.6864,  ..., -2.4146, -0.0192, -0.9714],\n",
      "         [ 1.7369,  1.9706, -1.1883,  ..., -7.5801, -1.0658, -1.2564],\n",
      "         [ 1.9928,  1.6703, -1.7026,  ..., -6.4909, -0.3983, -0.3778]],\n",
      "\n",
      "        [[-0.1671,  2.5749, -1.3714,  ..., -3.2985, -2.4641,  0.8818],\n",
      "         [ 0.8194,  2.2522,  1.8368,  ..., -5.9659, -0.3569, -2.3624],\n",
      "         [ 1.1787,  0.3505, -1.8218,  ..., -3.4831, -3.6314, -1.1723],\n",
      "         ...,\n",
      "         [ 1.7930,  3.5882, -0.4269,  ..., -7.1424, -2.5552, -0.9769],\n",
      "         [-0.3982,  2.2391, -2.2496,  ..., -3.0651, -1.7917, -1.4124],\n",
      "         [ 0.3935, -0.1359, -1.6775,  ..., -5.3560,  0.1048, -1.9153]],\n",
      "\n",
      "        [[ 0.9965,  5.0322, -2.0085,  ..., -5.7173, -0.5759, -0.8770],\n",
      "         [ 1.2274,  2.2623, -1.3476,  ..., -5.5690, -0.0422,  0.7254],\n",
      "         [-0.0749,  1.0985, -1.7180,  ..., -4.3720, -0.8283, -2.6531],\n",
      "         ...,\n",
      "         [ 1.6269,  2.7072, -0.7046,  ..., -4.3134,  0.7710, -0.3644],\n",
      "         [ 0.5344,  4.3820, -1.5004,  ..., -5.9712, -1.2107,  0.3183],\n",
      "         [ 0.2595,  2.1372, -1.2249,  ..., -3.7324, -0.7826, -1.2285]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 88, 64]) , torch.Size([512, 8, 88, 64]), torch.Size([512, 8, 88, 64])\n",
      "Score shape -- torch.Size([512, 8, 88, 88])\n",
      "Mask ---> torch.Size([512, 1, 88])\n",
      "Mask new --> torch.Size([512, 1, 1, 88])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 91])\n",
      "Mask ---> torch.Size([512, 91, 91])\n",
      "Mask new --> torch.Size([512, 1, 91, 91])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 88, 64]), torch.Size([512, 8, 88, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 88])\n",
      "Mask ---> torch.Size([512, 1, 88])\n",
      "Mask new --> torch.Size([512, 1, 1, 88])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 91])\n",
      "Mask ---> torch.Size([512, 91, 91])\n",
      "Mask new --> torch.Size([512, 1, 91, 91])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 88, 64]), torch.Size([512, 8, 88, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 88])\n",
      "Mask ---> torch.Size([512, 1, 88])\n",
      "Mask new --> torch.Size([512, 1, 1, 88])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 91])\n",
      "Mask ---> torch.Size([512, 91, 91])\n",
      "Mask new --> torch.Size([512, 1, 91, 91])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 88, 64]), torch.Size([512, 8, 88, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 88])\n",
      "Mask ---> torch.Size([512, 1, 88])\n",
      "Mask new --> torch.Size([512, 1, 1, 88])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 91])\n",
      "Mask ---> torch.Size([512, 91, 91])\n",
      "Mask new --> torch.Size([512, 1, 91, 91])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 88, 64]), torch.Size([512, 8, 88, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 88])\n",
      "Mask ---> torch.Size([512, 1, 88])\n",
      "Mask new --> torch.Size([512, 1, 1, 88])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 91])\n",
      "Mask ---> torch.Size([512, 91, 91])\n",
      "Mask new --> torch.Size([512, 1, 91, 91])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 88, 64]), torch.Size([512, 8, 88, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 88])\n",
      "Mask ---> torch.Size([512, 1, 88])\n",
      "Mask new --> torch.Size([512, 1, 1, 88])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 91])\n",
      "Mask ---> torch.Size([512, 91, 91])\n",
      "Mask new --> torch.Size([512, 1, 91, 91])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 88, 64]), torch.Size([512, 8, 88, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 88])\n",
      "Mask ---> torch.Size([512, 1, 88])\n",
      "Mask new --> torch.Size([512, 1, 1, 88])\n",
      "predictions size : tensor([[-4.0364e-01, -3.3938e-01,  2.6769e-01,  ..., -4.7148e-01,\n",
      "         -7.7419e-03,  4.5100e-04],\n",
      "        [-3.9131e-01, -3.4477e-01,  3.4359e-01,  ..., -2.4829e-01,\n",
      "         -1.6565e-01, -1.1348e-01],\n",
      "        [-3.8753e-01, -2.3814e-01,  2.5845e-01,  ..., -3.4388e-01,\n",
      "         -3.0029e-01, -5.1941e-02],\n",
      "        ...,\n",
      "        [-3.5177e-01, -6.0568e-02,  4.9229e-01,  ...,  3.9008e-02,\n",
      "          1.4767e-01, -2.8046e-02],\n",
      "        [-4.7890e-01, -1.1072e-01,  4.4370e-01,  ..., -8.8985e-02,\n",
      "          1.1681e-01,  4.8490e-02],\n",
      "        [-4.1575e-01, -1.5819e-01,  3.9313e-01,  ...,  3.3996e-02,\n",
      "         -9.6406e-02, -1.6932e-01]], grad_fn=<ViewBackward>)\n",
      "targets size : torch.Size([46592])\n",
      "Loss.data ----> = 8.731669425964355\n",
      "--Encoder x after PE : tensor([[[ 0.3330,  0.9321,  0.3250,  ...,  0.8620,  0.1752,  0.7026],\n",
      "         [ 0.6799,  0.2311,  0.0000,  ...,  0.4768, -0.6050,  0.5417],\n",
      "         [ 0.6430, -0.9126,  1.0429,  ...,  1.4983, -0.0641,  0.8708],\n",
      "         ...,\n",
      "         [-0.2319,  0.5529, -0.4102,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.8427, -0.4381, -0.0000,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.0000, -1.2356,  0.6229,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.4474,  1.7683, -0.5475,  ...,  0.8771, -0.5327,  0.7982],\n",
      "         [ 0.7576,  0.0107,  0.5354,  ...,  1.2146,  0.1632,  1.1613],\n",
      "         [ 0.5899,  0.2463,  1.2368,  ...,  0.6726, -0.5832,  0.7393],\n",
      "         ...,\n",
      "         [-0.2319,  0.5529, -0.0000,  ...,  0.0000,  0.1775,  0.5406],\n",
      "         [-0.8427, -0.0000, -0.2582,  ...,  1.0595,  0.1775,  0.0000],\n",
      "         [-0.4383, -1.2356,  0.0000,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.4474,  0.9740,  0.2062,  ...,  0.6878,  0.0000,  1.6821],\n",
      "         [ 0.0000,  0.2409,  1.4997,  ...,  0.8360,  0.0000,  1.3515],\n",
      "         [ 1.1905, -0.9064,  1.2473,  ...,  1.3552, -0.4056,  1.3675],\n",
      "         ...,\n",
      "         [-0.2319,  0.5529, -0.4102,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.0000, -0.4381, -0.2582,  ...,  1.0595,  0.1775,  0.0000],\n",
      "         [-0.4383, -1.2356,  0.6229,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.5258,  0.9182,  0.4145,  ...,  0.5200, -0.0000,  0.0000],\n",
      "         [ 0.8775,  1.0725,  1.5237,  ...,  0.0000, -0.1306,  0.0000],\n",
      "         [ 1.2428,  0.2131,  0.7957,  ...,  0.5579,  0.2207,  1.4986],\n",
      "         ...,\n",
      "         [-0.0000,  0.5529, -0.4102,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.8427, -0.4381, -0.2582,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.4383, -1.2356,  0.6229,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.0649,  0.6855, -0.5559,  ...,  0.5166, -0.3069,  0.8599],\n",
      "         [ 1.2944,  0.0000,  1.4997,  ...,  0.8360,  0.2648,  1.3515],\n",
      "         [ 1.6283,  0.0000,  0.0000,  ...,  1.4701, -0.1393,  0.8646],\n",
      "         ...,\n",
      "         [-0.2319,  0.5529, -0.4102,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.8427, -0.4381, -0.2582,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.4383, -0.0000,  0.6229,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.5701,  1.2768,  0.1856,  ...,  0.8936, -0.2536,  0.5582],\n",
      "         [ 0.3225,  0.0000,  0.8612,  ...,  1.0703, -0.0545,  0.8485],\n",
      "         [ 0.5658, -0.0159,  0.4600,  ...,  1.7492, -0.4484,  0.5722],\n",
      "         ...,\n",
      "         [-0.2319,  0.5529, -0.0000,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.8427, -0.4381, -0.2582,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.4383, -0.0000,  0.6229,  ...,  1.0595,  0.1775,  0.5406]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "loop within encoder. Iteration -- 0\n",
      "this is x in EncoderLayer-----> tensor([[[ 0.3330,  0.9321,  0.3250,  ...,  0.8620,  0.1752,  0.7026],\n",
      "         [ 0.6799,  0.2311,  0.0000,  ...,  0.4768, -0.6050,  0.5417],\n",
      "         [ 0.6430, -0.9126,  1.0429,  ...,  1.4983, -0.0641,  0.8708],\n",
      "         ...,\n",
      "         [-0.2319,  0.5529, -0.4102,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.8427, -0.4381, -0.0000,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.0000, -1.2356,  0.6229,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.4474,  1.7683, -0.5475,  ...,  0.8771, -0.5327,  0.7982],\n",
      "         [ 0.7576,  0.0107,  0.5354,  ...,  1.2146,  0.1632,  1.1613],\n",
      "         [ 0.5899,  0.2463,  1.2368,  ...,  0.6726, -0.5832,  0.7393],\n",
      "         ...,\n",
      "         [-0.2319,  0.5529, -0.0000,  ...,  0.0000,  0.1775,  0.5406],\n",
      "         [-0.8427, -0.0000, -0.2582,  ...,  1.0595,  0.1775,  0.0000],\n",
      "         [-0.4383, -1.2356,  0.0000,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.4474,  0.9740,  0.2062,  ...,  0.6878,  0.0000,  1.6821],\n",
      "         [ 0.0000,  0.2409,  1.4997,  ...,  0.8360,  0.0000,  1.3515],\n",
      "         [ 1.1905, -0.9064,  1.2473,  ...,  1.3552, -0.4056,  1.3675],\n",
      "         ...,\n",
      "         [-0.2319,  0.5529, -0.4102,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.0000, -0.4381, -0.2582,  ...,  1.0595,  0.1775,  0.0000],\n",
      "         [-0.4383, -1.2356,  0.6229,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.5258,  0.9182,  0.4145,  ...,  0.5200, -0.0000,  0.0000],\n",
      "         [ 0.8775,  1.0725,  1.5237,  ...,  0.0000, -0.1306,  0.0000],\n",
      "         [ 1.2428,  0.2131,  0.7957,  ...,  0.5579,  0.2207,  1.4986],\n",
      "         ...,\n",
      "         [-0.0000,  0.5529, -0.4102,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.8427, -0.4381, -0.2582,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.4383, -1.2356,  0.6229,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.0649,  0.6855, -0.5559,  ...,  0.5166, -0.3069,  0.8599],\n",
      "         [ 1.2944,  0.0000,  1.4997,  ...,  0.8360,  0.2648,  1.3515],\n",
      "         [ 1.6283,  0.0000,  0.0000,  ...,  1.4701, -0.1393,  0.8646],\n",
      "         ...,\n",
      "         [-0.2319,  0.5529, -0.4102,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.8427, -0.4381, -0.2582,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.4383, -0.0000,  0.6229,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.5701,  1.2768,  0.1856,  ...,  0.8936, -0.2536,  0.5582],\n",
      "         [ 0.3225,  0.0000,  0.8612,  ...,  1.0703, -0.0545,  0.8485],\n",
      "         [ 0.5658, -0.0159,  0.4600,  ...,  1.7492, -0.4484,  0.5722],\n",
      "         ...,\n",
      "         [-0.2319,  0.5529, -0.0000,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.8427, -0.4381, -0.2582,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.4383, -0.0000,  0.6229,  ...,  1.0595,  0.1775,  0.5406]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 82, 64]) , torch.Size([512, 8, 82, 64]), torch.Size([512, 8, 82, 64])\n",
      "Score shape -- torch.Size([512, 8, 82, 82])\n",
      "Mask ---> torch.Size([512, 1, 82])\n",
      "Mask new --> torch.Size([512, 1, 1, 82])\n",
      "loop within encoder. Iteration -- 1\n",
      "this is x in EncoderLayer-----> tensor([[[-1.0969,  1.4618, -0.1883,  ..., -0.5431,  2.4825,  0.2338],\n",
      "         [-0.6409,  2.3550,  0.0971,  ..., -1.2181,  2.3389,  0.5417],\n",
      "         [-1.0593,  0.4103,  1.0355,  ...,  0.4373,  0.4584, -0.6734],\n",
      "         ...,\n",
      "         [-0.8281,  2.9890, -0.7152,  ..., -0.2586,  1.6595, -0.9442],\n",
      "         [-2.2483,  1.6522,  0.2548,  ..., -0.4646,  0.2753, -0.8101],\n",
      "         [ 0.3241,  1.0233,  0.4137,  ..., -0.3408,  2.4317, -0.8582]],\n",
      "\n",
      "        [[-1.9475,  2.5400, -0.1783,  ..., -0.5902,  1.8990, -0.1933],\n",
      "         [-0.2478,  2.1153,  1.0558,  ..., -0.1175,  2.6149,  0.8833],\n",
      "         [-0.8568,  2.0841,  1.9206,  ..., -0.7067,  1.2752, -0.5764],\n",
      "         ...,\n",
      "         [-1.4218,  3.1498,  0.0847,  ..., -0.0117,  1.8623, -0.5910],\n",
      "         [-1.9421,  1.4625,  0.8038,  ...,  1.0595,  1.2723, -0.7128],\n",
      "         [-1.5599,  0.7854,  0.8183,  ..., -0.9584,  1.9803, -0.4795]],\n",
      "\n",
      "        [[-2.2555,  2.5644, -0.4479,  ...,  0.6803,  1.8792,  0.7610],\n",
      "         [-1.0528,  2.3961,  1.2091,  ..., -0.7776,  1.8500,  0.1957],\n",
      "         [ 0.0652,  1.5368,  0.8762,  ...,  1.3552,  2.1810, -0.0077],\n",
      "         ...,\n",
      "         [-1.6570,  3.3115, -0.7092,  ..., -1.0996,  0.1775, -0.9998],\n",
      "         [-1.1268,  2.3467, -0.8403,  ..., -0.7802,  1.6571, -1.0022],\n",
      "         [-1.3418,  1.3246,  0.5284,  ..., -0.5788,  2.0481, -0.5138]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.2896,  3.4609,  0.2857,  ..., -0.8569,  1.6817, -0.4765],\n",
      "         [-0.2327,  2.8809,  1.0722,  ..., -1.3427,  1.7095, -0.3488],\n",
      "         [-0.2021,  2.5532,  0.8644,  ..., -1.0905,  1.2938, -0.2208],\n",
      "         ...,\n",
      "         [-1.6872,  3.1392, -0.5048,  ..., -0.7023,  1.5955, -0.5011],\n",
      "         [-2.3368,  1.6137, -0.2691,  ..., -0.4881,  2.3816, -0.6169],\n",
      "         [-1.1785,  1.4559,  0.0735,  ...,  1.0595,  1.9908, -0.2690]],\n",
      "\n",
      "        [[-1.0576,  3.0012, -0.3154,  ..., -1.0487,  1.7000, -1.2716],\n",
      "         [-0.2095,  2.5913,  2.2577,  ..., -0.6050,  2.4968, -0.3582],\n",
      "         [ 0.4350,  1.9161,  0.1328,  ..., -0.5735,  1.8404,  0.4960],\n",
      "         ...,\n",
      "         [-1.7826,  1.5081, -0.1038,  ..., -0.4095,  0.1839, -1.2841],\n",
      "         [-2.4819,  1.5372, -0.0781,  ..., -0.7256,  2.0550, -0.4156],\n",
      "         [-0.5941,  2.3148,  0.3909,  ..., -1.0650,  1.8160, -0.6843]],\n",
      "\n",
      "        [[-0.2287,  3.3505,  0.8065,  ..., -0.5006,  1.9178,  0.2138],\n",
      "         [-0.6032,  1.7913,  0.7017,  ...,  0.2766,  2.3990, -0.8829],\n",
      "         [-0.9974,  1.5055,  0.7826,  ...,  0.4124,  2.7422, -0.0256],\n",
      "         ...,\n",
      "         [-0.9788,  2.1460,  0.6758,  ..., -1.3657,  2.3220, -1.5989],\n",
      "         [-1.5407,  0.0907, -0.7789,  ..., -0.6511,  2.2093, -0.4250],\n",
      "         [-1.1049,  1.7066,  1.2527,  ..., -0.4236,  1.7481, -0.5500]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 82, 64]) , torch.Size([512, 8, 82, 64]), torch.Size([512, 8, 82, 64])\n",
      "Score shape -- torch.Size([512, 8, 82, 82])\n",
      "Mask ---> torch.Size([512, 1, 82])\n",
      "Mask new --> torch.Size([512, 1, 1, 82])\n",
      "loop within encoder. Iteration -- 2\n",
      "this is x in EncoderLayer-----> tensor([[[-2.0127e-01,  2.9940e+00,  5.8654e-01,  ..., -2.5922e+00,\n",
      "           2.4272e+00, -2.2104e-01],\n",
      "         [ 1.8526e-01,  4.0921e+00,  7.0172e-01,  ..., -3.4250e+00,\n",
      "           2.3046e+00, -1.1830e-01],\n",
      "         [-2.7542e-01,  1.3119e+00,  1.3217e+00,  ...,  8.3479e-01,\n",
      "           1.5584e-01, -1.2507e+00],\n",
      "         ...,\n",
      "         [-6.1290e-01,  5.4906e+00, -7.4561e-01,  ..., -4.9907e-01,\n",
      "           1.9229e+00, -1.1916e+00],\n",
      "         [-1.8130e+00,  3.6446e+00, -5.8858e-02,  ..., -1.5086e+00,\n",
      "           4.4020e-01, -1.0754e+00],\n",
      "         [ 5.2264e-01,  2.1503e+00, -2.9628e-02,  ..., -1.8970e+00,\n",
      "           2.6707e+00, -1.1634e+00]],\n",
      "\n",
      "        [[-1.3693e+00,  3.2432e+00, -4.7163e-02,  ..., -2.3966e+00,\n",
      "           2.4041e+00, -1.0267e+00],\n",
      "         [ 8.8895e-01,  2.8838e+00,  1.6413e+00,  ..., -1.7867e+00,\n",
      "           3.0120e+00,  4.2886e-01],\n",
      "         [-2.9720e-01,  2.9127e+00,  2.9889e+00,  ..., -2.0547e+00,\n",
      "           1.8165e+00, -1.1404e+00],\n",
      "         ...,\n",
      "         [-8.0229e-01,  4.7355e+00,  5.4926e-01,  ..., -1.8120e+00,\n",
      "           2.5603e+00, -1.0357e+00],\n",
      "         [-1.7080e+00,  2.8656e+00,  7.7186e-01,  ..., -6.2423e-01,\n",
      "           1.4162e+00, -1.6317e+00],\n",
      "         [-1.4291e+00,  1.4064e+00,  8.7372e-01,  ..., -2.7003e+00,\n",
      "           2.5242e+00,  1.3384e-03]],\n",
      "\n",
      "        [[-1.9793e+00,  3.6014e+00, -4.3572e-01,  ..., -8.8354e-01,\n",
      "           2.2116e+00, -3.4062e-01],\n",
      "         [-1.8491e-01,  3.8759e+00,  8.0584e-01,  ..., -2.4929e+00,\n",
      "           2.2722e+00, -1.1229e+00],\n",
      "         [ 7.5247e-01,  9.2956e-01,  4.1106e-01,  ..., -4.4779e-01,\n",
      "           2.1849e+00, -1.1062e+00],\n",
      "         ...,\n",
      "         [-1.4543e+00,  4.6846e+00, -1.1300e+00,  ..., -2.8673e+00,\n",
      "           2.3113e-01, -1.6437e+00],\n",
      "         [-1.0631e+00,  3.0794e+00, -1.2025e+00,  ..., -2.6753e+00,\n",
      "           2.0683e+00, -1.5338e+00],\n",
      "         [-9.1158e-01,  2.2446e+00, -5.5028e-02,  ..., -1.9376e+00,\n",
      "           2.5350e+00, -8.7122e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.3532e+00,  3.9762e+00,  5.6245e-01,  ..., -2.7346e+00,\n",
      "           2.6261e+00, -1.7575e+00],\n",
      "         [ 3.7934e-01,  4.1164e+00,  1.7796e+00,  ..., -2.8445e+00,\n",
      "           1.7670e+00, -1.5626e+00],\n",
      "         [ 2.5290e-01,  3.4650e+00,  1.3302e+00,  ..., -2.4592e+00,\n",
      "           1.3810e+00, -7.6473e-01],\n",
      "         ...,\n",
      "         [-1.4382e+00,  4.4654e+00, -6.3521e-01,  ..., -2.2561e+00,\n",
      "           1.6088e+00, -1.2528e+00],\n",
      "         [-2.7039e+00,  2.2745e+00, -8.6902e-01,  ..., -2.0102e+00,\n",
      "           2.3439e+00, -2.1037e+00],\n",
      "         [-1.1165e+00,  2.5733e+00,  7.3287e-02,  ...,  1.2888e+00,\n",
      "           1.9908e+00, -2.0171e+00]],\n",
      "\n",
      "        [[-1.1510e-01,  3.4251e+00,  2.8281e-01,  ..., -2.8302e+00,\n",
      "           2.3863e+00, -1.8977e+00],\n",
      "         [ 6.2867e-01,  3.0479e+00,  2.3164e+00,  ..., -2.2580e+00,\n",
      "           2.5421e+00, -1.8865e+00],\n",
      "         [ 1.8359e+00,  2.5824e+00,  2.5021e-01,  ..., -1.5967e+00,\n",
      "           1.7549e+00, -1.2748e+00],\n",
      "         ...,\n",
      "         [-1.4980e+00,  1.5775e+00, -2.5304e-01,  ..., -1.8178e+00,\n",
      "           4.6047e-01, -2.6283e+00],\n",
      "         [-1.7950e+00,  2.3106e+00, -2.4398e-01,  ..., -2.2196e+00,\n",
      "           2.6751e+00, -1.4792e+00],\n",
      "         [-3.7475e-03,  3.1106e+00,  4.9326e-01,  ..., -2.9283e+00,\n",
      "           2.5061e+00, -1.2117e+00]],\n",
      "\n",
      "        [[ 1.0942e+00,  4.0828e+00,  8.0762e-01,  ..., -2.1391e+00,\n",
      "           1.9482e+00, -8.0641e-02],\n",
      "         [ 2.8795e-01,  1.8740e+00,  2.0737e-01,  ..., -1.0728e+00,\n",
      "           2.7319e+00, -1.9838e+00],\n",
      "         [ 8.1300e-01,  1.8809e+00,  2.0164e-01,  ..., -9.6060e-01,\n",
      "           3.6060e+00, -1.1169e+00],\n",
      "         ...,\n",
      "         [ 3.5962e-01,  2.0977e+00, -1.8594e-01,  ..., -3.2719e+00,\n",
      "           2.6160e+00, -2.7829e+00],\n",
      "         [-6.2648e-01,  1.0045e+00, -9.4202e-01,  ..., -6.5110e-01,\n",
      "           2.2696e+00, -1.0531e+00],\n",
      "         [-9.6072e-01,  2.9152e+00,  2.6006e-01,  ..., -1.5860e+00,\n",
      "           2.0963e+00, -1.1585e+00]]], grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 82, 64]) , torch.Size([512, 8, 82, 64]), torch.Size([512, 8, 82, 64])\n",
      "Score shape -- torch.Size([512, 8, 82, 82])\n",
      "Mask ---> torch.Size([512, 1, 82])\n",
      "Mask new --> torch.Size([512, 1, 1, 82])\n",
      "loop within encoder. Iteration -- 3\n",
      "this is x in EncoderLayer-----> tensor([[[ 0.5814,  3.7217,  0.0636,  ..., -4.8053,  0.9080, -1.5821],\n",
      "         [ 1.8723,  5.6279,  0.5550,  ..., -6.4220,  2.5266, -2.2893],\n",
      "         [ 1.1690,  2.4198,  0.5682,  ..., -1.1957, -0.6908, -2.5741],\n",
      "         ...,\n",
      "         [ 0.4253,  6.9718, -1.3222,  ..., -2.7835,  0.2569, -2.6463],\n",
      "         [-1.1173,  4.4690, -0.4147,  ..., -2.9750, -0.5750, -2.2645],\n",
      "         [ 1.6786,  3.1046, -0.6630,  ..., -3.4747,  0.9996, -2.0587]],\n",
      "\n",
      "        [[ 0.0309,  4.3725, -0.3560,  ..., -5.1046,  2.9651, -2.3688],\n",
      "         [ 2.1997,  4.1873,  0.7974,  ..., -3.9539,  1.8021, -1.2030],\n",
      "         [ 0.8113,  4.1366,  2.9467,  ..., -4.7267,  1.4074, -2.8717],\n",
      "         ...,\n",
      "         [ 0.1013,  6.4095,  0.1783,  ..., -4.0832,  1.5868, -1.9481],\n",
      "         [-0.9853,  3.8911,  0.5030,  ..., -2.9729,  0.3565, -2.6919],\n",
      "         [-0.7497,  2.9737,  0.7979,  ..., -5.3475,  1.1707, -0.7142]],\n",
      "\n",
      "        [[-0.5607,  4.9350, -0.6362,  ..., -3.1599,  1.4617, -1.5520],\n",
      "         [ 0.6840,  4.8964,  0.5493,  ..., -5.2655,  1.2607, -1.9256],\n",
      "         [ 1.8244,  1.3770, -0.1392,  ..., -3.5373,  2.2407, -1.7867],\n",
      "         ...,\n",
      "         [-0.3896,  5.8370, -1.3305,  ..., -4.4996, -0.9883, -1.8941],\n",
      "         [ 0.1846,  4.4427, -1.5282,  ..., -5.1926,  1.6337, -2.8899],\n",
      "         [ 0.2021,  3.5976, -0.1831,  ..., -3.9696,  1.0464, -1.8083]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.7095,  4.9228, -0.1153,  ..., -3.3458,  1.6517, -3.2702],\n",
      "         [ 1.8686,  4.3373,  0.3181,  ..., -3.4284,  0.3485, -1.8067],\n",
      "         [ 0.9325,  4.3093,  1.3221,  ..., -5.2302, -0.5970, -2.0474],\n",
      "         ...,\n",
      "         [-0.8587,  4.7920, -1.2142,  ..., -4.5721, -0.3766, -2.2443],\n",
      "         [-1.9142,  3.8123, -1.2665,  ..., -2.7439,  2.0875, -2.9649],\n",
      "         [ 0.2959,  4.0400, -0.4357,  ..., -1.5572,  0.9586, -2.9167]],\n",
      "\n",
      "        [[ 1.0417,  3.4832,  0.2319,  ..., -5.3463,  1.4062, -3.6029],\n",
      "         [ 1.3718,  2.7359,  1.7161,  ..., -4.6112,  2.0614, -2.8047],\n",
      "         [ 2.7096,  3.2430,  0.2689,  ..., -1.6744,  1.0363, -1.9770],\n",
      "         ...,\n",
      "         [-0.0239,  2.5010, -0.5640,  ..., -4.4159,  0.8982, -3.1626],\n",
      "         [-1.0135,  3.4382, -0.0557,  ..., -4.8184,  1.1772, -2.1786],\n",
      "         [ 0.9123,  4.3125,  0.3370,  ..., -5.3533,  2.9702, -1.9261]],\n",
      "\n",
      "        [[ 1.7190,  4.9042,  0.4707,  ..., -5.0246,  0.5172, -1.0891],\n",
      "         [ 1.1241,  2.3843, -0.8478,  ..., -4.1614,  1.3962, -2.8395],\n",
      "         [ 1.2621,  2.4988,  0.1344,  ..., -1.8693,  2.0887, -1.7697],\n",
      "         ...,\n",
      "         [ 0.8420,  2.5595, -0.5895,  ..., -6.6879,  0.9948, -3.2051],\n",
      "         [ 0.1925,  1.7580, -1.7165,  ..., -3.6261,  0.0166, -1.4608],\n",
      "         [-0.2896,  3.4576, -0.1726,  ..., -4.8881,  0.2702, -1.3427]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 82, 64]) , torch.Size([512, 8, 82, 64]), torch.Size([512, 8, 82, 64])\n",
      "Score shape -- torch.Size([512, 8, 82, 82])\n",
      "Mask ---> torch.Size([512, 1, 82])\n",
      "Mask new --> torch.Size([512, 1, 1, 82])\n",
      "loop within encoder. Iteration -- 4\n",
      "this is x in EncoderLayer-----> tensor([[[-0.1206,  4.7984, -2.4591,  ..., -4.9624,  0.3863, -2.5753],\n",
      "         [ 1.6503,  6.4868, -2.3803,  ..., -6.7572,  2.2350, -4.2633],\n",
      "         [ 1.5025,  3.5611, -1.4148,  ..., -1.4561, -0.3252, -4.3611],\n",
      "         ...,\n",
      "         [ 0.9208,  7.9021, -4.0290,  ..., -3.4636, -1.1175, -4.5017],\n",
      "         [-0.5610,  4.4690, -2.6926,  ..., -3.1901, -2.0304, -3.6904],\n",
      "         [ 0.8837,  4.2791, -3.3532,  ..., -2.9931, -0.1188, -3.4779]],\n",
      "\n",
      "        [[ 0.0356,  4.8081, -2.7993,  ..., -5.7836,  2.0755, -4.6907],\n",
      "         [ 1.8376,  5.3962, -1.8350,  ..., -4.6984,  1.9230, -2.6473],\n",
      "         [ 0.2898,  4.7609,  0.5029,  ..., -5.6554,  0.5671, -4.3470],\n",
      "         ...,\n",
      "         [ 0.3475,  6.8456, -2.1838,  ..., -4.3576,  1.1875, -3.4621],\n",
      "         [-1.2369,  5.2853, -2.2213,  ..., -3.4703,  1.1381, -4.9086],\n",
      "         [-1.0650,  4.1767, -1.2602,  ..., -5.9733,  0.6705, -2.2608]],\n",
      "\n",
      "        [[ 0.3360,  4.3685, -3.0111,  ..., -3.6133,  1.6284, -3.0685],\n",
      "         [ 0.4454,  5.6446, -1.6192,  ..., -5.6123,  0.8804, -3.1794],\n",
      "         [ 1.4711,  2.2164, -2.6965,  ..., -4.2489,  0.7779, -3.4100],\n",
      "         ...,\n",
      "         [-0.1129,  7.1047, -3.6750,  ..., -4.7692, -1.5709, -4.4460],\n",
      "         [ 0.4250,  5.3030, -3.4778,  ..., -5.4375,  0.6101, -4.5764],\n",
      "         [ 0.2660,  4.7865, -3.1329,  ..., -4.2801,  0.1047, -3.3799]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.8853,  6.1038, -2.9688,  ..., -4.1683,  1.2525, -4.4519],\n",
      "         [ 2.0102,  4.8620, -1.4554,  ..., -4.4344, -1.3925, -2.7392],\n",
      "         [ 1.0042,  5.1813, -1.3958,  ..., -5.2302, -1.6258, -3.5439],\n",
      "         ...,\n",
      "         [-0.7858,  5.9370, -3.9728,  ..., -5.0056, -1.0578, -3.8950],\n",
      "         [-1.9063,  4.8690, -4.0850,  ..., -3.1167,  1.7206, -3.2120],\n",
      "         [-0.1680,  4.7861, -3.0215,  ..., -1.9104, -0.2085, -4.1861]],\n",
      "\n",
      "        [[ 2.0983,  4.4689, -1.7487,  ..., -5.9150,  0.9644, -5.4696],\n",
      "         [ 0.8625,  3.8455, -0.4527,  ..., -5.2423,  2.1633, -4.3326],\n",
      "         [ 2.0306,  4.0943, -1.6712,  ..., -2.1196,  0.5492, -3.4893],\n",
      "         ...,\n",
      "         [-0.6711,  3.0485, -2.9011,  ..., -4.7904,  0.1735, -5.1858],\n",
      "         [-1.9203,  4.3657, -1.6886,  ..., -5.5048,  0.6687, -3.9942],\n",
      "         [-0.2048,  4.7202, -1.0525,  ..., -5.8481,  3.3962, -3.2465]],\n",
      "\n",
      "        [[ 1.4082,  5.1320, -2.2559,  ..., -5.1143,  0.3084, -1.9592],\n",
      "         [ 1.3836,  3.7835, -2.8295,  ..., -5.2986,  1.1382, -3.9760],\n",
      "         [ 1.0097,  2.9736, -2.1743,  ..., -2.8807,  1.2543, -3.7242],\n",
      "         ...,\n",
      "         [ 0.8008,  3.6557, -3.4690,  ..., -7.4625,  1.1886, -4.5587],\n",
      "         [-0.5738,  1.6928, -4.0975,  ..., -4.3876, -0.8568, -2.1514],\n",
      "         [-1.1774,  4.5823, -3.1371,  ..., -5.8510, -0.0692, -2.5617]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 82, 64]) , torch.Size([512, 8, 82, 64]), torch.Size([512, 8, 82, 64])\n",
      "Score shape -- torch.Size([512, 8, 82, 82])\n",
      "Mask ---> torch.Size([512, 1, 82])\n",
      "Mask new --> torch.Size([512, 1, 1, 82])\n",
      "loop within encoder. Iteration -- 5\n",
      "this is x in EncoderLayer-----> tensor([[[ 1.6358e+00,  2.6326e+00, -2.5437e+00,  ..., -6.6480e+00,\n",
      "           2.9328e-01, -6.0283e-02],\n",
      "         [ 3.5679e+00,  5.2126e+00, -3.0062e+00,  ..., -8.6629e+00,\n",
      "           2.0411e+00, -2.1027e+00],\n",
      "         [ 3.4621e+00,  1.9185e+00, -6.1669e-02,  ..., -3.1337e+00,\n",
      "          -1.1824e+00, -1.9760e+00],\n",
      "         ...,\n",
      "         [ 2.1793e+00,  5.9917e+00, -3.4664e+00,  ..., -5.3463e+00,\n",
      "          -1.3047e+00, -2.4314e+00],\n",
      "         [ 1.2031e+00,  2.4098e+00, -1.4002e+00,  ..., -4.4303e+00,\n",
      "          -2.3371e+00, -1.7180e+00],\n",
      "         [ 2.7791e+00,  1.8332e+00, -2.8679e+00,  ..., -4.7335e+00,\n",
      "          -2.6253e-01, -1.5966e+00]],\n",
      "\n",
      "        [[ 1.5248e+00,  3.0616e+00, -2.9142e+00,  ..., -8.3204e+00,\n",
      "           1.8937e+00, -2.7472e+00],\n",
      "         [ 3.5092e+00,  3.8749e+00, -1.4529e+00,  ..., -6.1859e+00,\n",
      "           1.3176e+00, -4.3933e-01],\n",
      "         [ 2.2415e+00,  3.8585e+00,  9.6276e-01,  ..., -7.6276e+00,\n",
      "          -4.9798e-01, -2.9710e+00],\n",
      "         ...,\n",
      "         [ 1.3854e+00,  4.7081e+00, -1.7730e+00,  ..., -4.9402e+00,\n",
      "           4.3217e-01, -1.8905e+00],\n",
      "         [ 4.6416e-01,  3.1419e+00, -3.0881e+00,  ..., -5.4222e+00,\n",
      "           7.8893e-01, -3.1281e+00],\n",
      "         [ 5.8453e-01,  2.8807e+00, -2.0332e+00,  ..., -8.0215e+00,\n",
      "          -1.8136e-01, -6.9156e-01]],\n",
      "\n",
      "        [[ 1.3700e+00,  3.3574e+00, -1.8294e+00,  ..., -5.1786e+00,\n",
      "           1.8916e+00, -9.4048e-01],\n",
      "         [ 2.3493e+00,  4.0955e+00, -9.1197e-01,  ..., -7.2010e+00,\n",
      "           4.8922e-01, -1.2813e+00],\n",
      "         [ 3.1328e+00,  8.1670e-04, -1.7702e+00,  ..., -5.8345e+00,\n",
      "          -1.4559e-02, -1.4463e+00],\n",
      "         ...,\n",
      "         [ 6.7685e-01,  7.1047e+00, -2.1107e+00,  ..., -5.4589e+00,\n",
      "          -2.0898e+00, -2.8329e+00],\n",
      "         [ 9.6326e-01,  3.5638e+00, -2.6840e+00,  ..., -7.2151e+00,\n",
      "           2.7929e-01, -2.4637e+00],\n",
      "         [ 1.9376e+00,  2.8607e+00, -2.9481e+00,  ..., -6.0156e+00,\n",
      "          -8.5065e-01, -1.5498e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.6223e-01,  4.9438e+00, -2.2324e+00,  ..., -6.6953e+00,\n",
      "          -4.2423e-02, -1.8162e+00],\n",
      "         [ 4.5284e+00,  2.4525e+00, -8.7031e-01,  ..., -6.0786e+00,\n",
      "          -1.9637e+00, -2.3446e-01],\n",
      "         [ 1.4565e+00,  3.7595e+00, -1.2345e+00,  ..., -7.3829e+00,\n",
      "          -1.8251e+00, -2.5444e+00],\n",
      "         ...,\n",
      "         [ 8.0003e-01,  5.2616e+00, -3.4172e+00,  ..., -5.7070e+00,\n",
      "          -1.6513e+00, -2.1882e+00],\n",
      "         [-6.5705e-01,  3.0078e+00, -4.1244e+00,  ..., -4.7565e+00,\n",
      "           1.0153e+00, -1.4187e+00],\n",
      "         [ 1.8707e+00,  3.4736e+00, -2.6371e+00,  ..., -2.2064e+00,\n",
      "           2.6365e-01, -3.2797e+00]],\n",
      "\n",
      "        [[ 2.9807e+00,  3.1082e+00, -1.3403e+00,  ..., -7.3879e+00,\n",
      "           5.2824e-01, -4.0377e+00],\n",
      "         [ 2.5510e+00,  1.6678e+00,  7.0682e-01,  ..., -6.8335e+00,\n",
      "           1.2522e+00, -2.4279e+00],\n",
      "         [ 3.9587e+00,  2.1700e+00, -3.8520e-01,  ..., -3.2707e+00,\n",
      "          -6.9900e-01, -2.4662e+00],\n",
      "         ...,\n",
      "         [ 7.5381e-01,  1.1412e+00, -2.0326e+00,  ..., -6.1279e+00,\n",
      "          -2.8614e-01, -3.4791e+00],\n",
      "         [-5.3005e-01,  2.6842e+00, -1.0461e+00,  ..., -6.5787e+00,\n",
      "          -3.2083e-01, -2.6639e+00],\n",
      "         [ 1.3210e+00,  3.0815e+00, -1.9778e-01,  ..., -7.1628e+00,\n",
      "           2.6691e+00, -1.1676e+00]],\n",
      "\n",
      "        [[ 3.0875e+00,  2.9398e+00, -1.7873e+00,  ..., -6.5714e+00,\n",
      "          -3.4819e-01,  3.5571e-01],\n",
      "         [ 2.8801e+00,  1.3527e+00, -1.9156e+00,  ..., -7.2550e+00,\n",
      "           8.0943e-01, -1.7441e+00],\n",
      "         [ 2.8728e+00,  7.5632e-01, -2.0438e+00,  ..., -4.6461e+00,\n",
      "          -5.5463e-02, -1.8610e+00],\n",
      "         ...,\n",
      "         [ 1.4199e+00,  1.3815e+00, -2.9786e+00,  ..., -9.3514e+00,\n",
      "           1.8558e+00, -2.8087e+00],\n",
      "         [ 1.1102e+00, -4.5985e-01, -5.1314e+00,  ..., -6.1051e+00,\n",
      "          -2.0520e+00,  4.4589e-02],\n",
      "         [ 9.8721e-01,  3.0477e+00, -2.8368e+00,  ..., -7.0681e+00,\n",
      "          -1.7465e-01, -5.3003e-01]]], grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 82, 64]) , torch.Size([512, 8, 82, 64]), torch.Size([512, 8, 82, 64])\n",
      "Score shape -- torch.Size([512, 8, 82, 82])\n",
      "Mask ---> torch.Size([512, 1, 82])\n",
      "Mask new --> torch.Size([512, 1, 1, 82])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 90, 64]) , torch.Size([512, 8, 90, 64]), torch.Size([512, 8, 90, 64])\n",
      "Score shape -- torch.Size([512, 8, 90, 90])\n",
      "Mask ---> torch.Size([512, 90, 90])\n",
      "Mask new --> torch.Size([512, 1, 90, 90])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 90, 64]) , torch.Size([512, 8, 82, 64]), torch.Size([512, 8, 82, 64])\n",
      "Score shape -- torch.Size([512, 8, 90, 82])\n",
      "Mask ---> torch.Size([512, 1, 82])\n",
      "Mask new --> torch.Size([512, 1, 1, 82])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 90, 64]) , torch.Size([512, 8, 90, 64]), torch.Size([512, 8, 90, 64])\n",
      "Score shape -- torch.Size([512, 8, 90, 90])\n",
      "Mask ---> torch.Size([512, 90, 90])\n",
      "Mask new --> torch.Size([512, 1, 90, 90])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 90, 64]) , torch.Size([512, 8, 82, 64]), torch.Size([512, 8, 82, 64])\n",
      "Score shape -- torch.Size([512, 8, 90, 82])\n",
      "Mask ---> torch.Size([512, 1, 82])\n",
      "Mask new --> torch.Size([512, 1, 1, 82])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 90, 64]) , torch.Size([512, 8, 90, 64]), torch.Size([512, 8, 90, 64])\n",
      "Score shape -- torch.Size([512, 8, 90, 90])\n",
      "Mask ---> torch.Size([512, 90, 90])\n",
      "Mask new --> torch.Size([512, 1, 90, 90])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 90, 64]) , torch.Size([512, 8, 82, 64]), torch.Size([512, 8, 82, 64])\n",
      "Score shape -- torch.Size([512, 8, 90, 82])\n",
      "Mask ---> torch.Size([512, 1, 82])\n",
      "Mask new --> torch.Size([512, 1, 1, 82])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 90, 64]) , torch.Size([512, 8, 90, 64]), torch.Size([512, 8, 90, 64])\n",
      "Score shape -- torch.Size([512, 8, 90, 90])\n",
      "Mask ---> torch.Size([512, 90, 90])\n",
      "Mask new --> torch.Size([512, 1, 90, 90])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 90, 64]) , torch.Size([512, 8, 82, 64]), torch.Size([512, 8, 82, 64])\n",
      "Score shape -- torch.Size([512, 8, 90, 82])\n",
      "Mask ---> torch.Size([512, 1, 82])\n",
      "Mask new --> torch.Size([512, 1, 1, 82])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 90, 64]) , torch.Size([512, 8, 90, 64]), torch.Size([512, 8, 90, 64])\n",
      "Score shape -- torch.Size([512, 8, 90, 90])\n",
      "Mask ---> torch.Size([512, 90, 90])\n",
      "Mask new --> torch.Size([512, 1, 90, 90])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 90, 64]) , torch.Size([512, 8, 82, 64]), torch.Size([512, 8, 82, 64])\n",
      "Score shape -- torch.Size([512, 8, 90, 82])\n",
      "Mask ---> torch.Size([512, 1, 82])\n",
      "Mask new --> torch.Size([512, 1, 1, 82])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 90, 64]) , torch.Size([512, 8, 90, 64]), torch.Size([512, 8, 90, 64])\n",
      "Score shape -- torch.Size([512, 8, 90, 90])\n",
      "Mask ---> torch.Size([512, 90, 90])\n",
      "Mask new --> torch.Size([512, 1, 90, 90])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 90, 64]) , torch.Size([512, 8, 82, 64]), torch.Size([512, 8, 82, 64])\n",
      "Score shape -- torch.Size([512, 8, 90, 82])\n",
      "Mask ---> torch.Size([512, 1, 82])\n",
      "Mask new --> torch.Size([512, 1, 1, 82])\n",
      "predictions size : tensor([[-0.2953, -0.2115,  0.1423,  ..., -0.1344, -0.0428,  0.1812],\n",
      "        [-0.3364, -0.1917,  0.3015,  ..., -0.2714,  0.0095, -0.0040],\n",
      "        [-0.0404, -0.2084,  0.2925,  ..., -0.2597, -0.0421, -0.0542],\n",
      "        ...,\n",
      "        [-0.6238, -0.1157,  0.4343,  ...,  0.1620, -0.0729,  0.0266],\n",
      "        [-0.6662, -0.1826,  0.2976,  ...,  0.0101, -0.0906,  0.0675],\n",
      "        [-0.5206, -0.2915,  0.2946,  ..., -0.1508,  0.1124,  0.1373]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "targets size : torch.Size([46080])\n",
      "Loss.data ----> = 8.632616996765137\n",
      "--Encoder x after PE : tensor([[[-0.0071,  0.4591, -0.4927,  ...,  0.6986,  0.3227,  1.3818],\n",
      "         [ 0.3935,  1.1793,  1.5461,  ...,  1.4497, -0.2789,  1.7449],\n",
      "         [ 0.5661, -0.0158,  0.4605,  ...,  1.7500, -0.4479,  0.0000],\n",
      "         ...,\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.6515, -0.0000, -0.0868,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.3009, -1.3217,  0.8777,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.0000,  1.6895, -0.0416,  ...,  0.7600, -0.1447,  0.7942],\n",
      "         [ 0.8321,  0.2124,  0.8972,  ...,  1.2796, -0.5147,  0.8479],\n",
      "         [ 0.7156, -0.0000,  0.4887,  ...,  0.8094, -0.2722,  1.0438],\n",
      "         ...,\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.6515, -0.9060, -0.0868,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.3009, -1.3217,  0.8777,  ...,  1.0595,  0.1775,  0.0000]],\n",
      "\n",
      "        [[-0.0000,  1.6315,  0.5035,  ...,  1.0550,  0.0000,  1.0043],\n",
      "         [ 1.5526,  0.3418,  0.6948,  ...,  0.6518,  0.0380,  0.6474],\n",
      "         [ 1.5797, -0.2230,  1.2515,  ...,  0.8948, -0.2513,  0.5568],\n",
      "         ...,\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.6515, -0.9060, -0.0868,  ...,  1.0595,  0.1775,  0.0000],\n",
      "         [ 0.3009, -1.3217,  0.8777,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.5242,  0.9193,  0.4128,  ...,  0.5214, -0.6345,  0.0000],\n",
      "         [ 0.0000,  0.1187,  1.0718,  ...,  1.3558, -0.4043,  1.3678],\n",
      "         [ 1.6435, -0.4929,  1.6135,  ...,  0.6392, -0.4587,  0.7045],\n",
      "         ...,\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.6515, -0.9060, -0.0868,  ...,  0.0000,  0.1775,  0.5406],\n",
      "         [ 0.3009, -1.3217,  0.8777,  ...,  1.0595,  0.1775,  0.0000]],\n",
      "\n",
      "        [[ 0.5694,  1.2780,  0.1869,  ...,  0.8948, -0.2513,  0.5568],\n",
      "         [ 0.6897,  0.0000,  0.2406,  ...,  0.9986,  0.4139,  1.6340],\n",
      "         [ 1.4380, -0.5876,  0.4563,  ...,  1.0056,  0.2907,  0.4728],\n",
      "         ...,\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  0.0000,  0.0000,  0.5406],\n",
      "         [-0.6515, -0.9060, -0.0000,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.3009, -0.0000,  0.8777,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.0952,  1.4421, -0.3096,  ...,  1.7509, -0.3156,  0.5533],\n",
      "         [ 0.7561,  0.0127,  0.5331,  ...,  1.2162,  0.1647,  1.1599],\n",
      "         [ 0.9726, -0.8358,  1.5849,  ...,  0.9823,  0.5263,  1.6299],\n",
      "         ...,\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.6515, -0.9060, -0.0868,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.3009, -1.3217,  0.8777,  ...,  1.0595,  0.1775,  0.5406]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "loop within encoder. Iteration -- 0\n",
      "this is x in EncoderLayer-----> tensor([[[-0.0071,  0.4591, -0.4927,  ...,  0.6986,  0.3227,  1.3818],\n",
      "         [ 0.3935,  1.1793,  1.5461,  ...,  1.4497, -0.2789,  1.7449],\n",
      "         [ 0.5661, -0.0158,  0.4605,  ...,  1.7500, -0.4479,  0.0000],\n",
      "         ...,\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.6515, -0.0000, -0.0868,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.3009, -1.3217,  0.8777,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.0000,  1.6895, -0.0416,  ...,  0.7600, -0.1447,  0.7942],\n",
      "         [ 0.8321,  0.2124,  0.8972,  ...,  1.2796, -0.5147,  0.8479],\n",
      "         [ 0.7156, -0.0000,  0.4887,  ...,  0.8094, -0.2722,  1.0438],\n",
      "         ...,\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.6515, -0.9060, -0.0868,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.3009, -1.3217,  0.8777,  ...,  1.0595,  0.1775,  0.0000]],\n",
      "\n",
      "        [[-0.0000,  1.6315,  0.5035,  ...,  1.0550,  0.0000,  1.0043],\n",
      "         [ 1.5526,  0.3418,  0.6948,  ...,  0.6518,  0.0380,  0.6474],\n",
      "         [ 1.5797, -0.2230,  1.2515,  ...,  0.8948, -0.2513,  0.5568],\n",
      "         ...,\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.6515, -0.9060, -0.0868,  ...,  1.0595,  0.1775,  0.0000],\n",
      "         [ 0.3009, -1.3217,  0.8777,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.5242,  0.9193,  0.4128,  ...,  0.5214, -0.6345,  0.0000],\n",
      "         [ 0.0000,  0.1187,  1.0718,  ...,  1.3558, -0.4043,  1.3678],\n",
      "         [ 1.6435, -0.4929,  1.6135,  ...,  0.6392, -0.4587,  0.7045],\n",
      "         ...,\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.6515, -0.9060, -0.0868,  ...,  0.0000,  0.1775,  0.5406],\n",
      "         [ 0.3009, -1.3217,  0.8777,  ...,  1.0595,  0.1775,  0.0000]],\n",
      "\n",
      "        [[ 0.5694,  1.2780,  0.1869,  ...,  0.8948, -0.2513,  0.5568],\n",
      "         [ 0.6897,  0.0000,  0.2406,  ...,  0.9986,  0.4139,  1.6340],\n",
      "         [ 1.4380, -0.5876,  0.4563,  ...,  1.0056,  0.2907,  0.4728],\n",
      "         ...,\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  0.0000,  0.0000,  0.5406],\n",
      "         [-0.6515, -0.9060, -0.0000,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.3009, -0.0000,  0.8777,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.0952,  1.4421, -0.3096,  ...,  1.7509, -0.3156,  0.5533],\n",
      "         [ 0.7561,  0.0127,  0.5331,  ...,  1.2162,  0.1647,  1.1599],\n",
      "         [ 0.9726, -0.8358,  1.5849,  ...,  0.9823,  0.5263,  1.6299],\n",
      "         ...,\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.6515, -0.9060, -0.0868,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.3009, -1.3217,  0.8777,  ...,  1.0595,  0.1775,  0.5406]]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 89, 64]) , torch.Size([512, 8, 89, 64]), torch.Size([512, 8, 89, 64])\n",
      "Score shape -- torch.Size([512, 8, 89, 89])\n",
      "Mask ---> torch.Size([512, 1, 89])\n",
      "Mask new --> torch.Size([512, 1, 1, 89])\n",
      "loop within encoder. Iteration -- 1\n",
      "this is x in EncoderLayer-----> tensor([[[-2.0135,  2.5520, -0.1131,  ..., -1.2710,  1.8633, -0.2739],\n",
      "         [-2.0812,  3.0580,  0.4592,  ...,  0.1324,  1.7807,  0.3157],\n",
      "         [-2.1077,  1.4106,  0.1977,  ...,  0.3285,  1.9876, -0.8802],\n",
      "         ...,\n",
      "         [-0.6062,  1.9885, -0.3880,  ..., -0.6373,  2.5931,  0.5406],\n",
      "         [-2.4410,  1.7600, -0.5587,  ...,  0.9660,  1.6841, -0.2827],\n",
      "         [-1.3418, -1.3217,  0.5597,  ...,  1.1674,  2.3946, -1.2341]],\n",
      "\n",
      "        [[-1.6370,  3.7617,  0.1969,  ..., -1.0491,  0.7131, -0.8424],\n",
      "         [-0.7455,  2.2737,  0.5637,  ..., -0.7190,  2.3634,  0.4798],\n",
      "         [-0.2356,  2.6226,  0.4773,  ..., -1.7187,  2.1879, -0.6213],\n",
      "         ...,\n",
      "         [-1.9803,  1.3019, -0.7044,  ..., -0.7616,  2.0420, -1.5362],\n",
      "         [-2.2210, -0.2372, -0.0530,  ..., -1.0376,  1.8187, -0.0726],\n",
      "         [-0.4283,  1.0766,  1.3821,  ..., -1.7078,  2.4895, -1.4656]],\n",
      "\n",
      "        [[-2.0346,  3.1601,  0.1901,  ..., -0.7278,  1.7420,  0.4014],\n",
      "         [-0.2321,  2.5767,  0.8770,  ..., -1.1287,  0.0380, -0.4183],\n",
      "         [-0.4411,  1.4337,  1.8813,  ..., -1.2523,  1.7974,  0.1347],\n",
      "         ...,\n",
      "         [-2.7311,  2.0391, -0.2346,  ..., -0.9484,  1.6629, -1.3039],\n",
      "         [-1.7997,  0.6719,  0.5586,  ..., -0.9153,  2.0633, -1.0501],\n",
      "         [-0.8127,  0.8012,  1.1847,  ..., -1.0592,  1.8794, -0.7766]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.5999,  3.7043,  1.0598,  ..., -0.9945,  2.2028, -1.0576],\n",
      "         [ 0.2623,  2.0867,  1.0494,  ..., -0.2032,  2.4161,  1.1130],\n",
      "         [ 0.4947,  0.6881,  2.5696,  ..., -1.4916,  2.9930, -0.6231],\n",
      "         ...,\n",
      "         [-1.6108,  2.5176,  0.5647,  ..., -1.5733,  2.3598, -1.3984],\n",
      "         [-1.6384,  1.4670, -0.8002,  ..., -2.0610,  2.2626, -0.9721],\n",
      "         [-0.8327, -0.2783,  0.9808,  ..., -0.7668,  2.2232, -1.1110]],\n",
      "\n",
      "        [[ 0.7979,  3.6154, -0.5248,  ..., -0.9047,  0.8974, -0.1295],\n",
      "         [-0.6560,  2.3754, -0.3781,  ..., -0.1370,  2.5141,  0.1844],\n",
      "         [-0.5341,  1.5702,  0.0118,  ..., -0.0349,  1.3799, -0.5094],\n",
      "         ...,\n",
      "         [-2.9108,  2.6024,  0.0555,  ..., -0.1048,  0.2754, -0.8771],\n",
      "         [-2.5601,  0.1445,  0.4963,  ..., -0.6360,  1.3076, -0.8911],\n",
      "         [-1.7819,  2.6647,  1.1131,  ..., -0.1581,  1.7903, -1.2067]],\n",
      "\n",
      "        [[-1.8440,  3.5374,  0.1793,  ...,  0.5258, -0.3156,  0.0492],\n",
      "         [-0.8031,  2.0662,  0.0627,  ...,  0.7211,  2.8387,  0.2971],\n",
      "         [-1.2792,  1.2346,  1.8135,  ..., -0.6472,  1.6565,  0.2369],\n",
      "         ...,\n",
      "         [-2.1724,  2.7075, -0.0936,  ..., -0.6928,  2.3745, -1.0805],\n",
      "         [-1.9760,  1.3282,  0.2888,  ..., -0.3338,  2.2245, -0.9308],\n",
      "         [ 0.3009,  0.6806,  0.8703,  ..., -0.5719,  2.6947, -0.8763]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 89, 64]) , torch.Size([512, 8, 89, 64]), torch.Size([512, 8, 89, 64])\n",
      "Score shape -- torch.Size([512, 8, 89, 89])\n",
      "Mask ---> torch.Size([512, 1, 89])\n",
      "Mask new --> torch.Size([512, 1, 1, 89])\n",
      "loop within encoder. Iteration -- 2\n",
      "this is x in EncoderLayer-----> tensor([[[-1.4263,  4.2204, -0.6766,  ..., -1.2162,  1.8094, -1.1367],\n",
      "         [-1.3169,  4.2164,  0.3844,  ..., -1.3158,  2.0183, -0.9469],\n",
      "         [-1.0097,  2.5435, -0.2318,  ..., -0.9407,  2.2089, -1.7137],\n",
      "         ...,\n",
      "         [ 0.3846,  2.7794, -0.7714,  ..., -2.2278,  3.0224,  0.2121],\n",
      "         [-1.8522,  3.3948, -0.1545,  ..., -0.2857,  1.7851, -1.1034],\n",
      "         [-0.5307, -0.5355, -0.0810,  ..., -0.1165,  2.1464, -2.2741]],\n",
      "\n",
      "        [[-0.4752,  4.2468, -0.0872,  ..., -1.8383,  0.1366, -2.2516],\n",
      "         [-0.1156,  3.2805,  0.0084,  ..., -1.8358,  1.9216, -0.7754],\n",
      "         [ 0.7129,  3.4503,  0.5641,  ..., -2.9435,  2.1503, -1.2965],\n",
      "         ...,\n",
      "         [-0.8851,  2.4707, -1.1494,  ..., -2.5700,  1.6829, -2.2698],\n",
      "         [-0.8956,  1.0516, -0.3993,  ..., -2.3007,  1.2959, -1.2118],\n",
      "         [-0.2684,  2.7081,  0.7923,  ..., -2.5107,  2.1313, -2.7308]],\n",
      "\n",
      "        [[-1.6067,  4.0240, -0.1120,  ..., -1.5904,  2.1229,  0.1697],\n",
      "         [ 0.4920,  3.2413,  0.4832,  ..., -2.1150,  0.7167, -0.9835],\n",
      "         [ 0.8296,  2.0252,  1.0530,  ..., -1.2523,  2.3428, -0.4746],\n",
      "         ...,\n",
      "         [-1.7857,  2.3182, -0.5531,  ..., -2.6244,  1.5858, -2.0337],\n",
      "         [-1.2471,  1.7195, -0.4782,  ..., -2.5278,  2.2403, -1.5455],\n",
      "         [ 0.1896,  1.4461,  0.5693,  ..., -2.4401,  1.7024, -1.4665]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.8572,  4.9058,  1.3641,  ..., -3.0742,  1.0139, -3.3154],\n",
      "         [ 0.4862,  2.7343,  0.5833,  ..., -1.9691,  1.3125, -0.2503],\n",
      "         [ 0.9590,  2.1521,  2.4510,  ..., -1.3795,  3.2056, -1.9715],\n",
      "         ...,\n",
      "         [-0.7301,  4.4080,  0.3893,  ..., -2.4533,  1.3943, -1.9242],\n",
      "         [-0.3828,  2.7229, -0.5264,  ..., -2.2487,  2.3393, -1.8647],\n",
      "         [ 0.4424,  0.9601,  1.2190,  ..., -2.6246,  1.2821, -1.8498]],\n",
      "\n",
      "        [[ 2.0888,  4.8807, -0.1373,  ..., -2.5743,  0.6352, -2.0479],\n",
      "         [ 0.8991,  3.1861,  0.1298,  ..., -1.3290,  2.3726,  0.0757],\n",
      "         [ 0.6992,  2.0748, -0.0549,  ..., -1.6680,  1.1359, -1.3139],\n",
      "         ...,\n",
      "         [-1.7569,  3.8718,  0.2956,  ..., -1.3977,  0.4774, -1.7989],\n",
      "         [-2.0313,  1.4181,  0.4877,  ..., -1.7675,  1.2598, -2.0417],\n",
      "         [-0.5871,  3.8035,  1.1131,  ..., -1.4343,  2.2742, -1.1874]],\n",
      "\n",
      "        [[-0.9618,  5.2368,  0.5500,  ..., -1.0728, -0.5200, -0.5960],\n",
      "         [-0.7522,  1.8974,  0.7671,  ...,  0.3537,  2.4976, -0.2547],\n",
      "         [-0.6343,  3.3093,  2.3236,  ..., -2.1307,  1.2919, -0.6844],\n",
      "         ...,\n",
      "         [-0.7296,  4.1518,  0.0352,  ..., -1.8538,  2.2159, -1.1058],\n",
      "         [-1.3213,  0.8838,  0.3831,  ..., -1.8785,  2.4696, -1.2778],\n",
      "         [ 0.8332,  2.2045,  0.1617,  ..., -2.0732,  2.6242, -0.8763]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 89, 64]) , torch.Size([512, 8, 89, 64]), torch.Size([512, 8, 89, 64])\n",
      "Score shape -- torch.Size([512, 8, 89, 89])\n",
      "Mask ---> torch.Size([512, 1, 89])\n",
      "Mask new --> torch.Size([512, 1, 1, 89])\n",
      "loop within encoder. Iteration -- 3\n",
      "this is x in EncoderLayer-----> tensor([[[ 1.3656e-01,  5.2180e+00, -1.4451e+00,  ..., -3.4480e+00,\n",
      "           1.9618e+00, -2.5909e+00],\n",
      "         [-3.7232e-01,  5.8206e+00, -7.3567e-01,  ..., -3.8029e+00,\n",
      "           6.9733e-01, -2.5502e+00],\n",
      "         [ 2.5019e-01,  2.7523e+00, -6.2831e-01,  ..., -3.5933e+00,\n",
      "           6.5953e-01, -2.6729e+00],\n",
      "         ...,\n",
      "         [ 1.1831e+00,  3.9966e+00, -1.6748e+00,  ..., -4.9202e+00,\n",
      "           1.1300e+00, -8.7489e-01],\n",
      "         [-1.2851e+00,  4.6064e+00, -9.0130e-01,  ..., -2.7290e+00,\n",
      "           4.2952e-02, -1.8842e+00],\n",
      "         [ 5.3134e-01,  4.8157e-01, -3.6174e-01,  ..., -1.3308e+00,\n",
      "           5.6581e-01, -3.2974e+00]],\n",
      "\n",
      "        [[-1.2159e-01,  5.3472e+00, -6.2364e-01,  ..., -3.6841e+00,\n",
      "          -4.5802e-01, -3.3981e+00],\n",
      "         [ 8.6117e-01,  4.5383e+00, -7.7611e-01,  ..., -4.0479e+00,\n",
      "           1.1372e+00, -1.5860e+00],\n",
      "         [ 1.4240e+00,  4.8325e+00, -2.7963e-01,  ..., -5.4430e+00,\n",
      "           1.1526e+00, -2.5454e+00],\n",
      "         ...,\n",
      "         [ 4.8479e-02,  4.0336e+00, -1.2560e+00,  ..., -5.4351e+00,\n",
      "           2.7332e-01, -2.7551e+00],\n",
      "         [ 5.4570e-01,  2.2721e+00, -5.1720e-01,  ..., -4.8202e+00,\n",
      "          -5.9231e-02, -1.6569e+00],\n",
      "         [ 5.8901e-02,  3.8575e+00,  6.5803e-01,  ..., -4.3867e+00,\n",
      "           1.9584e-01, -2.7912e+00]],\n",
      "\n",
      "        [[-8.9373e-01,  4.7335e+00, -7.4085e-01,  ..., -5.1745e+00,\n",
      "           1.4379e+00,  1.6974e-01],\n",
      "         [ 1.1596e+00,  4.2331e+00, -3.5705e-01,  ..., -5.1749e+00,\n",
      "          -2.4915e-01, -2.2179e+00],\n",
      "         [ 1.4972e+00,  3.1968e+00,  6.7533e-01,  ..., -3.8874e+00,\n",
      "           1.1466e+00, -1.8020e+00],\n",
      "         ...,\n",
      "         [-1.3912e+00,  2.9038e+00, -4.2615e-01,  ..., -5.4272e+00,\n",
      "           6.0100e-01, -2.2635e+00],\n",
      "         [-5.1914e-01,  2.3497e+00, -1.0690e-01,  ..., -6.1544e+00,\n",
      "           7.3918e-01, -1.8599e+00],\n",
      "         [ 4.9425e-01,  2.2292e+00,  5.4757e-01,  ..., -5.3576e+00,\n",
      "           7.2809e-01, -3.1095e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.6905e-01,  6.2666e+00,  1.2143e-01,  ..., -3.6264e+00,\n",
      "          -8.3306e-01, -4.2663e+00],\n",
      "         [ 2.2320e+00,  3.7147e+00,  4.9502e-01,  ..., -4.3775e+00,\n",
      "          -2.7383e-02, -1.3502e+00],\n",
      "         [ 2.3797e+00,  3.6255e+00,  2.3568e+00,  ..., -1.7670e+00,\n",
      "           1.3365e+00, -3.1131e+00],\n",
      "         ...,\n",
      "         [ 1.0668e+00,  5.4763e+00,  3.9846e-01,  ..., -5.4987e+00,\n",
      "           6.4612e-02, -2.7884e+00],\n",
      "         [ 1.7340e+00,  3.3132e+00, -7.6842e-01,  ..., -4.8500e+00,\n",
      "           3.5067e-01, -2.6208e+00],\n",
      "         [ 1.8427e+00,  1.6160e+00,  1.3693e+00,  ..., -4.8051e+00,\n",
      "          -2.9265e-01, -3.3007e+00]],\n",
      "\n",
      "        [[ 3.4967e+00,  5.7184e+00, -6.5177e-01,  ..., -4.8974e+00,\n",
      "          -5.6697e-03, -3.4236e+00],\n",
      "         [ 1.6585e+00,  4.6429e+00, -1.4372e-01,  ..., -3.4107e+00,\n",
      "           8.3941e-01, -3.9783e-01],\n",
      "         [ 2.0833e+00,  3.3568e+00, -7.9537e-01,  ..., -2.2652e+00,\n",
      "          -2.9310e-01, -2.4156e+00],\n",
      "         ...,\n",
      "         [-1.0649e+00,  5.2764e+00,  2.3003e-01,  ..., -4.1484e+00,\n",
      "          -1.1114e+00, -2.1984e+00],\n",
      "         [-4.9678e-01,  2.6106e+00,  1.5573e-01,  ..., -4.2023e+00,\n",
      "          -5.8955e-01, -2.9397e+00],\n",
      "         [-1.7480e-01,  5.0828e+00,  8.4278e-01,  ..., -4.2227e+00,\n",
      "           5.5680e-01, -2.3012e+00]],\n",
      "\n",
      "        [[-4.6546e-01,  5.9367e+00, -1.6096e-02,  ..., -3.8272e+00,\n",
      "          -1.8478e+00, -1.1163e+00],\n",
      "         [ 3.2783e-01,  2.9203e+00,  3.3096e-01,  ..., -2.3206e+00,\n",
      "           9.8907e-01, -1.1242e+00],\n",
      "         [ 7.5008e-02,  3.3704e+00,  1.7235e+00,  ..., -5.0294e+00,\n",
      "          -3.7448e-03, -2.1248e+00],\n",
      "         ...,\n",
      "         [ 1.1597e+00,  5.1268e+00, -5.6483e-02,  ..., -4.8291e+00,\n",
      "           1.0183e+00, -1.7511e+00],\n",
      "         [ 1.8169e-01,  1.3657e+00,  1.1887e-01,  ..., -4.4136e+00,\n",
      "           9.2469e-01, -2.7060e+00],\n",
      "         [ 1.7428e+00,  3.1744e+00, -1.9630e-01,  ..., -5.1983e+00,\n",
      "           1.1330e+00, -1.3601e+00]]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 89, 64]) , torch.Size([512, 8, 89, 64]), torch.Size([512, 8, 89, 64])\n",
      "Score shape -- torch.Size([512, 8, 89, 89])\n",
      "Mask ---> torch.Size([512, 1, 89])\n",
      "Mask new --> torch.Size([512, 1, 1, 89])\n",
      "loop within encoder. Iteration -- 4\n",
      "this is x in EncoderLayer-----> tensor([[[ 0.1366,  6.5112, -4.0824,  ..., -4.4230,  0.9173, -4.8347],\n",
      "         [ 0.0519,  7.0721, -2.9689,  ..., -4.1291, -0.0349, -4.3464],\n",
      "         [ 1.5174,  3.8615, -3.6953,  ..., -4.1525, -0.3673, -4.5138],\n",
      "         ...,\n",
      "         [ 0.8380,  5.4576, -4.0401,  ..., -4.9609,  0.8088, -1.2684],\n",
      "         [-1.8025,  5.8112, -3.5701,  ..., -2.9787, -1.1814, -3.3055],\n",
      "         [ 0.3472,  1.8960, -3.5660,  ..., -1.7422, -0.2908, -4.8780]],\n",
      "\n",
      "        [[-0.2917,  6.5753, -2.5234,  ..., -4.1192, -1.5435, -4.7013],\n",
      "         [ 0.4137,  6.0222, -2.2722,  ..., -4.2955,  1.0639, -3.6393],\n",
      "         [ 1.2127,  6.0859, -1.6165,  ..., -5.8198,  0.8402, -4.4724],\n",
      "         ...,\n",
      "         [ 0.2031,  5.2023, -2.5272,  ..., -5.5763, -0.5345, -4.9098],\n",
      "         [ 0.4158,  2.7616, -2.3935,  ..., -5.0491, -0.5902, -3.1542],\n",
      "         [ 0.0752,  5.0269, -0.8642,  ..., -4.1286, -0.4471, -4.8305]],\n",
      "\n",
      "        [[-1.6170,  6.0384, -3.1579,  ..., -5.8758,  1.1302, -1.5568],\n",
      "         [ 0.8319,  5.2802, -3.1260,  ..., -6.0401, -0.5506, -3.9531],\n",
      "         [ 1.7205,  4.1206, -1.8199,  ..., -4.2247,  1.5090, -3.8278],\n",
      "         ...,\n",
      "         [-0.6901,  3.7934, -3.1493,  ..., -6.4619, -0.0153, -4.0216],\n",
      "         [ 0.1513,  3.5145, -2.4167,  ..., -6.6447,  0.5696, -3.6216],\n",
      "         [ 0.1150,  3.2784, -1.9678,  ..., -6.1819, -0.0356, -3.1069]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.8397,  7.3159, -2.0033,  ..., -5.0329, -1.5387, -5.4706],\n",
      "         [ 2.1160,  5.1992,  0.4950,  ..., -5.2006, -0.0274, -2.3659],\n",
      "         [ 2.0847,  4.4564,  1.5871,  ..., -1.9650,  0.6430, -4.6318],\n",
      "         ...,\n",
      "         [ 1.5220,  6.3454, -2.1112,  ..., -6.0226, -0.7031, -3.6271],\n",
      "         [ 1.2215,  4.7303, -2.5707,  ..., -5.5363, -0.2574, -4.0500],\n",
      "         [ 1.5989,  2.0238, -1.1714,  ..., -5.6637,  0.2708, -3.8244]],\n",
      "\n",
      "        [[ 3.8689,  7.2446, -0.9971,  ..., -5.6053, -0.9657, -5.6209],\n",
      "         [ 1.9087,  6.0681, -1.8495,  ..., -4.1702, -0.2545, -2.4390],\n",
      "         [ 2.3526,  4.9011, -3.3320,  ..., -2.0551, -0.8536, -4.4788],\n",
      "         ...,\n",
      "         [-1.0929,  6.5027, -1.5559,  ..., -4.9278, -1.6364, -3.7158],\n",
      "         [-0.4736,  4.2637, -2.1479,  ..., -3.9956, -1.9707, -3.7606],\n",
      "         [-0.0577,  5.1134, -0.7133,  ..., -4.7958, -0.7430, -2.9023]],\n",
      "\n",
      "        [[-1.3765,  6.4976, -2.6112,  ..., -4.1719, -2.3348, -3.0324],\n",
      "         [ 0.7168,  2.7393, -1.5326,  ..., -2.5882,  0.2278, -3.1039],\n",
      "         [-0.3908,  3.3696, -0.8104,  ..., -4.9259, -0.7042, -3.9320],\n",
      "         ...,\n",
      "         [ 0.7700,  5.1814, -2.9231,  ..., -4.9987,  0.6150, -3.6684],\n",
      "         [-0.5485,  2.1545, -1.5197,  ..., -4.2595, -0.0620, -4.5454],\n",
      "         [ 2.8867,  3.8811, -1.3701,  ..., -5.4130,  0.5755, -2.4142]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 89, 64]) , torch.Size([512, 8, 89, 64]), torch.Size([512, 8, 89, 64])\n",
      "Score shape -- torch.Size([512, 8, 89, 89])\n",
      "Mask ---> torch.Size([512, 1, 89])\n",
      "Mask new --> torch.Size([512, 1, 1, 89])\n",
      "loop within encoder. Iteration -- 5\n",
      "this is x in EncoderLayer-----> tensor([[[ 0.5568,  5.4902, -3.5608,  ..., -4.6000,  0.4248, -4.0764],\n",
      "         [ 0.7451,  5.3825, -2.3070,  ..., -5.8733, -0.1167, -2.0540],\n",
      "         [ 3.0183,  2.6483, -3.4796,  ..., -4.9288,  0.0931, -2.7272],\n",
      "         ...,\n",
      "         [ 1.9778,  3.9934, -4.9395,  ..., -7.1884,  0.4414,  0.5125],\n",
      "         [-0.9419,  4.8310, -3.4464,  ..., -2.9787, -1.2046, -1.3908],\n",
      "         [ 1.2895,  0.7336, -2.7204,  ..., -3.1584, -0.4709, -3.1435]],\n",
      "\n",
      "        [[ 0.3177,  5.3221, -2.2957,  ..., -6.6456, -1.9735, -2.7906],\n",
      "         [ 1.4758,  4.4041, -1.9504,  ..., -6.2864,  1.1571, -1.7016],\n",
      "         [ 3.0052,  4.5829, -1.1503,  ..., -7.6519,  0.0596, -2.6508],\n",
      "         ...,\n",
      "         [ 2.1385,  4.0799, -2.2794,  ..., -8.2806, -0.5736, -3.0997],\n",
      "         [ 2.5710,  1.0770, -2.2620,  ..., -7.2641, -0.8654, -2.2215],\n",
      "         [ 1.8336,  5.0269, -1.3068,  ..., -6.7305, -0.7392, -3.3864]],\n",
      "\n",
      "        [[-1.3371,  5.0927, -2.6792,  ..., -8.4082,  1.1256,  0.5837],\n",
      "         [ 1.8145,  3.5540, -2.8623,  ..., -8.4743, -1.0359, -1.4854],\n",
      "         [ 2.5674,  3.1808, -2.8293,  ..., -6.5942,  1.8510, -1.5738],\n",
      "         ...,\n",
      "         [ 0.7087,  1.9684, -1.9520,  ..., -7.1772, -0.3360, -2.2176],\n",
      "         [ 0.3404,  3.2731, -2.3991,  ..., -8.5313,  0.3854, -1.1773],\n",
      "         [ 1.1496,  2.0240, -1.8856,  ..., -8.6068, -0.4496, -0.9884]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.9654,  5.6182, -1.9059,  ..., -7.5580, -0.3941, -2.6018],\n",
      "         [ 3.7411,  3.6193,  0.4249,  ..., -5.6349, -0.4940, -1.3434],\n",
      "         [ 3.3576,  2.9165,  2.1595,  ..., -4.2199,  0.2522, -1.7361],\n",
      "         ...,\n",
      "         [ 2.7969,  5.3312, -1.4014,  ..., -7.9609, -0.6882, -1.6093],\n",
      "         [ 2.9937,  2.9324, -2.8717,  ..., -8.0881,  0.1343, -2.1558],\n",
      "         [ 3.1622,  0.2317, -1.1957,  ..., -7.3780, -0.2352, -1.7049]],\n",
      "\n",
      "        [[ 5.5864,  6.3429,  0.0784,  ..., -7.8647, -1.1346, -4.0165],\n",
      "         [ 2.5006,  4.7054, -1.2381,  ..., -6.5414, -0.3997, -0.7710],\n",
      "         [ 3.5545,  3.1229, -3.6030,  ..., -4.0464, -0.4638, -3.2928],\n",
      "         ...,\n",
      "         [-0.1983,  4.6174, -2.3432,  ..., -7.5370, -1.8501, -2.4553],\n",
      "         [ 0.8714,  2.4130, -1.2693,  ..., -5.8080, -2.5539, -2.4016],\n",
      "         [ 1.1908,  4.0266,  0.0763,  ..., -6.9927, -1.0005, -1.5723]],\n",
      "\n",
      "        [[-0.3605,  5.1953, -2.7266,  ..., -4.1719, -2.2925, -0.3905],\n",
      "         [ 1.1052,  1.6014, -0.5512,  ..., -4.9365,  0.4377, -1.3901],\n",
      "         [ 0.2229,  1.8121, -0.1235,  ..., -6.8686, -0.9059, -3.0953],\n",
      "         ...,\n",
      "         [ 1.9267,  4.1010, -2.5849,  ..., -6.7398,  0.4579, -1.9519],\n",
      "         [-0.1842,  0.3511, -1.4426,  ..., -5.7398, -0.1404, -2.4170],\n",
      "         [ 3.6122,  2.0389, -0.2303,  ..., -7.8424,  0.3316, -0.1268]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 89, 64]) , torch.Size([512, 8, 89, 64]), torch.Size([512, 8, 89, 64])\n",
      "Score shape -- torch.Size([512, 8, 89, 89])\n",
      "Mask ---> torch.Size([512, 1, 89])\n",
      "Mask new --> torch.Size([512, 1, 1, 89])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 91])\n",
      "Mask ---> torch.Size([512, 91, 91])\n",
      "Mask new --> torch.Size([512, 1, 91, 91])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 89, 64]), torch.Size([512, 8, 89, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 89])\n",
      "Mask ---> torch.Size([512, 1, 89])\n",
      "Mask new --> torch.Size([512, 1, 1, 89])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 91])\n",
      "Mask ---> torch.Size([512, 91, 91])\n",
      "Mask new --> torch.Size([512, 1, 91, 91])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 89, 64]), torch.Size([512, 8, 89, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 89])\n",
      "Mask ---> torch.Size([512, 1, 89])\n",
      "Mask new --> torch.Size([512, 1, 1, 89])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 91])\n",
      "Mask ---> torch.Size([512, 91, 91])\n",
      "Mask new --> torch.Size([512, 1, 91, 91])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 89, 64]), torch.Size([512, 8, 89, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 89])\n",
      "Mask ---> torch.Size([512, 1, 89])\n",
      "Mask new --> torch.Size([512, 1, 1, 89])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 91])\n",
      "Mask ---> torch.Size([512, 91, 91])\n",
      "Mask new --> torch.Size([512, 1, 91, 91])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 89, 64]), torch.Size([512, 8, 89, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 89])\n",
      "Mask ---> torch.Size([512, 1, 89])\n",
      "Mask new --> torch.Size([512, 1, 1, 89])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 91])\n",
      "Mask ---> torch.Size([512, 91, 91])\n",
      "Mask new --> torch.Size([512, 1, 91, 91])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 89, 64]), torch.Size([512, 8, 89, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 89])\n",
      "Mask ---> torch.Size([512, 1, 89])\n",
      "Mask new --> torch.Size([512, 1, 1, 89])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 91])\n",
      "Mask ---> torch.Size([512, 91, 91])\n",
      "Mask new --> torch.Size([512, 1, 91, 91])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 89, 64]), torch.Size([512, 8, 89, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 89])\n",
      "Mask ---> torch.Size([512, 1, 89])\n",
      "Mask new --> torch.Size([512, 1, 1, 89])\n",
      "predictions size : tensor([[-0.4157, -0.3107,  0.2332,  ..., -0.3386, -0.2376,  0.0113],\n",
      "        [-0.3351, -0.3189,  0.2486,  ..., -0.1919, -0.0660,  0.0520],\n",
      "        [-0.3039, -0.3591,  0.1641,  ..., -0.1754, -0.0855,  0.0020],\n",
      "        ...,\n",
      "        [-0.3722, -0.3032,  0.3244,  ..., -0.2556,  0.0653,  0.1369],\n",
      "        [-0.2886, -0.2962,  0.2469,  ...,  0.0077, -0.0263,  0.0201],\n",
      "        [-0.4819, -0.2161,  0.3265,  ..., -0.1376,  0.0103,  0.2134]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "targets size : torch.Size([46592])\n",
      "Loss.data ----> = 8.567496299743652\n",
      "--Encoder x after PE : tensor([[[-0.5232,  0.9206,  0.0000,  ...,  0.5221, -0.6329,  0.7908],\n",
      "         [ 0.0000,  0.1396,  0.0000,  ...,  0.0000, -0.1565,  0.9056],\n",
      "         [ 0.8303, -0.0000,  0.7046,  ...,  1.2177,  0.0000,  1.1586],\n",
      "         ...,\n",
      "         [-0.6890, -0.4661,  0.1307,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.0000, -1.2464,  1.1276,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [ 0.1341, -0.0000,  1.7377,  ...,  1.0595,  0.1775,  0.0000]],\n",
      "\n",
      "        [[ 0.5691,  1.2791,  0.1878,  ...,  0.8959, -0.2493,  0.5556],\n",
      "         [ 0.7383,  0.0878,  0.5240,  ...,  1.2248,  0.0215,  1.5780],\n",
      "         [ 0.9728, -0.8356,  1.5831,  ...,  0.9821,  0.5266,  1.6292],\n",
      "         ...,\n",
      "         [-0.6890, -0.4661,  0.1307,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.7361, -1.2464,  1.1276,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.1341, -1.1375,  1.7377,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.5619,  0.0000,  0.0983,  ...,  1.3252,  0.4901,  1.2065],\n",
      "         [ 0.0000,  0.5509,  0.8568,  ...,  1.3785, -0.4903,  1.0262],\n",
      "         [ 0.8303, -1.0084,  0.7046,  ...,  1.2177,  0.1659,  1.1586],\n",
      "         ...,\n",
      "         [-0.5838, -0.2867, -0.9218,  ...,  1.5179,  0.4996,  1.4808],\n",
      "         [-0.0000, -0.7864, -0.1373,  ...,  1.7189, -0.0191,  0.7553],\n",
      "         [-0.0000, -0.6547,  0.8769,  ...,  0.7245,  0.0000,  1.1674]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "loop within encoder. Iteration -- 0\n",
      "this is x in EncoderLayer-----> tensor([[[-0.5232,  0.9206,  0.0000,  ...,  0.5221, -0.6329,  0.7908],\n",
      "         [ 0.0000,  0.1396,  0.0000,  ...,  0.0000, -0.1565,  0.9056],\n",
      "         [ 0.8303, -0.0000,  0.7046,  ...,  1.2177,  0.0000,  1.1586],\n",
      "         ...,\n",
      "         [-0.6890, -0.4661,  0.1307,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.0000, -1.2464,  1.1276,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [ 0.1341, -0.0000,  1.7377,  ...,  1.0595,  0.1775,  0.0000]],\n",
      "\n",
      "        [[ 0.5691,  1.2791,  0.1878,  ...,  0.8959, -0.2493,  0.5556],\n",
      "         [ 0.7383,  0.0878,  0.5240,  ...,  1.2248,  0.0215,  1.5780],\n",
      "         [ 0.9728, -0.8356,  1.5831,  ...,  0.9821,  0.5266,  1.6292],\n",
      "         ...,\n",
      "         [-0.6890, -0.4661,  0.1307,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.7361, -1.2464,  1.1276,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.1341, -1.1375,  1.7377,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.5619,  0.0000,  0.0983,  ...,  1.3252,  0.4901,  1.2065],\n",
      "         [ 0.0000,  0.5509,  0.8568,  ...,  1.3785, -0.4903,  1.0262],\n",
      "         [ 0.8303, -1.0084,  0.7046,  ...,  1.2177,  0.1659,  1.1586],\n",
      "         ...,\n",
      "         [-0.5838, -0.2867, -0.9218,  ...,  1.5179,  0.4996,  1.4808],\n",
      "         [-0.0000, -0.7864, -0.1373,  ...,  1.7189, -0.0191,  0.7553],\n",
      "         [-0.0000, -0.6547,  0.8769,  ...,  0.7245,  0.0000,  1.1674]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 70, 64]) , torch.Size([3, 8, 70, 64]), torch.Size([3, 8, 70, 64])\n",
      "Score shape -- torch.Size([3, 8, 70, 70])\n",
      "Mask ---> torch.Size([3, 1, 70])\n",
      "Mask new --> torch.Size([3, 1, 1, 70])\n",
      "loop within encoder. Iteration -- 1\n",
      "this is x in EncoderLayer-----> tensor([[[-2.9315,  2.9812,  0.8676,  ..., -1.3046,  1.0016, -0.1239],\n",
      "         [-1.4322,  2.2242,  0.6297,  ..., -2.0172,  2.6807,  0.9056],\n",
      "         [-0.4579,  2.4832,  1.4207,  ..., -1.0749,  2.9808,  0.5647],\n",
      "         ...,\n",
      "         [-2.0889,  2.2006,  0.8377,  ..., -1.1845,  2.3410, -1.0201],\n",
      "         [-1.3516, -0.0215,  1.2387,  ..., -1.4809,  1.8943,  0.2698],\n",
      "         [-1.4223,  2.7895,  1.8292,  ..., -0.3857,  2.3688, -2.2455]],\n",
      "\n",
      "        [[-1.1866,  3.3629,  1.0140,  ..., -1.0555,  3.5268, -0.0500],\n",
      "         [-0.6235,  2.7799,  1.2644,  ..., -1.2238,  0.6774,  1.5341],\n",
      "         [-1.2825,  1.7207,  2.1518,  ..., -1.8431,  1.4614,  0.9478],\n",
      "         ...,\n",
      "         [-2.3481,  2.2056,  0.3656,  ..., -1.1862,  2.9108, -0.9861],\n",
      "         [-0.5527,  1.3761,  1.7815,  ..., -1.5545,  3.4917,  0.0974],\n",
      "         [-0.9118,  0.1898,  2.5538,  ..., -2.0415,  1.6617,  0.1234]],\n",
      "\n",
      "        [[-1.8576,  2.3175, -0.4831,  ...,  0.3962,  1.2761,  0.4788],\n",
      "         [-1.6842,  2.8164,  0.9595,  ...,  0.4822,  1.3516, -0.1326],\n",
      "         [-1.2569,  1.3795,  0.9751,  ...,  0.0149,  2.4960,  0.5684],\n",
      "         ...,\n",
      "         [-2.0781,  0.3263, -0.6287,  ...,  0.2538,  2.1495, -0.2937],\n",
      "         [-1.1140,  1.6295, -0.1373,  ...,  0.8014,  1.8307, -0.8270],\n",
      "         [-1.8034, -0.0087,  0.6577,  ..., -0.5061,  2.4736, -0.7552]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 70, 64]) , torch.Size([3, 8, 70, 64]), torch.Size([3, 8, 70, 64])\n",
      "Score shape -- torch.Size([3, 8, 70, 70])\n",
      "Mask ---> torch.Size([3, 1, 70])\n",
      "Mask new --> torch.Size([3, 1, 1, 70])\n",
      "loop within encoder. Iteration -- 2\n",
      "this is x in EncoderLayer-----> tensor([[[-1.9705,  3.4050,  0.8825,  ..., -2.4341,  0.9047, -1.5502],\n",
      "         [-0.0262,  3.1175,  1.4062,  ..., -3.2693,  2.6509, -0.0645],\n",
      "         [-0.1763,  3.0636,  1.4847,  ..., -2.6899,  3.6034, -0.4437],\n",
      "         ...,\n",
      "         [-1.6069,  2.9531,  0.5977,  ..., -2.3154,  2.1600, -1.2470],\n",
      "         [-0.8764,  0.4461,  1.0614,  ..., -3.1921,  1.8686, -0.3387],\n",
      "         [-0.9860,  3.3647,  1.7671,  ..., -1.5360,  2.0502, -2.3378]],\n",
      "\n",
      "        [[ 0.3362,  3.9114,  0.8275,  ..., -3.1745,  3.6900, -0.0087],\n",
      "         [-0.0352,  3.9282,  0.6409,  ..., -1.2238,  0.8779, -0.1015],\n",
      "         [-0.1576,  3.3402,  2.4405,  ..., -2.9917,  1.3679, -0.1807],\n",
      "         ...,\n",
      "         [-1.4674,  3.3904,  0.2188,  ..., -3.1710,  3.1502, -1.8151],\n",
      "         [-0.1406,  1.9079,  0.8318,  ..., -3.0795,  3.0115, -1.1011],\n",
      "         [-0.1363,  1.0002,  2.1867,  ..., -3.5491,  1.5912, -0.9564]],\n",
      "\n",
      "        [[-1.5978,  4.0961, -0.0677,  ...,  0.1195,  1.3940, -1.1461],\n",
      "         [-1.3732,  2.8164,  1.0297,  ..., -1.8381,  0.8900, -0.5886],\n",
      "         [ 0.0067,  0.9477, -0.0423,  ..., -1.5517,  2.0948, -0.2947],\n",
      "         ...,\n",
      "         [-1.4403,  1.3705, -0.1979,  ..., -0.5650,  2.5842, -0.8101],\n",
      "         [-1.0591,  3.3506, -0.2533,  ..., -1.0497,  1.8307, -2.1915],\n",
      "         [-1.2716,  1.2127,  0.5022,  ..., -1.3748,  3.0530, -1.2978]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 70, 64]) , torch.Size([3, 8, 70, 64]), torch.Size([3, 8, 70, 64])\n",
      "Score shape -- torch.Size([3, 8, 70, 70])\n",
      "Mask ---> torch.Size([3, 1, 70])\n",
      "Mask new --> torch.Size([3, 1, 1, 70])\n",
      "loop within encoder. Iteration -- 3\n",
      "this is x in EncoderLayer-----> tensor([[[-1.3055,  4.2724,  0.3235,  ..., -3.0533,  1.2016, -2.7722],\n",
      "         [ 0.6062,  4.5374,  0.4182,  ..., -5.4758,  0.9612, -1.6541],\n",
      "         [ 0.6946,  4.3646,  0.0380,  ..., -3.3244,  2.5424, -1.7109],\n",
      "         ...,\n",
      "         [-1.6058,  4.0973, -0.2501,  ..., -5.5145,  0.9711, -2.6419],\n",
      "         [ 0.2450,  1.5426,  0.5274,  ..., -6.0041,  0.4241, -1.0159],\n",
      "         [-0.1274,  4.5408,  0.8373,  ..., -4.3538,  2.0916, -3.4309]],\n",
      "\n",
      "        [[ 1.0693,  4.8711,  0.6006,  ..., -5.9187,  2.2037, -1.8797],\n",
      "         [ 0.8994,  4.0482,  0.0578,  ..., -4.6360, -0.4877, -0.9801],\n",
      "         [ 0.0622,  4.2584,  2.6971,  ..., -5.3237,  0.2453, -0.8900],\n",
      "         ...,\n",
      "         [-0.5525,  4.1001,  0.5094,  ..., -6.3900,  3.0266, -2.5306],\n",
      "         [ 0.8200,  2.2879, -0.0710,  ..., -6.1233,  1.1933, -2.2769],\n",
      "         [ 1.5307,  1.7700,  1.6537,  ..., -6.8153,  0.2385, -1.3931]],\n",
      "\n",
      "        [[-0.4476,  5.0315, -0.8465,  ..., -2.7967,  1.3890, -2.2243],\n",
      "         [-0.1296,  3.6007,  0.4400,  ..., -2.1283, -1.0750, -2.3267],\n",
      "         [ 0.8766,  1.8057, -0.9940,  ..., -4.6340,  0.7017, -0.5203],\n",
      "         ...,\n",
      "         [-1.4403,  1.9920, -1.4401,  ..., -3.7765,  1.2411, -1.5947],\n",
      "         [ 0.3143,  4.4215, -1.0068,  ..., -1.8081,  0.5615, -3.0597],\n",
      "         [-0.7489,  1.7662,  0.6255,  ..., -4.1101,  1.2577, -1.5332]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 70, 64]) , torch.Size([3, 8, 70, 64]), torch.Size([3, 8, 70, 64])\n",
      "Score shape -- torch.Size([3, 8, 70, 70])\n",
      "Mask ---> torch.Size([3, 1, 70])\n",
      "Mask new --> torch.Size([3, 1, 1, 70])\n",
      "loop within encoder. Iteration -- 4\n",
      "this is x in EncoderLayer-----> tensor([[[-0.4417,  6.1304, -2.0139,  ..., -4.3218,  0.3600, -4.4926],\n",
      "         [ 0.3640,  5.4500, -1.2374,  ..., -6.1292,  0.1410, -3.9041],\n",
      "         [-0.1299,  5.8985, -2.4565,  ..., -4.4962,  1.8744, -3.4917],\n",
      "         ...,\n",
      "         [-2.0088,  5.0591, -2.7079,  ..., -6.4283,  0.5482, -4.4867],\n",
      "         [ 0.8069,  1.2723, -1.6737,  ..., -7.2519, -0.5508, -2.0626],\n",
      "         [-0.2034,  4.4920, -1.5303,  ..., -5.6531,  0.7856, -5.4810]],\n",
      "\n",
      "        [[ 0.3322,  6.1161, -1.8159,  ..., -6.8815,  2.6484, -3.5579],\n",
      "         [ 0.6471,  5.2163, -2.5752,  ..., -5.4331, -0.1539, -2.2608],\n",
      "         [-0.0705,  5.6891,  0.1709,  ..., -6.0408,  0.4912, -2.4125],\n",
      "         ...,\n",
      "         [-1.2111,  5.4882, -1.5807,  ..., -7.1807,  2.7513, -4.4091],\n",
      "         [ 0.7349,  4.0158, -2.3195,  ..., -5.9936,  1.0998, -4.1894],\n",
      "         [ 1.1313,  3.2473, -0.7571,  ..., -7.8428,  0.9045, -2.5113]],\n",
      "\n",
      "        [[ 0.5387,  5.0077, -3.9268,  ..., -3.0658, -0.0496, -3.9005],\n",
      "         [-0.8125,  4.3390, -1.4835,  ..., -2.7983, -1.2435, -3.6447],\n",
      "         [ 0.1143,  2.9240, -2.9944,  ..., -5.6964, -0.7689, -1.8142],\n",
      "         ...,\n",
      "         [-1.5492,  3.3541, -4.5529,  ..., -3.7915, -0.1205, -3.8415],\n",
      "         [-0.1003,  5.4526, -3.9350,  ..., -1.8770, -0.5574, -4.5456],\n",
      "         [-1.2153,  2.8413, -2.3375,  ..., -4.5357,  2.4743, -3.4634]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 70, 64]) , torch.Size([3, 8, 70, 64]), torch.Size([3, 8, 70, 64])\n",
      "Score shape -- torch.Size([3, 8, 70, 70])\n",
      "Mask ---> torch.Size([3, 1, 70])\n",
      "Mask new --> torch.Size([3, 1, 1, 70])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop within encoder. Iteration -- 5\n",
      "this is x in EncoderLayer-----> tensor([[[  0.5796,   5.3307,  -2.3741,  ...,  -5.2855,   1.1693,  -4.4926],\n",
      "         [  2.0855,   4.2141,  -0.7107,  ...,  -8.4357,  -0.6645,  -2.5086],\n",
      "         [  1.4739,   4.8020,  -1.6681,  ...,  -5.0307,   2.4531,  -1.9225],\n",
      "         ...,\n",
      "         [ -0.7318,   4.3292,  -1.6974,  ...,  -8.9682,   0.7243,  -2.5219],\n",
      "         [  2.3301,   0.5871,  -1.2639,  ...,  -7.5478,  -0.5319,  -0.1926],\n",
      "         [  0.9651,   3.5720,  -0.7260,  ...,  -5.8632,   0.4134,  -3.6682]],\n",
      "\n",
      "        [[  1.4904,   4.7306,  -1.5127,  ...,  -9.3468,   3.7137,  -1.5286],\n",
      "         [  1.6074,   3.5344,  -1.4772,  ...,  -7.3805,   0.4317,  -1.2360],\n",
      "         [  1.3271,   3.1477,   0.7420,  ...,  -8.7358,   1.0437,   0.1583],\n",
      "         ...,\n",
      "         [ -0.2570,   4.0135,  -1.6634,  ...,  -9.0268,   3.6578,  -3.3951],\n",
      "         [  2.0639,   2.4502,  -3.2367,  ...,  -7.8102,   1.6374,  -2.3330],\n",
      "         [  2.2615,   1.5472,  -0.1701,  ..., -10.1188,   1.5185,  -0.5640]],\n",
      "\n",
      "        [[  1.8292,   3.5996,  -2.6651,  ...,  -4.0517,  -0.0788,  -1.6716],\n",
      "         [  0.1731,   3.3036,  -0.8629,  ...,  -5.1249,  -0.8508,  -2.4836],\n",
      "         [  0.3793,   1.3047,  -3.4279,  ...,  -7.7376,  -0.0534,  -0.2554],\n",
      "         ...,\n",
      "         [ -1.2571,   2.0335,  -3.7983,  ...,  -5.5963,   0.0717,  -2.0268],\n",
      "         [  0.6681,   4.5966,  -2.6574,  ...,  -4.0854,  -0.4300,  -3.7399],\n",
      "         [ -0.1363,   1.9077,  -1.6792,  ...,  -4.7026,   2.9734,  -1.4531]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 70, 64]) , torch.Size([3, 8, 70, 64]), torch.Size([3, 8, 70, 64])\n",
      "Score shape -- torch.Size([3, 8, 70, 70])\n",
      "Mask ---> torch.Size([3, 1, 70])\n",
      "Mask new --> torch.Size([3, 1, 1, 70])\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 74, 64]) , torch.Size([3, 8, 74, 64]), torch.Size([3, 8, 74, 64])\n",
      "Score shape -- torch.Size([3, 8, 74, 74])\n",
      "Mask ---> torch.Size([3, 74, 74])\n",
      "Mask new --> torch.Size([3, 1, 74, 74])\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 74, 64]) , torch.Size([3, 8, 70, 64]), torch.Size([3, 8, 70, 64])\n",
      "Score shape -- torch.Size([3, 8, 74, 70])\n",
      "Mask ---> torch.Size([3, 1, 70])\n",
      "Mask new --> torch.Size([3, 1, 1, 70])\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 74, 64]) , torch.Size([3, 8, 74, 64]), torch.Size([3, 8, 74, 64])\n",
      "Score shape -- torch.Size([3, 8, 74, 74])\n",
      "Mask ---> torch.Size([3, 74, 74])\n",
      "Mask new --> torch.Size([3, 1, 74, 74])\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 74, 64]) , torch.Size([3, 8, 70, 64]), torch.Size([3, 8, 70, 64])\n",
      "Score shape -- torch.Size([3, 8, 74, 70])\n",
      "Mask ---> torch.Size([3, 1, 70])\n",
      "Mask new --> torch.Size([3, 1, 1, 70])\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 74, 64]) , torch.Size([3, 8, 74, 64]), torch.Size([3, 8, 74, 64])\n",
      "Score shape -- torch.Size([3, 8, 74, 74])\n",
      "Mask ---> torch.Size([3, 74, 74])\n",
      "Mask new --> torch.Size([3, 1, 74, 74])\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 74, 64]) , torch.Size([3, 8, 70, 64]), torch.Size([3, 8, 70, 64])\n",
      "Score shape -- torch.Size([3, 8, 74, 70])\n",
      "Mask ---> torch.Size([3, 1, 70])\n",
      "Mask new --> torch.Size([3, 1, 1, 70])\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 74, 64]) , torch.Size([3, 8, 74, 64]), torch.Size([3, 8, 74, 64])\n",
      "Score shape -- torch.Size([3, 8, 74, 74])\n",
      "Mask ---> torch.Size([3, 74, 74])\n",
      "Mask new --> torch.Size([3, 1, 74, 74])\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 74, 64]) , torch.Size([3, 8, 70, 64]), torch.Size([3, 8, 70, 64])\n",
      "Score shape -- torch.Size([3, 8, 74, 70])\n",
      "Mask ---> torch.Size([3, 1, 70])\n",
      "Mask new --> torch.Size([3, 1, 1, 70])\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 74, 64]) , torch.Size([3, 8, 74, 64]), torch.Size([3, 8, 74, 64])\n",
      "Score shape -- torch.Size([3, 8, 74, 74])\n",
      "Mask ---> torch.Size([3, 74, 74])\n",
      "Mask new --> torch.Size([3, 1, 74, 74])\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 74, 64]) , torch.Size([3, 8, 70, 64]), torch.Size([3, 8, 70, 64])\n",
      "Score shape -- torch.Size([3, 8, 74, 70])\n",
      "Mask ---> torch.Size([3, 1, 70])\n",
      "Mask new --> torch.Size([3, 1, 1, 70])\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 74, 64]) , torch.Size([3, 8, 74, 64]), torch.Size([3, 8, 74, 64])\n",
      "Score shape -- torch.Size([3, 8, 74, 74])\n",
      "Mask ---> torch.Size([3, 74, 74])\n",
      "Mask new --> torch.Size([3, 1, 74, 74])\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 74, 64]) , torch.Size([3, 8, 70, 64]), torch.Size([3, 8, 70, 64])\n",
      "Score shape -- torch.Size([3, 8, 74, 70])\n",
      "Mask ---> torch.Size([3, 1, 70])\n",
      "Mask new --> torch.Size([3, 1, 1, 70])\n",
      "predictions size : tensor([[-0.2858, -0.2172,  0.1739,  ..., -0.3615, -0.3648,  0.4364],\n",
      "        [-0.3756, -0.3408,  0.0758,  ..., -0.3004, -0.1413,  0.2012],\n",
      "        [-0.4177, -0.3884,  0.2555,  ..., -0.3493, -0.0953,  0.2891],\n",
      "        ...,\n",
      "        [-0.4124, -0.3193,  0.2457,  ..., -0.2266,  0.0309,  0.2003],\n",
      "        [-0.4060, -0.2999,  0.1567,  ..., -0.2453, -0.0298,  0.0511],\n",
      "        [-0.5687, -0.2380,  0.2113,  ..., -0.2949, -0.0066,  0.0250]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "targets size : torch.Size([222])\n",
      "Loss.data ----> = 8.595947265625\n",
      "--Encoder x after PE : tensor([[[-0.0284,  0.0000,  0.4604,  ...,  1.3406,  0.0874,  0.9737],\n",
      "         [ 1.2894,  0.2463,  1.4934,  ...,  0.8358,  0.2688,  1.3487],\n",
      "         [ 0.4169, -0.8831,  0.0000,  ...,  1.7109, -0.1544,  0.9044],\n",
      "         ...,\n",
      "         [-0.4383, -1.2356,  0.6229,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.6096, -1.1531,  1.5235,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.3376, -0.2617,  1.7185,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.5623,  0.0000,  0.0969,  ...,  1.3268,  0.4898,  1.2065],\n",
      "         [ 0.2785,  0.0467,  0.0000,  ...,  1.5194,  0.6491,  0.6313],\n",
      "         [ 0.8300, -1.0068,  0.7027,  ...,  1.2175,  0.1665,  1.1574],\n",
      "         ...,\n",
      "         [-0.4383, -1.2356,  0.6229,  ...,  0.0000,  0.1775,  0.5406],\n",
      "         [ 0.6096, -1.1531,  1.5235,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [ 1.3376, -0.2617,  1.7185,  ...,  1.0595,  0.1775,  0.0000]],\n",
      "\n",
      "        [[ 0.5701,  1.2794,  0.1879,  ...,  0.8970, -0.2479,  0.5542],\n",
      "         [ 0.8300,  0.2162,  0.8937,  ...,  1.2780, -0.5116,  0.8472],\n",
      "         [ 0.5678, -0.0147,  0.4599,  ...,  1.7517, -0.4476,  0.5709],\n",
      "         ...,\n",
      "         [-0.4383, -0.0000,  0.6229,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [ 0.6096, -1.1531,  1.5235,  ...,  0.0000,  0.1775,  0.5406],\n",
      "         [ 1.3376, -0.2617,  0.0000,  ...,  1.0595,  0.0000,  0.5406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.2441,  0.8745,  0.0000,  ...,  0.8458, -0.4629,  1.0884],\n",
      "         [ 0.0000,  0.0914,  0.9596,  ...,  1.5559,  0.1288,  1.5539],\n",
      "         [ 1.1333,  0.1863,  0.5138,  ...,  1.6254, -0.0000,  0.5070],\n",
      "         ...,\n",
      "         [-0.4383, -1.2356,  0.6229,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.6096, -0.0000,  1.5235,  ...,  0.0000,  0.1775,  0.5406],\n",
      "         [ 1.3376, -0.2617,  1.7185,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.5145,  0.6432,  0.6565,  ...,  1.1624,  0.0000,  1.1686],\n",
      "         [ 0.3701,  0.3926,  0.0000,  ...,  0.0000,  0.5690,  1.0716],\n",
      "         [ 1.3948, -1.0271,  0.7790,  ...,  1.7621, -0.0886,  0.7927],\n",
      "         ...,\n",
      "         [-0.4383, -1.2356,  0.6229,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.6096, -1.1531,  0.0000,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.3376, -0.0000,  1.7185,  ...,  0.0000,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.5701,  1.2794,  0.1879,  ...,  0.8970, -0.2479,  0.5542],\n",
      "         [ 0.9834,  0.2655,  1.2237,  ...,  0.8497, -0.3327,  1.3329],\n",
      "         [ 1.0684, -0.8375,  0.8396,  ...,  1.3633,  0.1000,  0.6028],\n",
      "         ...,\n",
      "         [-0.0000, -1.2356,  0.6229,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.6096, -1.1531,  1.5235,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.3376, -0.2617,  1.7185,  ...,  1.0595,  0.1775,  0.5406]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "loop within encoder. Iteration -- 0\n",
      "this is x in EncoderLayer-----> tensor([[[-0.0284,  0.0000,  0.4604,  ...,  1.3406,  0.0874,  0.9737],\n",
      "         [ 1.2894,  0.2463,  1.4934,  ...,  0.8358,  0.2688,  1.3487],\n",
      "         [ 0.4169, -0.8831,  0.0000,  ...,  1.7109, -0.1544,  0.9044],\n",
      "         ...,\n",
      "         [-0.4383, -1.2356,  0.6229,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.6096, -1.1531,  1.5235,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.3376, -0.2617,  1.7185,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.5623,  0.0000,  0.0969,  ...,  1.3268,  0.4898,  1.2065],\n",
      "         [ 0.2785,  0.0467,  0.0000,  ...,  1.5194,  0.6491,  0.6313],\n",
      "         [ 0.8300, -1.0068,  0.7027,  ...,  1.2175,  0.1665,  1.1574],\n",
      "         ...,\n",
      "         [-0.4383, -1.2356,  0.6229,  ...,  0.0000,  0.1775,  0.5406],\n",
      "         [ 0.6096, -1.1531,  1.5235,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [ 1.3376, -0.2617,  1.7185,  ...,  1.0595,  0.1775,  0.0000]],\n",
      "\n",
      "        [[ 0.5701,  1.2794,  0.1879,  ...,  0.8970, -0.2479,  0.5542],\n",
      "         [ 0.8300,  0.2162,  0.8937,  ...,  1.2780, -0.5116,  0.8472],\n",
      "         [ 0.5678, -0.0147,  0.4599,  ...,  1.7517, -0.4476,  0.5709],\n",
      "         ...,\n",
      "         [-0.4383, -0.0000,  0.6229,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [ 0.6096, -1.1531,  1.5235,  ...,  0.0000,  0.1775,  0.5406],\n",
      "         [ 1.3376, -0.2617,  0.0000,  ...,  1.0595,  0.0000,  0.5406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.2441,  0.8745,  0.0000,  ...,  0.8458, -0.4629,  1.0884],\n",
      "         [ 0.0000,  0.0914,  0.9596,  ...,  1.5559,  0.1288,  1.5539],\n",
      "         [ 1.1333,  0.1863,  0.5138,  ...,  1.6254, -0.0000,  0.5070],\n",
      "         ...,\n",
      "         [-0.4383, -1.2356,  0.6229,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.6096, -0.0000,  1.5235,  ...,  0.0000,  0.1775,  0.5406],\n",
      "         [ 1.3376, -0.2617,  1.7185,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.5145,  0.6432,  0.6565,  ...,  1.1624,  0.0000,  1.1686],\n",
      "         [ 0.3701,  0.3926,  0.0000,  ...,  0.0000,  0.5690,  1.0716],\n",
      "         [ 1.3948, -1.0271,  0.7790,  ...,  1.7621, -0.0886,  0.7927],\n",
      "         ...,\n",
      "         [-0.4383, -1.2356,  0.6229,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.6096, -1.1531,  0.0000,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.3376, -0.0000,  1.7185,  ...,  0.0000,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.5701,  1.2794,  0.1879,  ...,  0.8970, -0.2479,  0.5542],\n",
      "         [ 0.9834,  0.2655,  1.2237,  ...,  0.8497, -0.3327,  1.3329],\n",
      "         [ 1.0684, -0.8375,  0.8396,  ...,  1.3633,  0.1000,  0.6028],\n",
      "         ...,\n",
      "         [-0.0000, -1.2356,  0.6229,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.6096, -1.1531,  1.5235,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.3376, -0.2617,  1.7185,  ...,  1.0595,  0.1775,  0.5406]]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 84, 64]) , torch.Size([512, 8, 84, 64]), torch.Size([512, 8, 84, 64])\n",
      "Score shape -- torch.Size([512, 8, 84, 84])\n",
      "Mask ---> torch.Size([512, 1, 84])\n",
      "Mask new --> torch.Size([512, 1, 1, 84])\n",
      "loop within encoder. Iteration -- 1\n",
      "this is x in EncoderLayer-----> tensor([[[-1.8483e+00,  8.5939e-01,  1.1991e+00,  ..., -4.6804e-01,\n",
      "           1.0693e+00,  4.4452e-01],\n",
      "         [ 1.1190e+00,  2.8090e+00,  9.7838e-01,  ..., -1.2101e+00,\n",
      "           2.9374e+00,  4.0845e-01],\n",
      "         [-1.0753e+00,  1.3349e+00,  5.3119e-01,  ..., -3.1184e-01,\n",
      "           2.7698e+00, -1.1215e-01],\n",
      "         ...,\n",
      "         [-1.7659e+00, -5.7324e-01,  7.3938e-01,  ..., -2.4080e+00,\n",
      "           2.5366e+00, -1.0820e+00],\n",
      "         [-1.0609e+00,  8.5476e-01,  9.2553e-01,  ..., -7.4749e-01,\n",
      "           2.4329e+00, -1.4874e+00],\n",
      "         [ 2.2365e+00,  2.2036e+00,  4.6491e-01,  ..., -1.9855e+00,\n",
      "           2.7575e+00, -1.0860e+00]],\n",
      "\n",
      "        [[-2.5009e+00,  2.5003e+00, -3.5937e-01,  ..., -6.9279e-01,\n",
      "           3.0389e+00,  1.3070e-02],\n",
      "         [-4.0877e-01,  1.7417e+00, -3.4149e-01,  ...,  5.9309e-01,\n",
      "           2.8530e+00,  4.2688e-02],\n",
      "         [-7.3667e-01, -1.7618e-01,  5.8204e-01,  ..., -1.1198e-01,\n",
      "           2.9336e+00,  3.4482e-01],\n",
      "         ...,\n",
      "         [-2.1617e+00,  1.1800e+00,  9.3848e-02,  ..., -2.3503e+00,\n",
      "           2.2942e+00, -1.3172e+00],\n",
      "         [-8.2349e-01,  1.3297e+00,  8.7876e-01,  ..., -1.0812e+00,\n",
      "           2.1738e+00, -1.1847e+00],\n",
      "         [-3.4072e-01,  1.9970e+00,  1.4783e+00,  ..., -8.9883e-01,\n",
      "           8.9233e-01, -1.7912e+00]],\n",
      "\n",
      "        [[-1.4527e+00,  3.2651e+00,  2.6830e-02,  ..., -4.1768e-01,\n",
      "           1.9954e+00, -5.5632e-01],\n",
      "         [ 6.3305e-02,  2.3409e+00,  2.6949e-01,  ...,  5.8303e-02,\n",
      "           2.4772e+00, -6.0148e-01],\n",
      "         [-2.1110e+00,  1.9123e+00,  2.1831e-01,  ...,  4.5668e-02,\n",
      "           2.0376e+00, -5.4472e-01],\n",
      "         ...,\n",
      "         [-2.0335e+00,  2.4177e+00,  5.6961e-02,  ..., -8.5141e-01,\n",
      "           1.5678e+00, -9.4476e-01],\n",
      "         [-1.0333e+00,  1.6948e+00,  1.5235e+00,  ..., -1.8002e+00,\n",
      "           1.9651e+00, -1.7669e+00],\n",
      "         [ 8.5272e-02,  3.9774e-01, -1.5138e-01,  ..., -9.5939e-01,\n",
      "           1.7915e+00, -1.0999e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.9402e+00,  3.4370e+00,  6.8836e-01,  ..., -9.6463e-01,\n",
      "           2.1166e+00,  2.5877e-02],\n",
      "         [-3.1025e-01,  2.8836e+00,  5.0443e-01,  ..., -3.9768e-02,\n",
      "           2.3505e+00,  2.7216e-01],\n",
      "         [-8.4393e-02,  2.9661e+00,  1.2739e-01,  ..., -7.9901e-01,\n",
      "           2.7783e+00,  9.7445e-04],\n",
      "         ...,\n",
      "         [-1.7403e+00,  2.0223e+00,  2.0030e-01,  ..., -1.9261e+00,\n",
      "           2.2617e+00, -1.1491e+00],\n",
      "         [-7.1663e-01,  2.8282e+00,  1.9172e+00,  ..., -2.4620e+00,\n",
      "           1.5956e+00, -1.7117e+00],\n",
      "         [ 3.6338e-01,  1.9405e+00,  2.1264e+00,  ..., -1.6491e+00,\n",
      "           2.3856e+00, -5.2714e-01]],\n",
      "\n",
      "        [[-1.8038e+00,  3.0624e+00,  6.3688e-02,  ..., -1.1334e+00,\n",
      "           2.6049e+00,  8.4295e-01],\n",
      "         [-1.6352e+00,  2.6641e+00, -4.4573e-01,  ..., -2.3524e+00,\n",
      "           2.9743e+00, -2.6385e-01],\n",
      "         [ 8.1017e-01,  2.0017e+00,  1.0501e+00,  ..., -6.2480e-01,\n",
      "           1.7540e+00, -2.6462e-01],\n",
      "         ...,\n",
      "         [-1.6504e+00, -1.5111e-01, -2.4900e-01,  ..., -1.7897e+00,\n",
      "           2.8661e+00, -8.9635e-01],\n",
      "         [-2.0101e-01,  1.6959e+00, -1.7096e-01,  ..., -1.5315e+00,\n",
      "           2.3206e+00, -1.2055e+00],\n",
      "         [ 2.6383e-01,  2.7915e+00,  1.6531e+00,  ..., -2.3759e+00,\n",
      "           2.2362e+00, -1.5823e+00]],\n",
      "\n",
      "        [[-8.7612e-01,  2.7393e+00,  1.1559e-01,  ..., -4.7660e-01,\n",
      "           2.5375e+00, -1.0098e+00],\n",
      "         [-7.0054e-01,  2.8352e+00,  5.2737e-01,  ..., -6.0353e-01,\n",
      "           3.0668e+00, -1.3756e-01],\n",
      "         [-7.2567e-01,  1.2934e+00,  1.0819e+00,  ..., -8.2507e-02,\n",
      "           2.4685e+00, -1.0749e+00],\n",
      "         ...,\n",
      "         [-8.4905e-01,  1.7636e+00, -4.1028e-02,  ...,  2.3920e-01,\n",
      "           2.9954e+00, -1.1990e+00],\n",
      "         [-6.7137e-01,  6.9932e-01,  1.4296e+00,  ..., -8.6282e-01,\n",
      "           2.4704e+00, -1.8353e+00],\n",
      "         [-4.7074e-02,  1.6406e+00,  1.7874e+00,  ..., -8.5898e-01,\n",
      "           2.7313e+00, -2.4201e+00]]], grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 84, 64]) , torch.Size([512, 8, 84, 64]), torch.Size([512, 8, 84, 64])\n",
      "Score shape -- torch.Size([512, 8, 84, 84])\n",
      "Mask ---> torch.Size([512, 1, 84])\n",
      "Mask new --> torch.Size([512, 1, 1, 84])\n",
      "loop within encoder. Iteration -- 2\n",
      "this is x in EncoderLayer-----> tensor([[[-1.0975,  0.5638,  1.0641,  ..., -2.3686,  1.9178, -1.4863],\n",
      "         [ 1.8624,  3.9295,  1.2584,  ..., -3.6553,  2.8568, -0.9712],\n",
      "         [ 0.0562,  1.8567,  0.5761,  ..., -0.4535,  3.2857, -0.6786],\n",
      "         ...,\n",
      "         [-1.0897, -0.2287, -0.2222,  ..., -4.3379,  2.2681, -2.0456],\n",
      "         [-0.7096,  1.5618,  1.3940,  ..., -3.1232,  2.5940, -2.0828],\n",
      "         [ 2.3744,  3.2300, -0.4632,  ..., -4.2470,  2.9753, -1.1458]],\n",
      "\n",
      "        [[-1.9415,  4.1503, -0.0602,  ..., -1.8871,  2.8298, -1.2805],\n",
      "         [-0.2313,  3.4219,  0.1783,  ..., -1.0072,  2.9594, -0.6235],\n",
      "         [ 0.0807,  1.5698,  0.8007,  ..., -1.8212,  2.6828, -0.0815],\n",
      "         ...,\n",
      "         [-1.8427,  2.8193, -0.4583,  ..., -3.1831,  1.6172, -1.7110],\n",
      "         [-0.8235,  3.0494,  0.6643,  ..., -2.5718,  2.3168, -1.8702],\n",
      "         [-0.0463,  3.6187,  1.3049,  ..., -2.2000,  1.1844, -2.3136]],\n",
      "\n",
      "        [[-0.7505,  4.3961,  0.3947,  ..., -1.8295,  1.8476, -1.4692],\n",
      "         [ 0.7905,  3.7490, -0.0093,  ...,  0.3592,  2.7460, -1.9170],\n",
      "         [-1.7105,  3.8705,  0.1169,  ..., -0.9603,  2.5100, -1.5258],\n",
      "         ...,\n",
      "         [-1.7777,  3.5803, -0.6054,  ..., -2.1798,  1.4760, -1.1693],\n",
      "         [-1.3133,  2.9241,  1.1970,  ..., -3.3589,  1.5788, -2.1072],\n",
      "         [ 0.2126,  2.0863,  0.1618,  ..., -2.2426,  1.6195, -1.6574]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.6408,  4.7175, -0.2720,  ..., -2.6292,  2.2893, -1.2909],\n",
      "         [ 0.3199,  3.9246,  0.2632,  ..., -1.6705,  1.8878, -0.8580],\n",
      "         [ 0.4342,  4.4244, -0.5878,  ..., -2.8510,  3.1799, -1.0470],\n",
      "         ...,\n",
      "         [-1.5498,  3.3560, -0.5910,  ..., -3.2341,  2.8410, -2.1460],\n",
      "         [-0.5117,  4.1471,  1.2604,  ..., -4.0383,  1.8530, -2.7328],\n",
      "         [ 1.0234,  3.4198,  0.8301,  ..., -3.0864,  2.4995, -1.1722]],\n",
      "\n",
      "        [[-1.4522,  3.9728,  0.1689,  ..., -2.6852,  3.1833,  0.0653],\n",
      "         [-1.2297,  3.9793, -0.1368,  ..., -4.7281,  2.4896, -1.1474],\n",
      "         [ 1.4832,  3.0156,  1.0723,  ..., -2.3725,  2.0013, -1.9659],\n",
      "         ...,\n",
      "         [-0.8605,  1.3030,  0.2809,  ..., -3.2653,  2.4730, -2.0134],\n",
      "         [ 0.3877,  3.1164,  0.1288,  ..., -3.0995,  2.3133, -1.8153],\n",
      "         [ 0.7583,  4.3943,  1.3207,  ..., -4.2115,  2.6886, -2.4104]],\n",
      "\n",
      "        [[ 0.7680,  3.4585,  0.6884,  ..., -1.9848,  1.2749, -2.5534],\n",
      "         [-0.1843,  2.5344,  0.8168,  ..., -2.4315,  2.0778, -1.9931],\n",
      "         [ 1.0759,  1.8454,  1.1390,  ..., -1.7287,  1.3194, -2.8172],\n",
      "         ...,\n",
      "         [-0.3497,  2.3853, -0.0091,  ...,  0.2392,  2.5823, -2.5913],\n",
      "         [ 0.0979,  1.0122,  0.3797,  ..., -2.7481,  2.6949, -3.7563],\n",
      "         [ 0.8034,  2.5457,  1.4204,  ..., -3.0786,  1.3988, -3.7476]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 84, 64]) , torch.Size([512, 8, 84, 64]), torch.Size([512, 8, 84, 64])\n",
      "Score shape -- torch.Size([512, 8, 84, 84])\n",
      "Mask ---> torch.Size([512, 1, 84])\n",
      "Mask new --> torch.Size([512, 1, 1, 84])\n",
      "loop within encoder. Iteration -- 3\n",
      "this is x in EncoderLayer-----> tensor([[[-3.9981e-01,  1.6233e+00,  4.4966e-01,  ..., -4.8769e+00,\n",
      "           5.7900e-01, -2.9330e+00],\n",
      "         [ 3.0044e+00,  5.9210e+00,  3.5730e-01,  ..., -6.8181e+00,\n",
      "           1.7773e+00, -2.2808e+00],\n",
      "         [ 7.6780e-01,  3.3526e+00,  3.6255e-01,  ..., -2.5033e+00,\n",
      "           1.7241e+00, -2.3938e+00],\n",
      "         ...,\n",
      "         [-5.8825e-01,  1.5920e+00, -2.5648e-01,  ..., -6.8011e+00,\n",
      "           1.0978e+00, -3.2891e+00],\n",
      "         [-4.8307e-01,  2.8941e+00,  1.0285e+00,  ..., -5.6163e+00,\n",
      "           1.1089e+00, -2.9098e+00],\n",
      "         [ 2.3744e+00,  4.5956e+00, -9.3121e-01,  ..., -6.5791e+00,\n",
      "           1.2470e+00, -1.9166e+00]],\n",
      "\n",
      "        [[-1.0640e+00,  4.5457e+00, -8.0332e-01,  ..., -4.4739e+00,\n",
      "           1.2467e+00, -2.8288e+00],\n",
      "         [ 3.8201e-01,  4.5970e+00, -1.7881e-01,  ..., -3.2573e+00,\n",
      "           1.6611e+00, -2.2850e+00],\n",
      "         [ 1.1024e+00,  2.7777e+00,  6.3017e-01,  ..., -4.3087e+00,\n",
      "           1.5580e+00, -1.8766e+00],\n",
      "         ...,\n",
      "         [-6.7360e-01,  3.2735e+00, -9.6868e-01,  ..., -5.4852e+00,\n",
      "          -2.7966e-01, -3.0652e+00],\n",
      "         [ 5.4994e-01,  4.2282e+00,  6.0900e-01,  ..., -5.2201e+00,\n",
      "           1.5368e+00, -3.4183e+00],\n",
      "         [ 1.0542e+00,  5.2343e+00,  9.8035e-01,  ..., -5.0338e+00,\n",
      "          -6.8318e-01, -3.6253e+00]],\n",
      "\n",
      "        [[ 1.0649e-01,  5.8950e+00,  1.2847e-01,  ..., -4.7413e+00,\n",
      "           2.2945e+00, -2.8466e+00],\n",
      "         [ 1.6528e+00,  4.6161e+00, -2.3296e-01,  ..., -2.2080e+00,\n",
      "           1.3690e+00, -3.2503e+00],\n",
      "         [-7.8714e-01,  5.2868e+00,  8.7570e-02,  ..., -3.7708e+00,\n",
      "           1.1992e+00, -2.7008e+00],\n",
      "         ...,\n",
      "         [-1.5127e+00,  5.1343e+00, -5.6360e-01,  ..., -4.7680e+00,\n",
      "          -7.0304e-02, -1.1693e+00],\n",
      "         [-7.4838e-01,  3.6507e+00,  9.0585e-01,  ..., -6.0996e+00,\n",
      "          -3.6941e-01, -2.5320e+00],\n",
      "         [ 1.2389e+00,  3.3889e+00, -2.4982e-01,  ..., -5.2455e+00,\n",
      "           2.8133e-01, -2.5861e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 6.2535e-02,  6.5916e+00, -7.7072e-01,  ..., -5.6257e+00,\n",
      "           1.4855e+00, -1.7929e+00],\n",
      "         [ 1.1681e+00,  3.9563e+00,  4.5015e-01,  ..., -2.5657e+00,\n",
      "           6.8820e-01, -2.0789e+00],\n",
      "         [ 2.0230e+00,  6.1231e+00, -1.4701e+00,  ..., -5.4773e+00,\n",
      "           1.8726e+00, -2.2513e+00],\n",
      "         ...,\n",
      "         [-4.2924e-01,  5.0461e+00, -8.8439e-01,  ..., -5.2696e+00,\n",
      "           3.0380e+00, -3.1733e+00],\n",
      "         [-1.0991e-01,  6.3386e+00,  1.5903e+00,  ..., -7.0700e+00,\n",
      "           7.0418e-03, -3.1156e+00],\n",
      "         [ 1.9917e+00,  4.8330e+00,  2.5450e-01,  ..., -5.8888e+00,\n",
      "           1.2968e+00, -2.2170e+00]],\n",
      "\n",
      "        [[-8.6083e-01,  5.8296e+00, -7.4103e-01,  ..., -5.7151e+00,\n",
      "           2.1885e+00, -1.1654e+00],\n",
      "         [-9.0233e-01,  4.6559e+00,  3.0994e-03,  ..., -5.0064e+00,\n",
      "           1.8746e+00, -2.9867e+00],\n",
      "         [ 2.1546e+00,  3.9151e+00,  1.3142e+00,  ..., -5.4863e+00,\n",
      "           1.9940e+00, -2.7754e+00],\n",
      "         ...,\n",
      "         [-3.1238e-01,  2.6506e+00,  5.4889e-01,  ..., -6.3676e+00,\n",
      "           9.0296e-01, -3.2567e+00],\n",
      "         [ 1.1068e+00,  4.3707e+00,  4.0454e-02,  ..., -6.5592e+00,\n",
      "           7.5090e-01, -2.2190e+00],\n",
      "         [ 1.4560e+00,  5.1353e+00,  1.2082e+00,  ..., -4.4451e+00,\n",
      "           1.4763e+00, -2.8546e+00]],\n",
      "\n",
      "        [[ 1.7145e+00,  4.3534e+00,  3.8984e-01,  ..., -4.2538e+00,\n",
      "          -2.7916e-02, -3.2571e+00],\n",
      "         [ 1.1202e+00,  3.7096e+00,  8.0666e-01,  ..., -5.4340e+00,\n",
      "           2.4732e+00, -3.4251e+00],\n",
      "         [ 1.7682e+00,  3.0408e+00,  1.2278e+00,  ..., -4.2196e+00,\n",
      "          -5.8913e-01, -3.6161e+00],\n",
      "         ...,\n",
      "         [ 8.3212e-01,  2.4865e+00,  2.0532e-01,  ..., -7.0429e-02,\n",
      "           7.1830e-01, -3.3893e+00],\n",
      "         [ 1.0012e+00,  2.0450e+00,  6.8007e-01,  ..., -5.1618e+00,\n",
      "           7.8992e-01, -4.1501e+00],\n",
      "         [ 1.1223e+00,  3.8573e+00,  1.4214e+00,  ..., -6.2914e+00,\n",
      "           8.0968e-01, -3.9622e+00]]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 84, 64]) , torch.Size([512, 8, 84, 64]), torch.Size([512, 8, 84, 64])\n",
      "Score shape -- torch.Size([512, 8, 84, 84])\n",
      "Mask ---> torch.Size([512, 1, 84])\n",
      "Mask new --> torch.Size([512, 1, 1, 84])\n",
      "loop within encoder. Iteration -- 4\n",
      "this is x in EncoderLayer-----> tensor([[[-1.1779,  3.3045, -1.6909,  ..., -5.4941, -0.9482, -5.4169],\n",
      "         [ 2.6787,  7.4531, -1.9464,  ..., -7.2802,  0.3412, -3.3576],\n",
      "         [ 1.6108,  3.6567, -2.0009,  ..., -3.0147,  0.1593, -4.4318],\n",
      "         ...,\n",
      "         [-0.3409,  3.1617, -2.5720,  ..., -7.5859,  0.1931, -6.0781],\n",
      "         [-1.0342,  4.4838, -1.2932,  ..., -6.3567,  0.4925, -4.5262],\n",
      "         [ 1.4465,  5.7535, -3.0328,  ..., -6.5524,  1.0951, -4.0748]],\n",
      "\n",
      "        [[-1.5054,  6.1048, -3.5137,  ..., -5.1140,  1.8527, -5.0693],\n",
      "         [ 0.1561,  5.8857, -1.9652,  ..., -3.2950,  1.1398, -3.7584],\n",
      "         [ 0.6877,  4.1058,  0.3140,  ..., -4.7345,  0.8290, -4.2519],\n",
      "         ...,\n",
      "         [-0.9499,  4.9641, -1.6780,  ..., -5.9425, -1.8810, -5.1244],\n",
      "         [ 0.4242,  6.2730,  0.1284,  ..., -5.2982,  0.7166, -5.7065],\n",
      "         [ 0.9146,  6.9291, -1.1110,  ..., -5.4752, -1.0051, -5.1108]],\n",
      "\n",
      "        [[ 0.5742,  6.9100, -2.1328,  ..., -4.7037,  3.6935, -5.4078],\n",
      "         [ 0.7190,  5.9219, -2.2760,  ..., -2.5885,  2.9079, -5.2538],\n",
      "         [-1.4789,  6.9612, -3.0631,  ..., -3.5608,  0.2604, -5.5297],\n",
      "         ...,\n",
      "         [-1.5348,  6.2109, -2.4822,  ..., -4.9404, -0.7165, -3.1578],\n",
      "         [-0.8289,  4.8908, -1.5757,  ..., -6.4267, -0.7408, -4.2806],\n",
      "         [ 1.7631,  4.3208, -2.4904,  ..., -5.7182, -0.8395, -4.7211]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1359,  8.7210, -2.6573,  ..., -5.5823,  0.0110, -3.2040],\n",
      "         [ 0.5001,  5.6950, -1.6198,  ..., -2.6274,  0.1349, -3.8576],\n",
      "         [ 3.1779,  8.2132, -3.9708,  ..., -5.8595,  1.3527, -4.5631],\n",
      "         ...,\n",
      "         [-0.9613,  7.1708, -1.9066,  ..., -5.5897,  2.3267, -5.6670],\n",
      "         [-1.3228,  8.6510, -0.2312,  ..., -7.0840, -0.2159, -4.5321],\n",
      "         [ 1.6323,  7.3690, -1.7218,  ..., -5.8840,  1.0388, -3.5513]],\n",
      "\n",
      "        [[-0.7885,  7.8835, -3.3766,  ..., -6.5219,  2.1885, -3.7496],\n",
      "         [-1.3119,  4.6254, -2.2541,  ..., -6.1308,  1.5357, -4.0971],\n",
      "         [ 1.9607,  5.6355, -0.6284,  ..., -6.0861,  0.6976, -3.8802],\n",
      "         ...,\n",
      "         [-0.6247,  3.9524, -1.1714,  ..., -6.6344,  0.5082, -5.2655],\n",
      "         [ 0.4495,  6.1211, -2.3731,  ..., -6.4003,  0.8754, -4.3797],\n",
      "         [ 1.0615,  7.0613, -1.2486,  ..., -5.2172,  0.7689, -4.5942]],\n",
      "\n",
      "        [[ 2.2068,  5.3889, -2.5438,  ..., -4.5473, -0.5414, -4.4552],\n",
      "         [ 1.5456,  5.4607, -1.6494,  ..., -5.2339,  2.0208, -3.8947],\n",
      "         [ 2.3665,  3.3745, -1.3398,  ..., -4.8117, -0.9049, -5.1530],\n",
      "         ...,\n",
      "         [ 1.1542,  3.6362, -2.5661,  ..., -0.2908,  1.3459, -5.2110],\n",
      "         [ 0.8595,  3.6429, -1.8492,  ..., -5.6205, -1.1131, -5.4194],\n",
      "         [ 1.0447,  3.9140, -0.3131,  ..., -6.7059, -0.2281, -5.5006]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 84, 64]) , torch.Size([512, 8, 84, 64]), torch.Size([512, 8, 84, 64])\n",
      "Score shape -- torch.Size([512, 8, 84, 84])\n",
      "Mask ---> torch.Size([512, 1, 84])\n",
      "Mask new --> torch.Size([512, 1, 1, 84])\n",
      "loop within encoder. Iteration -- 5\n",
      "this is x in EncoderLayer-----> tensor([[[-0.3733,  2.2475, -0.3686,  ..., -8.2276, -0.7802, -3.4363],\n",
      "         [ 3.4689,  7.0290, -1.1028,  ..., -7.9666,  0.2979, -2.8965],\n",
      "         [ 3.3987,  2.7152, -1.2641,  ..., -5.8945, -0.2521, -2.9083],\n",
      "         ...,\n",
      "         [ 0.8043,  2.1488, -3.1635,  ..., -9.3935,  0.2266, -4.7584],\n",
      "         [ 0.5937,  3.2275, -0.1218,  ..., -9.0996,  0.6748, -3.5687],\n",
      "         [ 3.1785,  4.5133, -2.8363,  ..., -7.4387,  1.3860, -2.2662]],\n",
      "\n",
      "        [[-1.1907,  5.1481, -3.9881,  ..., -7.1096,  2.8545, -3.3947],\n",
      "         [ 1.1864,  5.2361, -0.4525,  ..., -6.1064,  2.0039, -2.6661],\n",
      "         [ 1.3656,  3.4514, -0.3179,  ..., -6.9966,  1.3737, -2.4687],\n",
      "         ...,\n",
      "         [-0.2203,  4.3025, -0.3152,  ..., -8.7320, -1.4091, -3.3236],\n",
      "         [ 1.0406,  5.8196,  1.3325,  ..., -7.4561,  0.5643, -4.3928],\n",
      "         [ 1.9126,  6.8521, -0.5405,  ..., -7.9163, -0.1301, -3.5642]],\n",
      "\n",
      "        [[ 1.5369,  6.5290, -2.4830,  ..., -7.4582,  4.2179, -3.3546],\n",
      "         [ 2.0389,  5.0660, -1.1395,  ..., -5.0896,  3.1226, -2.9047],\n",
      "         [-0.5446,  5.8266, -3.7725,  ..., -6.4101,  0.3055, -3.7566],\n",
      "         ...,\n",
      "         [-0.1086,  5.1816, -1.5027,  ..., -7.4380, -1.0867, -1.6260],\n",
      "         [ 0.5516,  3.3145, -0.2369,  ..., -9.0877, -0.8755, -2.3649],\n",
      "         [ 2.3743,  3.4928, -1.8215,  ..., -7.7589, -0.6562, -3.2608]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.4884,  7.8754, -1.7622,  ..., -8.3411,  0.3863, -1.4183],\n",
      "         [ 1.6833,  5.3662, -0.3141,  ..., -5.3874, -0.5160, -1.3211],\n",
      "         [ 4.4312,  7.2718, -4.4275,  ..., -8.6240,  1.5184, -2.9296],\n",
      "         ...,\n",
      "         [ 0.5486,  6.5798, -0.3124,  ..., -7.8493,  2.5344, -5.0363],\n",
      "         [-0.2319,  8.2060,  0.5904,  ..., -9.5234, -0.2959, -3.0201],\n",
      "         [ 3.1465,  6.6140, -0.7310,  ..., -8.3776,  1.4473, -1.8987]],\n",
      "\n",
      "        [[ 0.4471,  6.3459, -2.7254,  ..., -9.2791,  2.9084, -1.7530],\n",
      "         [ 0.1081,  3.6734, -1.6740,  ..., -8.0773,  2.0920, -2.2169],\n",
      "         [ 2.5390,  5.0224, -1.4648,  ..., -7.9708,  0.9682, -2.0281],\n",
      "         ...,\n",
      "         [ 0.2134,  2.7908, -0.9300,  ..., -8.4424,  1.1626, -3.4129],\n",
      "         [ 0.9373,  6.1211, -1.8898,  ..., -8.4254,  1.2740, -2.2647],\n",
      "         [ 1.8457,  6.1962, -0.1600,  ..., -8.3617,  1.5701, -2.1895]],\n",
      "\n",
      "        [[ 3.5005,  4.1304, -3.4062,  ..., -7.2204,  0.2774, -2.3947],\n",
      "         [ 2.9228,  3.8750, -1.1581,  ..., -7.5506,  2.7634, -2.1390],\n",
      "         [ 3.6319,  1.2844, -0.8222,  ..., -7.2977, -0.8670, -3.3125],\n",
      "         ...,\n",
      "         [ 2.2998,  2.0087, -2.2952,  ..., -2.2955,  2.3213, -3.0546],\n",
      "         [ 1.7579,  2.2807, -0.8668,  ..., -7.9556, -0.7951, -3.5741],\n",
      "         [ 2.7869,  2.1143, -0.3887,  ..., -9.4890, -0.2885, -3.4022]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 84, 64]) , torch.Size([512, 8, 84, 64]), torch.Size([512, 8, 84, 64])\n",
      "Score shape -- torch.Size([512, 8, 84, 84])\n",
      "Mask ---> torch.Size([512, 1, 84])\n",
      "Mask new --> torch.Size([512, 1, 1, 84])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 87])\n",
      "Mask ---> torch.Size([512, 87, 87])\n",
      "Mask new --> torch.Size([512, 1, 87, 87])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 84, 64]), torch.Size([512, 8, 84, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 84])\n",
      "Mask ---> torch.Size([512, 1, 84])\n",
      "Mask new --> torch.Size([512, 1, 1, 84])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 87])\n",
      "Mask ---> torch.Size([512, 87, 87])\n",
      "Mask new --> torch.Size([512, 1, 87, 87])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 84, 64]), torch.Size([512, 8, 84, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 84])\n",
      "Mask ---> torch.Size([512, 1, 84])\n",
      "Mask new --> torch.Size([512, 1, 1, 84])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 87])\n",
      "Mask ---> torch.Size([512, 87, 87])\n",
      "Mask new --> torch.Size([512, 1, 87, 87])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 84, 64]), torch.Size([512, 8, 84, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 84])\n",
      "Mask ---> torch.Size([512, 1, 84])\n",
      "Mask new --> torch.Size([512, 1, 1, 84])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 87])\n",
      "Mask ---> torch.Size([512, 87, 87])\n",
      "Mask new --> torch.Size([512, 1, 87, 87])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 84, 64]), torch.Size([512, 8, 84, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 84])\n",
      "Mask ---> torch.Size([512, 1, 84])\n",
      "Mask new --> torch.Size([512, 1, 1, 84])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 87])\n",
      "Mask ---> torch.Size([512, 87, 87])\n",
      "Mask new --> torch.Size([512, 1, 87, 87])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 84, 64]), torch.Size([512, 8, 84, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 84])\n",
      "Mask ---> torch.Size([512, 1, 84])\n",
      "Mask new --> torch.Size([512, 1, 1, 84])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 87])\n",
      "Mask ---> torch.Size([512, 87, 87])\n",
      "Mask new --> torch.Size([512, 1, 87, 87])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 84, 64]), torch.Size([512, 8, 84, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 84])\n",
      "Mask ---> torch.Size([512, 1, 84])\n",
      "Mask new --> torch.Size([512, 1, 1, 84])\n",
      "predictions size : tensor([[-0.2292, -0.4846,  0.1083,  ..., -0.4339, -0.1529, -0.0040],\n",
      "        [-0.2858, -0.2494,  0.0538,  ..., -0.2331, -0.3444,  0.1076],\n",
      "        [-0.3601, -0.4306,  0.1255,  ..., -0.1607, -0.1027,  0.1816],\n",
      "        ...,\n",
      "        [-0.2934, -0.4505,  0.1123,  ..., -0.2398, -0.1601,  0.1946],\n",
      "        [-0.4554, -0.4349,  0.1292,  ..., -0.2518, -0.2190,  0.1727],\n",
      "        [-0.3723, -0.3837,  0.1173,  ..., -0.1467, -0.2765,  0.0801]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "targets size : torch.Size([44544])\n",
      "Loss.data ----> = 8.446044921875\n",
      "--Encoder x after PE : tensor([[[ 0.5134,  1.6838,  0.0000,  ...,  1.0767, -0.1963,  1.2360],\n",
      "         [ 1.2883,  0.2479,  1.4915,  ...,  0.8353,  0.2694,  1.3480],\n",
      "         [ 1.3764,  0.0617,  0.6923,  ...,  0.5223,  0.5145,  0.0000],\n",
      "         ...,\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.0000,  0.5406]],\n",
      "\n",
      "        [[ 0.5710,  1.2794,  0.1881,  ...,  0.0000, -0.2465,  0.5529],\n",
      "         [ 1.2476,  0.0000,  1.4148,  ...,  0.9640, -0.0322,  1.4850],\n",
      "         [ 0.5140, -0.9809,  0.9656,  ...,  0.8962, -0.1881,  0.6312],\n",
      "         ...,\n",
      "         [ 1.0763,  0.6715,  0.0000,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  0.0000,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.5710,  1.2794,  0.1881,  ...,  0.8978, -0.2465,  0.5529],\n",
      "         [ 1.3449,  0.3254,  0.8741,  ...,  0.5554, -0.6360,  0.6924],\n",
      "         [ 0.5877, -0.2837,  1.6286,  ...,  1.6462,  0.2701,  1.6179],\n",
      "         ...,\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.5625,  1.7515,  0.0000,  ...,  1.3284,  0.4894,  1.2065],\n",
      "         [ 0.9566,  0.5491,  0.8537,  ...,  1.3817, -0.4928,  1.0229],\n",
      "         [ 0.8298, -1.0053,  0.7014,  ...,  1.2173,  0.1671,  1.1562],\n",
      "         ...,\n",
      "         [ 1.0763,  0.6715,  0.0000,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.0000, -0.4602,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.2432,  0.8738,  0.2447,  ...,  0.8458, -0.0000,  1.0878],\n",
      "         [ 0.4736,  0.0435,  0.6594,  ...,  0.9743, -0.2442,  0.9277],\n",
      "         [ 0.4438, -0.8593,  1.0542,  ...,  1.3682, -0.0000,  0.9834],\n",
      "         ...,\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.0000],\n",
      "         [-0.7645,  0.1060, -0.0000,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.2679,  1.2173,  0.6591,  ...,  0.8076,  0.5687,  0.4789],\n",
      "         [ 0.0000,  0.8196,  0.5295,  ...,  0.6173,  0.2685,  0.8737],\n",
      "         [ 1.0721, -0.3446,  0.6100,  ...,  0.5657,  0.6189,  1.7136],\n",
      "         ...,\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "loop within encoder. Iteration -- 0\n",
      "this is x in EncoderLayer-----> tensor([[[ 0.5134,  1.6838,  0.0000,  ...,  1.0767, -0.1963,  1.2360],\n",
      "         [ 1.2883,  0.2479,  1.4915,  ...,  0.8353,  0.2694,  1.3480],\n",
      "         [ 1.3764,  0.0617,  0.6923,  ...,  0.5223,  0.5145,  0.0000],\n",
      "         ...,\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.0000,  0.5406]],\n",
      "\n",
      "        [[ 0.5710,  1.2794,  0.1881,  ...,  0.0000, -0.2465,  0.5529],\n",
      "         [ 1.2476,  0.0000,  1.4148,  ...,  0.9640, -0.0322,  1.4850],\n",
      "         [ 0.5140, -0.9809,  0.9656,  ...,  0.8962, -0.1881,  0.6312],\n",
      "         ...,\n",
      "         [ 1.0763,  0.6715,  0.0000,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  0.0000,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.5710,  1.2794,  0.1881,  ...,  0.8978, -0.2465,  0.5529],\n",
      "         [ 1.3449,  0.3254,  0.8741,  ...,  0.5554, -0.6360,  0.6924],\n",
      "         [ 0.5877, -0.2837,  1.6286,  ...,  1.6462,  0.2701,  1.6179],\n",
      "         ...,\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.5625,  1.7515,  0.0000,  ...,  1.3284,  0.4894,  1.2065],\n",
      "         [ 0.9566,  0.5491,  0.8537,  ...,  1.3817, -0.4928,  1.0229],\n",
      "         [ 0.8298, -1.0053,  0.7014,  ...,  1.2173,  0.1671,  1.1562],\n",
      "         ...,\n",
      "         [ 1.0763,  0.6715,  0.0000,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.0000, -0.4602,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.2432,  0.8738,  0.2447,  ...,  0.8458, -0.0000,  1.0878],\n",
      "         [ 0.4736,  0.0435,  0.6594,  ...,  0.9743, -0.2442,  0.9277],\n",
      "         [ 0.4438, -0.8593,  1.0542,  ...,  1.3682, -0.0000,  0.9834],\n",
      "         ...,\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.0000],\n",
      "         [-0.7645,  0.1060, -0.0000,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.2679,  1.2173,  0.6591,  ...,  0.8076,  0.5687,  0.4789],\n",
      "         [ 0.0000,  0.8196,  0.5295,  ...,  0.6173,  0.2685,  0.8737],\n",
      "         [ 1.0721, -0.3446,  0.6100,  ...,  0.5657,  0.6189,  1.7136],\n",
      "         ...,\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "loop within encoder. Iteration -- 1\n",
      "this is x in EncoderLayer-----> tensor([[[-1.5553,  4.1929,  0.2457,  ...,  1.4400,  2.2212,  0.7857],\n",
      "         [-1.0382,  3.4553,  1.3069,  ..., -1.3784,  3.3580, -0.1271],\n",
      "         [ 0.0576,  2.7186,  0.5546,  ..., -1.8168,  3.5249, -1.0884],\n",
      "         ...,\n",
      "         [-0.3118,  3.6645,  0.7345,  ..., -1.2962,  2.9684, -0.5680],\n",
      "         [-1.6417,  3.5123,  0.0240,  ..., -1.2165,  2.2224, -0.6996],\n",
      "         [-2.2842,  3.0029, -0.8500,  ..., -1.3858,  2.4520, -0.6277]],\n",
      "\n",
      "        [[-1.3449,  3.4540, -0.6624,  ..., -2.2160,  1.8202, -1.0856],\n",
      "         [-1.7105,  2.9814,  1.2317,  ..., -1.7583,  2.2132,  0.9617],\n",
      "         [-2.1364,  1.4150, -0.0438,  ..., -1.0601,  2.7504, -0.6008],\n",
      "         ...,\n",
      "         [-0.4927,  3.0853, -0.4297,  ..., -1.1779,  0.6966, -1.2727],\n",
      "         [-1.7122,  3.6286, -0.2542,  ..., -2.1947,  1.5552, -1.1821],\n",
      "         [-2.5498,  2.7255, -1.1700,  ..., -1.3237,  2.2327,  0.2098]],\n",
      "\n",
      "        [[-1.3864,  3.2900, -0.2960,  ...,  0.8625,  1.5413, -0.9634],\n",
      "         [-0.8423,  2.8320,  0.3905,  ..., -1.6380,  2.1688, -0.8034],\n",
      "         [-1.8913,  0.9028,  1.1279,  ...,  0.7793,  2.9069, -0.9046],\n",
      "         ...,\n",
      "         [ 2.0299,  3.5446,  0.6079,  ..., -1.2873,  2.5308, -0.9547],\n",
      "         [-1.4905,  3.4486,  0.7908,  ..., -1.2266,  2.2648, -1.8114],\n",
      "         [-2.7133,  2.7726, -0.5601,  ..., -0.8049,  2.1892, -0.9493]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.7297,  4.6510, -0.2451,  ..., -0.9721,  3.1658, -0.2550],\n",
      "         [-0.8190,  2.9261,  0.6538,  ...,  0.3761,  1.7586,  0.6990],\n",
      "         [-0.9008,  1.7373,  1.4897,  ..., -0.0530,  3.0903,  0.4676],\n",
      "         ...,\n",
      "         [-0.2250,  3.8276, -0.0722,  ...,  1.1185,  1.4885, -1.8434],\n",
      "         [-1.2746,  3.9335, -0.6143,  ..., -0.0124,  2.7574, -1.8420],\n",
      "         [-2.7445,  2.4033, -0.1620,  ..., -0.5801,  2.7339, -0.8253]],\n",
      "\n",
      "        [[-0.9049,  3.6474,  0.4148,  ..., -0.0417,  1.6421,  0.0302],\n",
      "         [-1.0890,  1.2241,  0.6917,  ..., -1.1651,  2.5599,  1.0323],\n",
      "         [-1.8716,  0.9171,  1.6256,  ..., -1.3106,  2.8315,  0.0789],\n",
      "         ...,\n",
      "         [-0.9665,  3.6061,  0.9499,  ..., -1.8366,  2.8000, -0.7181],\n",
      "         [ 0.2679,  3.7021, -0.3329,  ..., -1.2656,  2.2108, -1.7763],\n",
      "         [-1.8616,  2.0381,  0.5937,  ..., -1.2395,  3.4336, -1.3745]],\n",
      "\n",
      "        [[-2.4908,  3.7211,  0.2334,  ..., -0.7889,  1.9643,  0.1689],\n",
      "         [-2.2169,  3.7305,  0.8868,  ..., -0.7981,  2.6490, -0.9753],\n",
      "         [-1.0740,  3.1090,  0.2415,  ...,  0.5657,  2.8029,  1.3022],\n",
      "         ...,\n",
      "         [-0.8013,  3.4031,  0.8471,  ..., -0.9836,  2.3629, -0.8294],\n",
      "         [-1.5760,  3.5223, -0.7035,  ..., -2.3083,  1.2210, -0.3604],\n",
      "         [-2.8289,  2.6715, -0.3511,  ..., -0.2880,  1.4703, -0.7776]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "loop within encoder. Iteration -- 2\n",
      "this is x in EncoderLayer-----> tensor([[[-1.5303,  5.7767, -0.1095,  ..., -0.9917,  1.2820, -0.2591],\n",
      "         [-1.0521,  5.0119,  0.8585,  ..., -3.6522,  3.5069, -1.2366],\n",
      "         [ 0.8268,  4.4365,  0.7392,  ..., -3.8971,  3.3313, -2.1980],\n",
      "         ...,\n",
      "         [ 0.2010,  4.9547,  0.3678,  ..., -2.8921,  2.9247, -0.5680],\n",
      "         [-1.4846,  4.9882, -0.6139,  ..., -3.2665,  1.7647, -1.8071],\n",
      "         [-1.9431,  4.0397, -1.8353,  ..., -3.3405,  2.7648, -2.0182]],\n",
      "\n",
      "        [[-0.7663,  5.0205, -0.9938,  ..., -3.6702,  1.7254, -2.3296],\n",
      "         [-1.6223,  4.2500,  1.3567,  ..., -3.2403,  2.0877, -0.2585],\n",
      "         [-1.8263,  2.8464, -0.3914,  ..., -2.4129,  3.0069, -1.7037],\n",
      "         ...,\n",
      "         [ 0.6428,  3.1420, -1.2523,  ..., -2.6320,  0.2907, -2.1303],\n",
      "         [-1.0070,  4.8881, -0.6671,  ..., -3.5730,  1.4351, -1.6539],\n",
      "         [-2.0428,  4.2315, -1.6847,  ..., -2.6631,  1.9633, -0.5447]],\n",
      "\n",
      "        [[-0.7797,  5.0355, -0.3357,  ...,  0.7209,  1.0271, -2.4376],\n",
      "         [ 0.0123,  4.7477,  0.6518,  ..., -3.3289,  1.9671, -2.4880],\n",
      "         [-1.3905,  2.0565,  1.4285,  ..., -1.5981,  2.8566, -2.1820],\n",
      "         ...,\n",
      "         [ 2.0844,  5.4160,  0.1620,  ..., -1.2873,  2.1549, -1.3859],\n",
      "         [-1.6958,  3.9833,  0.4604,  ..., -2.8981,  2.0321, -2.7196],\n",
      "         [-2.6252,  4.5495, -0.8899,  ..., -2.2990,  1.8801, -1.6350]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.5495,  6.2735, -0.4173,  ..., -2.9526,  2.3590, -1.9282],\n",
      "         [-0.8640,  4.6084,  0.2291,  ..., -0.7931,  1.5195,  0.3543],\n",
      "         [-0.3619,  3.8699,  1.4636,  ..., -1.8593,  2.9632, -0.4316],\n",
      "         ...,\n",
      "         [ 0.1285,  5.8129, -0.4519,  ..., -0.3479,  0.8895, -2.3821],\n",
      "         [-1.2863,  4.1308, -1.3834,  ..., -1.0728,  2.3626, -2.4770],\n",
      "         [-2.6220,  4.2099, -0.3714,  ..., -2.1083,  2.8889, -1.0018]],\n",
      "\n",
      "        [[-0.3702,  5.7670, -0.2594,  ..., -1.5274,  1.7274, -2.0658],\n",
      "         [-0.7511,  2.3707, -0.0405,  ..., -2.9261,  1.7429, -0.7571],\n",
      "         [-1.1971,  2.6120,  0.7328,  ..., -2.5948,  2.6420, -1.8299],\n",
      "         ...,\n",
      "         [-0.6173,  4.6964,  0.6637,  ..., -2.6418,  2.4146, -2.4269],\n",
      "         [ 0.8608,  5.5317, -0.6194,  ..., -2.6435,  2.4274, -2.9718],\n",
      "         [-1.8493,  3.9974, -0.1217,  ..., -2.4925,  3.1242, -1.5916]],\n",
      "\n",
      "        [[-2.3212,  5.5584, -0.2719,  ..., -2.8499,  2.1218, -1.1760],\n",
      "         [-1.3468,  4.7395,  0.4100,  ..., -2.3713,  2.4831, -1.9139],\n",
      "         [-0.5884,  4.0489, -0.5383,  ..., -1.3087,  2.5312, -0.1778],\n",
      "         ...,\n",
      "         [-0.4514,  4.9371, -0.0508,  ..., -0.7652,  2.0236, -1.7753],\n",
      "         [-1.1249,  5.4873, -0.5227,  ..., -2.4062,  0.9026, -1.0684],\n",
      "         [-2.6876,  2.5428, -0.4087,  ..., -1.9225,  1.1382, -1.6547]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "loop within encoder. Iteration -- 3\n",
      "this is x in EncoderLayer-----> tensor([[[-1.2260e+00,  6.7585e+00, -7.3557e-01,  ..., -3.3665e+00,\n",
      "           5.9554e-01, -1.4365e+00],\n",
      "         [-9.0547e-01,  6.9304e+00,  2.2566e-01,  ..., -7.1491e+00,\n",
      "           2.5867e+00, -2.7886e+00],\n",
      "         [ 2.2077e+00,  6.1086e+00,  7.0388e-01,  ..., -6.2224e+00,\n",
      "           2.0516e+00, -3.4912e+00],\n",
      "         ...,\n",
      "         [ 1.3209e+00,  6.0421e+00,  7.5084e-01,  ..., -5.8519e+00,\n",
      "           2.8689e+00, -1.5169e+00],\n",
      "         [-6.0926e-01,  6.8624e+00, -5.8251e-01,  ..., -6.2685e+00,\n",
      "           1.9167e-01, -2.5904e+00],\n",
      "         [-8.6466e-01,  4.5462e+00, -2.2431e+00,  ..., -6.7543e+00,\n",
      "           2.5822e+00, -3.2775e+00]],\n",
      "\n",
      "        [[-8.3709e-01,  6.5346e+00, -1.6742e+00,  ..., -4.0364e+00,\n",
      "           5.9273e-01, -3.8020e+00],\n",
      "         [-1.1116e+00,  5.6472e+00,  9.1298e-01,  ..., -5.4393e+00,\n",
      "           1.5094e+00, -1.2557e+00],\n",
      "         [-8.7076e-01,  4.5312e+00, -4.6861e-01,  ..., -4.7193e+00,\n",
      "           1.8351e+00, -3.3678e+00],\n",
      "         ...,\n",
      "         [ 1.8665e+00,  4.5577e+00, -9.1167e-01,  ..., -3.5246e+00,\n",
      "          -4.9742e-01, -3.4220e+00],\n",
      "         [ 2.6146e-01,  6.0551e+00, -9.7451e-01,  ..., -6.2687e+00,\n",
      "           7.9259e-03, -3.3042e+00],\n",
      "         [-1.2026e+00,  5.8904e+00, -1.7322e+00,  ..., -5.3795e+00,\n",
      "           3.6860e-01, -2.2161e+00]],\n",
      "\n",
      "        [[ 4.9302e-01,  6.2562e+00, -7.8836e-01,  ..., -1.1743e+00,\n",
      "          -5.7323e-01, -3.9487e+00],\n",
      "         [ 8.8080e-01,  6.2441e+00,  2.7842e-01,  ..., -6.2816e+00,\n",
      "           4.0145e-01, -3.6146e+00],\n",
      "         [-5.9791e-01,  3.5792e+00,  1.3053e+00,  ..., -3.9476e+00,\n",
      "           1.7432e+00, -3.5714e+00],\n",
      "         ...,\n",
      "         [ 3.1687e+00,  7.0589e+00, -2.7416e-01,  ..., -2.4208e+00,\n",
      "           9.7538e-01, -2.0472e+00],\n",
      "         [-1.7358e-01,  3.8737e+00,  7.3630e-01,  ..., -5.8560e+00,\n",
      "           6.1600e-01, -4.3509e+00],\n",
      "         [-1.6084e+00,  5.7604e+00, -1.2905e+00,  ..., -5.1002e+00,\n",
      "          -3.2632e-01, -2.8347e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.5770e+00,  7.7321e+00, -1.1263e+00,  ..., -3.3085e+00,\n",
      "           7.7154e-01, -3.4046e+00],\n",
      "         [ 7.0351e-02,  5.6084e+00, -3.3750e-01,  ..., -4.1838e+00,\n",
      "           1.9608e-01, -1.4098e+00],\n",
      "         [ 4.3234e-01,  5.0290e+00,  9.1772e-01,  ..., -5.0786e+00,\n",
      "           1.8377e+00, -2.1261e+00],\n",
      "         ...,\n",
      "         [ 1.0577e+00,  6.7691e+00,  4.8927e-02,  ..., -3.2269e+00,\n",
      "          -7.4487e-01, -3.0592e+00],\n",
      "         [-6.9190e-01,  5.4973e+00, -1.8552e+00,  ..., -4.2736e+00,\n",
      "           9.3703e-01, -3.7438e+00],\n",
      "         [-1.0390e+00,  5.2702e+00, -8.1055e-01,  ..., -5.4093e+00,\n",
      "           1.0978e+00, -2.2431e+00]],\n",
      "\n",
      "        [[ 6.6489e-01,  7.0479e+00, -1.3664e+00,  ..., -5.1426e+00,\n",
      "           6.9832e-01, -3.3311e+00],\n",
      "         [ 1.7929e-01,  4.2298e+00, -7.9259e-01,  ..., -5.3295e+00,\n",
      "           1.3674e+00, -2.3839e+00],\n",
      "         [-4.2664e-01,  3.2059e+00,  2.8248e-01,  ..., -2.6822e+00,\n",
      "           1.3938e+00, -3.4263e+00],\n",
      "         ...,\n",
      "         [ 6.0918e-01,  6.0774e+00,  7.6274e-02,  ..., -6.2484e+00,\n",
      "           8.4301e-01, -2.7718e+00],\n",
      "         [ 1.8566e+00,  6.4816e+00, -2.3930e-01,  ..., -5.8721e+00,\n",
      "           6.4215e-01, -4.5351e+00],\n",
      "         [-2.3997e-01,  4.9917e+00, -7.1844e-01,  ..., -3.4808e+00,\n",
      "           1.3127e+00, -2.2182e+00]],\n",
      "\n",
      "        [[-1.0093e+00,  6.7909e+00, -8.0021e-01,  ..., -5.3653e+00,\n",
      "           1.0628e+00, -2.7787e+00],\n",
      "         [ 1.2085e-01,  5.8795e+00,  1.2840e-01,  ..., -4.5761e+00,\n",
      "           2.1540e+00, -3.7074e+00],\n",
      "         [ 3.5145e-01,  4.4563e+00, -4.5557e-01,  ..., -3.2815e+00,\n",
      "           8.4450e-01, -9.2424e-01],\n",
      "         ...,\n",
      "         [ 4.9355e-01,  6.1321e+00, -5.7364e-03,  ..., -2.7709e+00,\n",
      "           6.9990e-01, -2.9008e+00],\n",
      "         [ 3.0383e-01,  6.5708e+00, -6.4462e-01,  ..., -4.9598e+00,\n",
      "           9.5267e-01, -2.6143e+00],\n",
      "         [-1.2888e+00,  4.2915e+00, -2.5971e-01,  ..., -4.2255e+00,\n",
      "          -1.9809e-01, -3.1581e+00]]], grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "loop within encoder. Iteration -- 4\n",
      "this is x in EncoderLayer-----> tensor([[[-7.7394e-01,  8.3908e+00, -3.0749e+00,  ..., -3.3504e+00,\n",
      "           3.1565e-01, -4.4523e+00],\n",
      "         [-1.0858e+00,  7.8994e+00, -1.9165e+00,  ..., -7.1491e+00,\n",
      "           7.7448e-01, -3.7481e+00],\n",
      "         [ 2.6717e+00,  7.5855e+00, -1.9737e+00,  ..., -6.2586e+00,\n",
      "           3.8261e-01, -5.9605e+00],\n",
      "         ...,\n",
      "         [ 8.2049e-01,  7.7771e+00, -1.1727e+00,  ..., -6.4143e+00,\n",
      "           1.8342e+00, -4.1098e+00],\n",
      "         [-1.0458e+00,  7.3105e+00, -1.4627e+00,  ..., -7.2051e+00,\n",
      "          -7.1351e-01, -5.1906e+00],\n",
      "         [-1.2898e+00,  6.1831e+00, -4.2101e+00,  ..., -6.8001e+00,\n",
      "           1.9448e+00, -5.0774e+00]],\n",
      "\n",
      "        [[-2.8984e-03,  8.4296e+00, -3.9221e+00,  ..., -4.2502e+00,\n",
      "           2.4662e-01, -6.2542e+00],\n",
      "         [-1.3306e+00,  6.9563e+00, -6.5933e-01,  ..., -5.3766e+00,\n",
      "           3.1817e-01, -4.1073e+00],\n",
      "         [-1.5373e+00,  4.7074e+00, -2.5525e+00,  ..., -5.2032e+00,\n",
      "           1.1502e+00, -6.2587e+00],\n",
      "         ...,\n",
      "         [ 2.5092e+00,  6.3761e+00, -3.2130e+00,  ..., -3.4840e+00,\n",
      "          -9.7476e-01, -5.7693e+00],\n",
      "         [ 6.0096e-01,  7.8387e+00, -3.5698e+00,  ..., -6.9036e+00,\n",
      "          -5.4022e-01, -5.0918e+00],\n",
      "         [-9.3792e-01,  7.2232e+00, -3.7778e+00,  ..., -5.5045e+00,\n",
      "          -1.1935e+00, -4.5619e+00]],\n",
      "\n",
      "        [[ 6.6555e-01,  8.4599e+00, -3.3822e+00,  ..., -1.5914e+00,\n",
      "          -1.0700e+00, -5.6163e+00],\n",
      "         [-5.7900e-02,  8.0991e+00, -2.2420e+00,  ..., -6.1131e+00,\n",
      "           1.6916e+00, -6.0040e+00],\n",
      "         [-1.1219e+00,  4.8973e+00, -1.6081e+00,  ..., -3.3811e+00,\n",
      "           1.3573e-01, -6.3940e+00],\n",
      "         ...,\n",
      "         [ 2.5256e+00,  8.9049e+00, -1.9629e+00,  ..., -2.3018e+00,\n",
      "           1.8413e+00, -4.3753e+00],\n",
      "         [-4.2759e-01,  5.0606e+00, -1.0019e+00,  ..., -5.8763e+00,\n",
      "          -1.2757e-01, -6.5619e+00],\n",
      "         [-2.2715e+00,  7.3439e+00, -4.0053e+00,  ..., -5.0726e+00,\n",
      "          -8.7172e-01, -4.4378e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.8727e+00,  9.1197e+00, -3.0357e+00,  ..., -3.6206e+00,\n",
      "          -1.8313e-01, -5.0092e+00],\n",
      "         [ 1.1875e+00,  7.1877e+00, -2.8802e+00,  ..., -4.2150e+00,\n",
      "          -2.8389e-01, -3.8386e+00],\n",
      "         [-6.6424e-01,  6.8374e+00, -9.7559e-01,  ..., -5.9820e+00,\n",
      "           3.2371e+00, -4.9060e+00],\n",
      "         ...,\n",
      "         [-5.5882e-02,  8.1072e+00, -2.3053e+00,  ..., -3.8918e+00,\n",
      "           2.8073e-02, -5.2955e+00],\n",
      "         [-6.8052e-01,  7.0904e+00, -4.8399e+00,  ..., -4.6808e+00,\n",
      "          -2.0955e-02, -6.0113e+00],\n",
      "         [-1.7550e+00,  6.8601e+00, -3.1946e+00,  ..., -5.5360e+00,\n",
      "           4.7100e-01, -4.4468e+00]],\n",
      "\n",
      "        [[ 8.2170e-01,  8.7100e+00, -3.0930e+00,  ..., -5.1961e+00,\n",
      "           9.6986e-02, -5.5015e+00],\n",
      "         [ 5.9248e-02,  5.5175e+00, -3.6470e+00,  ..., -6.1325e+00,\n",
      "           1.0714e+00, -4.1549e+00],\n",
      "         [ 3.8314e-01,  4.4903e+00, -2.1814e+00,  ..., -3.1229e+00,\n",
      "           7.7241e-01, -5.6610e+00],\n",
      "         ...,\n",
      "         [ 6.0785e-01,  7.9129e+00, -1.2641e+00,  ..., -6.0575e+00,\n",
      "           1.5726e-01, -4.0586e+00],\n",
      "         [ 1.7709e+00,  6.7504e+00, -3.0985e+00,  ..., -6.1168e+00,\n",
      "          -2.1271e-01, -6.5153e+00],\n",
      "         [-3.7585e-01,  6.8369e+00, -3.3153e+00,  ..., -3.5529e+00,\n",
      "           6.6168e-01, -3.8635e+00]],\n",
      "\n",
      "        [[-2.2071e+00,  8.2720e+00, -2.5989e+00,  ..., -5.2743e+00,\n",
      "           1.7396e+00, -5.7346e+00],\n",
      "         [-1.4730e-01,  7.7861e+00,  1.2840e-01,  ..., -5.0346e+00,\n",
      "           1.7105e+00, -6.7048e+00],\n",
      "         [ 1.0380e-01,  5.9307e+00, -2.1098e+00,  ..., -3.5777e+00,\n",
      "           6.4356e-01, -2.0437e+00],\n",
      "         ...,\n",
      "         [ 1.0954e+00,  6.9495e+00, -2.4905e+00,  ..., -2.5914e+00,\n",
      "          -4.4216e-01, -5.0082e+00],\n",
      "         [ 1.2966e-01,  8.6142e+00, -2.8381e+00,  ..., -5.0607e+00,\n",
      "          -2.7169e-01, -5.7169e+00],\n",
      "         [-1.7546e+00,  5.6860e+00, -2.3855e+00,  ..., -4.3021e+00,\n",
      "          -9.4683e-01, -5.5742e+00]]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "loop within encoder. Iteration -- 5\n",
      "this is x in EncoderLayer-----> tensor([[[-0.4961,  7.4471, -2.0857,  ..., -5.3875, -0.2889, -2.6684],\n",
      "         [ 0.1346,  7.3953, -1.1653,  ..., -9.2316,  2.2773, -2.3897],\n",
      "         [ 4.1295,  6.5391, -0.8660,  ..., -8.6035, -0.1690, -4.5922],\n",
      "         ...,\n",
      "         [ 2.0030,  6.9904,  0.0881,  ..., -8.6200,  1.8019, -3.0543],\n",
      "         [-0.7775,  6.4845, -0.1669,  ..., -8.9162, -0.5249, -3.9168],\n",
      "         [-0.3307,  5.4973, -3.5991,  ..., -9.0150,  2.3285, -3.8469]],\n",
      "\n",
      "        [[ 0.8564,  7.9400, -2.6708,  ..., -7.2824,  0.2890, -5.3064],\n",
      "         [-0.1970,  6.2343,  0.2761,  ..., -5.5239, -0.2665, -2.4603],\n",
      "         [ 0.0178,  3.9900, -0.7009,  ..., -7.5142,  0.4871, -4.5655],\n",
      "         ...,\n",
      "         [ 3.3425,  5.9099, -2.2782,  ..., -5.6814, -0.1264, -5.1684],\n",
      "         [ 1.7888,  7.0320, -2.3555,  ..., -9.0795, -0.8981, -3.7210],\n",
      "         [-0.8062,  6.7496, -4.1985,  ..., -7.9745, -1.3312, -3.8068]],\n",
      "\n",
      "        [[ 0.7677,  7.8543, -2.7895,  ..., -3.4141, -1.0700, -3.5236],\n",
      "         [ 0.8513,  7.2378, -0.6708,  ..., -8.3165,  2.1413, -4.5512],\n",
      "         [-0.0393,  3.9585, -0.5513,  ..., -5.7597, -0.0719, -4.3189],\n",
      "         ...,\n",
      "         [ 3.0860,  8.1160, -2.5005,  ..., -4.2274,  2.3700, -3.1110],\n",
      "         [ 0.4313,  4.1895, -1.0019,  ..., -8.6158, -0.2560, -4.8727],\n",
      "         [-1.0497,  6.5077, -3.0150,  ..., -7.8125, -0.3484, -2.8354]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.8906,  8.1876, -2.2370,  ..., -5.6981,  0.2270, -3.0367],\n",
      "         [ 2.1095,  6.1105, -1.9946,  ..., -6.6800, -0.0469, -2.0695],\n",
      "         [ 0.0100,  7.3753, -0.0868,  ..., -8.3418,  3.2768, -3.4268],\n",
      "         ...,\n",
      "         [ 0.4619,  7.3826, -1.5150,  ..., -5.9604, -0.6062, -3.4687],\n",
      "         [-0.2319,  6.2429, -3.8280,  ..., -6.5352, -0.1499, -4.5057],\n",
      "         [-0.7865,  5.7320, -1.9884,  ..., -8.4522,  1.3471, -3.0796]],\n",
      "\n",
      "        [[ 2.0718,  7.8610, -2.1128,  ..., -7.4257, -0.3543, -3.8826],\n",
      "         [ 1.3981,  4.6196, -3.2109,  ..., -7.7211,  1.9500, -3.3251],\n",
      "         [ 1.3470,  3.3082, -1.2031,  ..., -4.8749,  1.3962, -4.0917],\n",
      "         ...,\n",
      "         [ 1.6349,  7.8340,  0.5239,  ..., -9.0339,  0.1465, -1.7584],\n",
      "         [ 2.6792,  5.7439, -1.8377,  ..., -6.8724, -0.0414, -4.9971],\n",
      "         [ 1.3524,  5.6095, -1.6545,  ..., -6.1677,  0.4977, -2.1692]],\n",
      "\n",
      "        [[-1.5736,  8.1167, -1.3483,  ..., -7.8850,  2.2179, -3.5194],\n",
      "         [ 0.3040,  7.2121,  1.0573,  ..., -6.8125,  1.7195, -5.3950],\n",
      "         [ 1.0369,  6.0636, -2.5790,  ..., -5.6827,  0.1037, -0.4618],\n",
      "         ...,\n",
      "         [ 1.6271,  6.3722, -1.4702,  ..., -4.7594, -0.1439, -3.3124],\n",
      "         [ 0.3570,  8.0274, -1.1586,  ..., -7.2763, -0.4282, -4.3169],\n",
      "         [-1.1039,  5.1718, -0.9982,  ..., -6.4824, -0.8579, -3.7468]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 94, 64]) , torch.Size([512, 8, 94, 64]), torch.Size([512, 8, 94, 64])\n",
      "Score shape -- torch.Size([512, 8, 94, 94])\n",
      "Mask ---> torch.Size([512, 94, 94])\n",
      "Mask new --> torch.Size([512, 1, 94, 94])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 94, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 94, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 94, 64]) , torch.Size([512, 8, 94, 64]), torch.Size([512, 8, 94, 64])\n",
      "Score shape -- torch.Size([512, 8, 94, 94])\n",
      "Mask ---> torch.Size([512, 94, 94])\n",
      "Mask new --> torch.Size([512, 1, 94, 94])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 94, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 94, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 94, 64]) , torch.Size([512, 8, 94, 64]), torch.Size([512, 8, 94, 64])\n",
      "Score shape -- torch.Size([512, 8, 94, 94])\n",
      "Mask ---> torch.Size([512, 94, 94])\n",
      "Mask new --> torch.Size([512, 1, 94, 94])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 94, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 94, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 94, 64]) , torch.Size([512, 8, 94, 64]), torch.Size([512, 8, 94, 64])\n",
      "Score shape -- torch.Size([512, 8, 94, 94])\n",
      "Mask ---> torch.Size([512, 94, 94])\n",
      "Mask new --> torch.Size([512, 1, 94, 94])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 94, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 94, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 94, 64]) , torch.Size([512, 8, 94, 64]), torch.Size([512, 8, 94, 64])\n",
      "Score shape -- torch.Size([512, 8, 94, 94])\n",
      "Mask ---> torch.Size([512, 94, 94])\n",
      "Mask new --> torch.Size([512, 1, 94, 94])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 94, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 94, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 94, 64]) , torch.Size([512, 8, 94, 64]), torch.Size([512, 8, 94, 64])\n",
      "Score shape -- torch.Size([512, 8, 94, 94])\n",
      "Mask ---> torch.Size([512, 94, 94])\n",
      "Mask new --> torch.Size([512, 1, 94, 94])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 94, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 94, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "predictions size : tensor([[-0.2784, -0.3825,  0.1949,  ..., -0.3263, -0.2617,  0.1396],\n",
      "        [-0.3735, -0.2847,  0.2062,  ..., -0.2593, -0.2315,  0.1092],\n",
      "        [-0.3689, -0.4606,  0.2773,  ..., -0.5093, -0.3635, -0.0065],\n",
      "        ...,\n",
      "        [-0.4947, -0.4652, -0.0095,  ..., -0.2619, -0.2553,  0.1056],\n",
      "        [-0.2541, -0.4988,  0.1211,  ..., -0.2856, -0.3052,  0.1724],\n",
      "        [-0.3353, -0.3809,  0.1019,  ..., -0.3249, -0.1208,  0.1371]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "targets size : torch.Size([48128])\n",
      "Loss.data ----> = 8.39784049987793\n",
      "--Encoder x after PE : tensor([[[-0.0000,  1.4891,  0.1340,  ...,  1.2252, -0.4323,  0.7595],\n",
      "         [ 0.0000,  0.4452,  0.6790,  ...,  1.0635, -0.1943,  1.0170],\n",
      "         [ 0.5403, -0.3188,  0.9142,  ...,  1.1044,  0.5370,  1.5590],\n",
      "         ...,\n",
      "         [ 0.3009, -1.3217,  0.8777,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  0.0000,  0.1775,  0.5406],\n",
      "         [ 1.2549,  0.2458,  1.6227,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.5624,  1.7529,  0.0000,  ...,  1.3298,  0.4889,  1.2063],\n",
      "         [ 0.9579,  0.5484,  0.8524,  ...,  1.3831, -0.0000,  1.0214],\n",
      "         [ 0.8296, -1.0041,  0.7006,  ...,  1.2171,  0.1677,  1.1549],\n",
      "         ...,\n",
      "         [ 0.3009, -1.3217,  0.8777,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2549,  0.0000,  1.6227,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.0000,  0.9182,  0.4076,  ...,  0.5197, -0.0000,  0.7954],\n",
      "         [ 1.3238,  0.0942,  1.2839,  ...,  1.7095,  0.0000,  1.6522],\n",
      "         [ 1.3502, -0.6727,  1.5589,  ...,  1.6803, -0.1703,  1.3126],\n",
      "         ...,\n",
      "         [ 0.3009, -1.3217,  0.8777,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0000, -0.7834,  1.6566,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2549,  0.2458,  1.6227,  ...,  0.0000,  0.1775,  0.5406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.5718,  1.2791,  0.1886,  ...,  0.8984, -0.2453,  0.5516],\n",
      "         [ 0.9825,  0.2676,  0.0000,  ...,  0.8498, -0.3326,  1.3309],\n",
      "         [ 1.0673, -0.8343,  0.8364,  ...,  1.3627,  0.0992,  0.6027],\n",
      "         ...,\n",
      "         [ 0.0000, -0.0000,  0.8777,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0000,  0.2458,  1.6227,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.0634,  0.6928, -0.5595,  ...,  0.5239, -0.3122,  0.8558],\n",
      "         [ 0.6201,  0.0912,  1.2332,  ...,  0.6678,  0.6404,  1.2344],\n",
      "         [ 0.6472, -0.2233,  1.0834,  ...,  0.4658,  0.2420,  1.4636],\n",
      "         ...,\n",
      "         [ 0.3009, -1.3217,  0.8777,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  0.0000,  0.1775,  0.5406],\n",
      "         [ 1.2549,  0.2458,  1.6227,  ...,  1.0595,  0.0000,  0.5406]],\n",
      "\n",
      "        [[-0.1415,  0.7779,  0.6191,  ...,  1.2471, -0.4095,  0.4523],\n",
      "         [ 0.5050,  1.0873,  1.3636,  ...,  0.0000, -0.6293,  0.6233],\n",
      "         [ 1.0608, -0.6849,  0.8489,  ...,  1.6614, -0.6244,  1.4078],\n",
      "         ...,\n",
      "         [ 0.3009, -1.3217,  0.8777,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2549,  0.0000,  0.0000,  ...,  1.0595,  0.1775,  0.5406]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "loop within encoder. Iteration -- 0\n",
      "this is x in EncoderLayer-----> tensor([[[-0.0000,  1.4891,  0.1340,  ...,  1.2252, -0.4323,  0.7595],\n",
      "         [ 0.0000,  0.4452,  0.6790,  ...,  1.0635, -0.1943,  1.0170],\n",
      "         [ 0.5403, -0.3188,  0.9142,  ...,  1.1044,  0.5370,  1.5590],\n",
      "         ...,\n",
      "         [ 0.3009, -1.3217,  0.8777,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  0.0000,  0.1775,  0.5406],\n",
      "         [ 1.2549,  0.2458,  1.6227,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.5624,  1.7529,  0.0000,  ...,  1.3298,  0.4889,  1.2063],\n",
      "         [ 0.9579,  0.5484,  0.8524,  ...,  1.3831, -0.0000,  1.0214],\n",
      "         [ 0.8296, -1.0041,  0.7006,  ...,  1.2171,  0.1677,  1.1549],\n",
      "         ...,\n",
      "         [ 0.3009, -1.3217,  0.8777,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2549,  0.0000,  1.6227,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.0000,  0.9182,  0.4076,  ...,  0.5197, -0.0000,  0.7954],\n",
      "         [ 1.3238,  0.0942,  1.2839,  ...,  1.7095,  0.0000,  1.6522],\n",
      "         [ 1.3502, -0.6727,  1.5589,  ...,  1.6803, -0.1703,  1.3126],\n",
      "         ...,\n",
      "         [ 0.3009, -1.3217,  0.8777,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0000, -0.7834,  1.6566,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2549,  0.2458,  1.6227,  ...,  0.0000,  0.1775,  0.5406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.5718,  1.2791,  0.1886,  ...,  0.8984, -0.2453,  0.5516],\n",
      "         [ 0.9825,  0.2676,  0.0000,  ...,  0.8498, -0.3326,  1.3309],\n",
      "         [ 1.0673, -0.8343,  0.8364,  ...,  1.3627,  0.0992,  0.6027],\n",
      "         ...,\n",
      "         [ 0.0000, -0.0000,  0.8777,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0000,  0.2458,  1.6227,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.0634,  0.6928, -0.5595,  ...,  0.5239, -0.3122,  0.8558],\n",
      "         [ 0.6201,  0.0912,  1.2332,  ...,  0.6678,  0.6404,  1.2344],\n",
      "         [ 0.6472, -0.2233,  1.0834,  ...,  0.4658,  0.2420,  1.4636],\n",
      "         ...,\n",
      "         [ 0.3009, -1.3217,  0.8777,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  0.0000,  0.1775,  0.5406],\n",
      "         [ 1.2549,  0.2458,  1.6227,  ...,  1.0595,  0.0000,  0.5406]],\n",
      "\n",
      "        [[-0.1415,  0.7779,  0.6191,  ...,  1.2471, -0.4095,  0.4523],\n",
      "         [ 0.5050,  1.0873,  1.3636,  ...,  0.0000, -0.6293,  0.6233],\n",
      "         [ 1.0608, -0.6849,  0.8489,  ...,  1.6614, -0.6244,  1.4078],\n",
      "         ...,\n",
      "         [ 0.3009, -1.3217,  0.8777,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2549,  0.0000,  0.0000,  ...,  1.0595,  0.1775,  0.5406]]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 91])\n",
      "Mask ---> torch.Size([512, 1, 91])\n",
      "Mask new --> torch.Size([512, 1, 1, 91])\n",
      "loop within encoder. Iteration -- 1\n",
      "this is x in EncoderLayer-----> tensor([[[-2.3786e+00,  3.4904e+00, -6.1885e-01,  ..., -1.0992e+00,\n",
      "           1.6910e+00,  8.9896e-02],\n",
      "         [-1.8986e+00,  3.1674e+00,  6.3392e-01,  ..., -8.4930e-01,\n",
      "           1.9712e+00, -1.1411e+00],\n",
      "         [-1.7856e+00,  2.0645e+00, -9.0796e-01,  ..., -3.0593e-01,\n",
      "           3.5770e+00,  4.6832e-01],\n",
      "         ...,\n",
      "         [-2.1120e+00,  2.1417e+00,  5.3600e-01,  ..., -1.1635e+00,\n",
      "           2.6544e+00, -1.2760e+00],\n",
      "         [ 1.2314e+00,  8.2228e-01,  1.0837e+00,  ..., -9.0137e-01,\n",
      "           2.2056e+00, -1.5374e+00],\n",
      "         [-6.6109e-01,  3.0258e+00,  1.3899e+00,  ..., -2.0994e+00,\n",
      "           1.0549e+00, -1.0730e+00]],\n",
      "\n",
      "        [[-4.2422e-01,  4.2658e+00, -3.1623e-01,  ..., -1.4103e+00,\n",
      "           2.8724e+00, -3.2549e-01],\n",
      "         [-1.3378e+00,  3.2058e+00,  4.7402e-01,  ..., -1.0168e+00,\n",
      "           2.9394e+00, -3.2633e-02],\n",
      "         [-1.2641e+00,  1.8051e+00,  1.1624e+00,  ..., -1.2743e+00,\n",
      "           2.8730e+00,  5.1576e-01],\n",
      "         ...,\n",
      "         [-1.7427e+00, -4.2293e-01,  1.5300e+00,  ..., -1.5509e+00,\n",
      "           2.5521e+00, -1.2559e+00],\n",
      "         [-9.8076e-01,  1.7111e+00,  8.5125e-01,  ..., -1.3472e+00,\n",
      "           2.1918e+00, -9.4853e-01],\n",
      "         [-2.3830e-01,  3.1938e+00,  1.4102e+00,  ..., -1.0222e+00,\n",
      "           2.2102e+00, -1.5316e+00]],\n",
      "\n",
      "        [[-1.9744e+00,  3.4095e+00,  1.0175e-01,  ..., -1.1017e+00,\n",
      "           2.0474e+00, -7.2642e-01],\n",
      "         [-5.4478e-01,  2.5191e+00,  7.1656e-01,  ...,  1.3493e+00,\n",
      "           3.5458e+00,  2.6339e-01],\n",
      "         [ 1.3502e+00,  1.6091e+00,  1.9992e+00,  ...,  8.4338e-01,\n",
      "           3.4269e+00,  6.2594e-01],\n",
      "         ...,\n",
      "         [-5.3393e-01,  1.8976e+00,  1.2990e+00,  ..., -1.2014e+00,\n",
      "           3.2392e+00,  3.8013e-01],\n",
      "         [-1.5036e+00,  1.9139e+00,  1.6057e+00,  ..., -1.1378e+00,\n",
      "           2.3026e+00, -1.4828e+00],\n",
      "         [ 1.2247e-01,  2.3944e+00,  7.0691e-01,  ..., -2.1960e+00,\n",
      "           2.7447e+00, -1.3338e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.1630e+00,  3.8437e+00, -5.8568e-01,  ..., -7.3454e-01,\n",
      "           1.9573e+00, -6.4731e-01],\n",
      "         [-1.2956e+00,  2.6757e-01, -4.8687e-01,  ..., -1.1700e+00,\n",
      "           2.2332e+00,  1.4277e-01],\n",
      "         [ 4.2076e-03,  1.4285e+00, -2.1368e-01,  ...,  2.0972e-02,\n",
      "           2.7994e+00, -6.7569e-01],\n",
      "         ...,\n",
      "         [-1.6699e+00,  8.9948e-01,  6.6130e-02,  ..., -1.0400e+00,\n",
      "           2.3299e+00, -1.0931e+00],\n",
      "         [-2.6631e-01,  2.4367e+00,  1.3473e+00,  ...,  2.2863e-01,\n",
      "           1.5548e+00, -1.3395e+00],\n",
      "         [ 4.8413e-01,  3.3818e+00,  2.0700e+00,  ..., -1.1240e+00,\n",
      "           2.6410e+00, -1.4719e+00]],\n",
      "\n",
      "        [[-2.2178e+00,  2.9304e+00, -1.1842e+00,  ..., -1.1410e+00,\n",
      "           1.9310e+00, -1.0317e+00],\n",
      "         [-1.9860e+00,  2.4591e+00,  5.9329e-01,  ..., -1.7433e+00,\n",
      "           3.2474e+00, -2.6547e-01],\n",
      "         [-1.9965e+00,  2.5011e+00,  5.8458e-01,  ..., -1.6935e+00,\n",
      "           2.2204e+00, -7.4209e-02],\n",
      "         ...,\n",
      "         [-1.9927e+00,  3.6013e-01,  5.7775e-01,  ..., -1.4359e+00,\n",
      "           2.6836e+00, -1.5668e+00],\n",
      "         [ 1.2172e+00,  1.7104e+00,  2.0769e+00,  ..., -2.1864e+00,\n",
      "           3.4477e+00, -1.0580e+00],\n",
      "         [-3.6632e-01,  2.7817e+00,  1.6931e+00,  ..., -1.7473e+00,\n",
      "           2.1169e+00, -1.8937e+00]],\n",
      "\n",
      "        [[-2.1772e+00,  3.5557e+00,  1.1192e+00,  ..., -1.0733e+00,\n",
      "           1.6491e+00,  1.3155e-01],\n",
      "         [-1.8731e+00,  3.4287e+00,  9.8584e-02,  ..., -2.3309e+00,\n",
      "           8.1721e-01,  4.4571e-01],\n",
      "         [-1.0157e+00,  1.6625e+00,  8.3340e-02,  ..., -1.7434e+00,\n",
      "           1.7056e+00, -7.9284e-02],\n",
      "         ...,\n",
      "         [-1.1862e+00, -5.7272e-01,  2.5077e-01,  ..., -1.0176e+00,\n",
      "           2.2654e+00,  5.0102e-01],\n",
      "         [-4.4210e-01,  1.8931e+00,  1.5797e+00,  ..., -1.5175e+00,\n",
      "           2.2101e+00, -1.1785e+00],\n",
      "         [ 1.2833e+00,  2.4003e+00,  3.7637e-01,  ..., -1.0422e+00,\n",
      "           1.7747e-01, -4.8924e-01]]], grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 91])\n",
      "Mask ---> torch.Size([512, 1, 91])\n",
      "Mask new --> torch.Size([512, 1, 1, 91])\n",
      "loop within encoder. Iteration -- 2\n",
      "this is x in EncoderLayer-----> tensor([[[-1.8833,  5.0605, -0.9858,  ..., -3.2725,  0.8845, -1.0975],\n",
      "         [-1.8738,  3.1699,  0.9147,  ..., -2.7145,  1.8081, -2.2935],\n",
      "         [-1.3505,  3.6518, -1.5137,  ..., -2.4735,  2.8150, -1.1041],\n",
      "         ...,\n",
      "         [-1.9485,  3.9356,  0.0756,  ..., -2.9814,  1.9072, -2.5467],\n",
      "         [ 1.3720,  2.5211,  0.6115,  ..., -2.4404,  0.9835, -2.2160],\n",
      "         [-0.1024,  4.3639, -0.0936,  ..., -4.0216,  1.1584, -1.8745]],\n",
      "\n",
      "        [[-0.4984,  6.0779, -0.1723,  ..., -3.7394,  3.1488, -1.9440],\n",
      "         [-0.7696,  4.5761, -0.3934,  ..., -3.3172,  3.5980, -1.4269],\n",
      "         [-0.7722,  3.3726,  0.9981,  ..., -3.2081,  2.4732, -0.4250],\n",
      "         ...,\n",
      "         [-1.1807,  1.3542,  1.4997,  ..., -3.6903,  2.4624, -1.7854],\n",
      "         [-0.7700,  3.7852,  0.9097,  ..., -3.7925,  2.3228, -1.5946],\n",
      "         [ 0.3321,  4.9425,  1.1392,  ..., -3.2771,  2.5294, -2.5440]],\n",
      "\n",
      "        [[-1.5227,  3.0626, -0.1522,  ..., -1.1017,  2.3412, -1.9965],\n",
      "         [-0.2222,  3.0823,  0.7109,  ..., -0.3749,  3.9777, -1.5492],\n",
      "         [ 1.1936,  2.6979,  1.7025,  ..., -0.6024,  2.9821, -0.1551],\n",
      "         ...,\n",
      "         [-0.1576,  3.3737,  0.5442,  ..., -3.2260,  3.1336, -0.4903],\n",
      "         [-1.2073,  3.4289,  1.0311,  ..., -3.3429,  1.9046, -2.8467],\n",
      "         [ 0.2025,  2.7908, -0.1235,  ..., -3.6077,  2.6145, -2.2247]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.4116,  5.0809, -0.4028,  ..., -2.5249,  1.8287, -1.4615],\n",
      "         [-0.5944, -0.0794, -0.5576,  ..., -2.6613,  2.3663, -1.3167],\n",
      "         [ 0.9090,  2.7218, -0.2846,  ..., -0.0916,  2.5078, -1.9436],\n",
      "         ...,\n",
      "         [-1.3974,  2.7098, -0.6314,  ..., -3.2092,  1.9117, -1.8607],\n",
      "         [-0.2760,  3.9748,  0.7915,  ..., -1.5724,  1.5800, -0.9464],\n",
      "         [ 0.4835,  4.9883,  2.3943,  ..., -3.1989,  2.6410, -2.2855]],\n",
      "\n",
      "        [[-2.2178,  4.0600, -1.8710,  ..., -1.7746,  1.6092, -2.5152],\n",
      "         [-1.3705,  4.0646,  0.3174,  ..., -3.8428,  3.2276, -2.0617],\n",
      "         [-1.3600,  3.7441,  0.2096,  ..., -1.1091,  2.5607, -1.2538],\n",
      "         ...,\n",
      "         [-1.4818,  1.9606,  0.6940,  ..., -3.1196,  2.5673, -2.7462],\n",
      "         [ 1.6588,  3.4601,  1.2172,  ..., -3.8037,  3.6620, -2.0423],\n",
      "         [-0.3849,  3.8680,  0.6343,  ..., -3.6883,  2.7580, -3.7492]],\n",
      "\n",
      "        [[-2.0701,  5.5656,  0.7792,  ..., -1.7860,  1.6533, -0.6807],\n",
      "         [-1.6436,  5.0371, -0.7928,  ..., -4.0906,  1.0514, -0.2285],\n",
      "         [-0.7020,  3.5936, -0.3408,  ..., -1.6178,  1.3542, -1.0748],\n",
      "         ...,\n",
      "         [-0.5893,  0.8020, -0.7966,  ..., -3.3122,  2.6522, -0.3803],\n",
      "         [-0.0892,  3.5236,  0.9647,  ..., -3.7478,  2.4344, -2.3675],\n",
      "         [ 1.7274,  3.8710, -0.7790,  ..., -2.9115,  0.5383, -1.2053]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 91])\n",
      "Mask ---> torch.Size([512, 1, 91])\n",
      "Mask new --> torch.Size([512, 1, 1, 91])\n",
      "loop within encoder. Iteration -- 3\n",
      "this is x in EncoderLayer-----> tensor([[[-1.3885,  6.2607, -1.3393,  ..., -3.6394, -0.1399, -2.8191],\n",
      "         [-1.0931,  4.7133,  0.4601,  ..., -5.6196,  0.1422, -3.7721],\n",
      "         [-0.6737,  5.8353, -1.9096,  ..., -5.5888,  1.0886, -3.2674],\n",
      "         ...,\n",
      "         [-0.9380,  5.2181, -0.0997,  ..., -5.5926,  0.3965, -3.9945],\n",
      "         [ 2.0611,  3.1202,  0.4722,  ..., -4.6737,  0.0820, -3.3673],\n",
      "         [ 0.3426,  5.2825, -0.0993,  ..., -6.0290, -0.2966, -2.3830]],\n",
      "\n",
      "        [[ 0.5500,  7.2394, -0.7291,  ..., -6.8615,  1.1703, -3.4241],\n",
      "         [ 0.2807,  6.3060, -0.7672,  ..., -6.1987,  1.9966, -1.9891],\n",
      "         [ 0.0871,  4.9821,  0.8360,  ..., -5.7771,  1.0760, -2.1321],\n",
      "         ...,\n",
      "         [-0.3109,  2.6591,  1.5391,  ..., -6.5757,  1.0244, -3.1303],\n",
      "         [ 0.2361,  5.0749,  0.6398,  ..., -4.9265,  0.5876, -3.1865],\n",
      "         [ 1.8350,  6.5106,  1.3092,  ..., -5.8298,  0.4831, -3.8078]],\n",
      "\n",
      "        [[-0.7567,  4.5721, -0.5188,  ..., -3.5266,  0.7897, -2.6011],\n",
      "         [ 0.1846,  4.2971,  0.6861,  ..., -3.3102,  2.9241, -2.0688],\n",
      "         [ 1.5800,  4.3565,  1.6954,  ..., -3.4520,  2.4000, -1.9074],\n",
      "         ...,\n",
      "         [ 0.7095,  4.3365, -0.2304,  ..., -6.0332,  1.6716, -2.1481],\n",
      "         [-0.4453,  4.4109,  0.6960,  ..., -6.5732,  0.1981, -4.1260],\n",
      "         [ 0.5580,  4.1187, -0.6814,  ..., -6.3045,  1.0373, -3.4600]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.9728,  6.9069, -0.7824,  ..., -4.9511,  0.6548, -3.0925],\n",
      "         [ 0.2840,  0.8045, -1.0184,  ..., -5.4131,  1.1637, -2.7834],\n",
      "         [ 2.0491,  4.5566, -0.3243,  ..., -2.8853,  0.5905, -3.3771],\n",
      "         ...,\n",
      "         [-0.4020,  4.0573, -0.8534,  ..., -5.8642,  0.9172, -3.0167],\n",
      "         [ 0.8698,  5.7002,  0.7577,  ..., -3.5945, -0.1358, -1.4406],\n",
      "         [ 1.4583,  6.2635,  2.0881,  ..., -6.1472,  1.2360, -3.9179]],\n",
      "\n",
      "        [[-2.0023,  5.2833, -2.7766,  ..., -4.6257,  0.7307, -4.1165],\n",
      "         [-0.4248,  5.6763,  0.1171,  ..., -6.1115,  2.0968, -2.9986],\n",
      "         [-0.4437,  4.8038, -0.0320,  ..., -3.5875,  1.4519, -3.5049],\n",
      "         ...,\n",
      "         [-0.3489,  3.6007,  0.2898,  ..., -4.0981,  1.0648, -3.9733],\n",
      "         [ 2.2842,  4.9058,  0.9520,  ..., -5.7546,  4.2516, -3.5645],\n",
      "         [ 0.8287,  5.3192,  0.0909,  ..., -5.9117,  1.4891, -4.5467]],\n",
      "\n",
      "        [[-1.4597,  7.2655,  0.0461,  ..., -4.7159,  0.5402, -3.0276],\n",
      "         [-1.0302,  6.7542, -1.2437,  ..., -7.1567,  0.6362, -2.0464],\n",
      "         [ 0.2227,  3.5936, -0.7985,  ..., -4.6749,  1.7101, -2.9787],\n",
      "         ...,\n",
      "         [-0.0751,  2.4602, -1.2239,  ..., -5.3883,  1.5688, -1.8685],\n",
      "         [ 0.6044,  4.8160,  1.3879,  ..., -4.9153,  1.0947, -2.9068],\n",
      "         [ 2.6376,  5.5564, -0.9354,  ..., -5.9568, -0.7185, -2.5243]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 91])\n",
      "Mask ---> torch.Size([512, 1, 91])\n",
      "Mask new --> torch.Size([512, 1, 1, 91])\n",
      "loop within encoder. Iteration -- 4\n",
      "this is x in EncoderLayer-----> tensor([[[-1.9927,  8.2514, -3.3745,  ..., -4.2828, -0.8031, -5.5509],\n",
      "         [-1.6663,  6.7537, -1.8185,  ..., -5.3142, -0.1682, -6.4529],\n",
      "         [-0.4363,  7.1586, -4.1643,  ..., -5.8870,  1.8929, -6.1169],\n",
      "         ...,\n",
      "         [-1.6139,  7.0020, -2.6688,  ..., -5.6776, -0.2857, -5.7776],\n",
      "         [ 2.0611,  4.3866, -2.0962,  ..., -4.6720, -0.3388, -5.2463],\n",
      "         [ 0.1626,  6.8051, -1.9176,  ..., -6.3181, -0.4288, -5.0390]],\n",
      "\n",
      "        [[-0.7189,  9.2789, -2.8796,  ..., -7.4125,  0.5197, -6.1723],\n",
      "         [-0.6316,  7.7914, -3.2696,  ..., -6.7290,  0.1756, -4.8673],\n",
      "         [-0.6257,  7.0094, -1.5667,  ..., -5.8023,  0.1173, -4.8981],\n",
      "         ...,\n",
      "         [-0.5727,  4.7273, -0.8158,  ..., -6.7805, -0.1842, -5.7608],\n",
      "         [-0.6454,  7.3795, -1.5367,  ..., -5.1104, -0.2114, -5.2264],\n",
      "         [ 0.9118,  6.5106, -1.3228,  ..., -5.6885, -0.6344, -6.2152]],\n",
      "\n",
      "        [[-1.1817,  6.9361, -3.0034,  ..., -4.1025,  0.0481, -5.4889],\n",
      "         [-0.1201,  6.2520, -2.1392,  ..., -4.2814,  1.9386, -5.4485],\n",
      "         [ 0.7064,  6.2195, -0.5385,  ..., -3.7405,  3.0899, -4.1945],\n",
      "         ...,\n",
      "         [-0.0768,  6.0594, -2.1202,  ..., -6.6077,  0.5786, -4.2786],\n",
      "         [-1.3607,  6.6794, -1.8291,  ..., -7.3781, -1.4654, -6.8315],\n",
      "         [-0.0511,  5.7025, -3.6215,  ..., -6.9594,  0.3222, -5.6903]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.5573,  8.8679, -2.9593,  ..., -5.1149, -0.0927, -6.3020],\n",
      "         [-0.4979,  2.7415, -3.2990,  ..., -5.6842,  2.3630, -5.7591],\n",
      "         [ 1.9291,  6.5672, -2.4111,  ..., -2.9796, -0.4529, -5.9836],\n",
      "         ...,\n",
      "         [-1.4222,  5.5576, -2.8736,  ..., -6.0628,  0.1968, -5.4138],\n",
      "         [ 0.6559,  5.5114, -1.8165,  ..., -3.4275, -1.8416, -4.3964],\n",
      "         [ 1.1741,  8.1274, -0.5486,  ..., -6.1482,  0.9621, -6.2353]],\n",
      "\n",
      "        [[-3.2776,  7.0669, -5.0064,  ..., -5.0504,  0.3011, -6.6637],\n",
      "         [-1.1685,  7.7236, -2.3141,  ..., -6.4734,  0.6161, -5.9564],\n",
      "         [-1.1971,  4.8237, -1.6515,  ..., -3.8763,  0.2274, -6.3372],\n",
      "         ...,\n",
      "         [-0.8013,  5.5997, -2.2314,  ..., -4.2783,  0.5146, -6.8328],\n",
      "         [ 1.7021,  6.6968, -1.7148,  ..., -6.5800,  4.1925, -6.3790],\n",
      "         [ 0.3107,  5.3192, -0.5702,  ..., -6.0876,  1.0440, -6.8126]],\n",
      "\n",
      "        [[-2.3733,  9.4197, -1.7423,  ..., -4.3912, -0.6149, -6.3160],\n",
      "         [-1.3836,  8.5529, -3.5612,  ..., -7.1903, -0.0899, -5.6478],\n",
      "         [-0.5747,  5.4378, -3.1815,  ..., -4.7263,  0.8178, -5.7042],\n",
      "         ...,\n",
      "         [-1.3610,  4.2253, -3.2050,  ..., -5.5573,  0.9658, -4.2956],\n",
      "         [-0.1620,  6.9888, -1.0472,  ..., -5.0468,  0.7866, -5.9221],\n",
      "         [ 1.6914,  5.4670, -3.3564,  ..., -5.8168, -1.5930, -5.3462]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 91])\n",
      "Mask ---> torch.Size([512, 1, 91])\n",
      "Mask new --> torch.Size([512, 1, 1, 91])\n",
      "loop within encoder. Iteration -- 5\n",
      "this is x in EncoderLayer-----> tensor([[[ -1.2093,   7.8319,  -2.0038,  ...,  -6.8175,  -0.6523,  -4.2964],\n",
      "         [ -0.2767,   6.4739,  -0.2968,  ...,  -7.3202,   0.5169,  -4.9823],\n",
      "         [  0.9230,   6.0521,  -2.8570,  ...,  -8.3251,   2.3527,  -4.8368],\n",
      "         ...,\n",
      "         [ -0.1680,   6.9292,  -1.0290,  ...,  -6.2289,  -0.7969,  -4.3565],\n",
      "         [  3.0986,   3.7202,  -1.0046,  ...,  -6.8373,  -0.1850,  -4.0364],\n",
      "         [  1.5213,   6.1547,  -0.7203,  ...,  -8.3098,  -0.0208,  -3.1136]],\n",
      "\n",
      "        [[ -0.0365,   9.4924,  -2.2493,  ...,  -9.0991,   0.6443,  -4.4002],\n",
      "         [  0.6757,   6.8127,  -1.8203,  ...,  -9.3445,   0.6088,  -3.5118],\n",
      "         [  0.1989,   6.1669,  -0.5019,  ...,  -8.1037,   0.6207,  -3.3414],\n",
      "         ...,\n",
      "         [  0.0550,   4.0726,   0.6250,  ...,  -8.4930,  -0.7286,  -4.2837],\n",
      "         [  0.7335,   7.3978,  -0.5552,  ...,  -7.4077,  -0.0404,  -4.2685],\n",
      "         [  1.5233,   5.6783,  -0.2431,  ...,  -7.7877,  -0.3516,  -5.8620]],\n",
      "\n",
      "        [[ -0.4509,   6.4218,  -1.4207,  ...,  -7.3430,   0.7478,  -3.5096],\n",
      "         [  1.0212,   5.4089,  -1.0591,  ...,  -7.0346,   2.3857,  -4.3014],\n",
      "         [  2.1625,   5.4617,   0.1633,  ...,  -6.4075,   3.4383,  -2.3750],\n",
      "         ...,\n",
      "         [  0.9561,   5.0376,  -0.3206,  ...,  -8.7263,   0.6038,  -3.2502],\n",
      "         [ -0.6647,   7.1811,  -0.4740,  ..., -10.2450,  -0.8863,  -5.5517],\n",
      "         [  1.4076,   4.4411,  -2.7199,  ...,  -9.8516,   1.2798,  -5.6903]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  2.7997,   7.7850,  -1.9499,  ...,  -7.4998,   0.4209,  -4.8996],\n",
      "         [  0.1433,   2.4989,  -1.7523,  ...,  -7.9145,   2.7096,  -4.2183],\n",
      "         [  2.3612,   5.5194,  -0.7469,  ...,  -5.0643,   0.5139,  -3.8713],\n",
      "         ...,\n",
      "         [ -0.5142,   4.7615,  -1.8443,  ...,  -8.2216,   0.0818,  -4.1710],\n",
      "         [  2.1149,   4.5975,  -0.4494,  ...,  -5.6681,  -1.2142,  -3.1891],\n",
      "         [  2.2379,   7.6315,   0.7707,  ...,  -8.7927,   1.6113,  -4.5314]],\n",
      "\n",
      "        [[ -2.4833,   6.0033,  -3.7229,  ...,  -6.7835,   0.3277,  -5.5843],\n",
      "         [ -0.3170,   7.0462,  -0.8183,  ...,  -8.6328,   0.9865,  -4.3946],\n",
      "         [ -0.8157,   3.6940,  -0.7730,  ...,  -6.1797,   1.0508,  -5.1390],\n",
      "         ...,\n",
      "         [  0.0356,   4.5865,  -0.6306,  ...,  -6.2364,   0.7925,  -5.4974],\n",
      "         [  2.6226,   6.8612,  -0.5888,  ...,  -8.3612,   4.2649,  -4.6192],\n",
      "         [  1.2439,   4.6165,   1.0869,  ...,  -8.3973,   1.3975,  -4.6169]],\n",
      "\n",
      "        [[ -1.4342,   9.2063,  -0.3580,  ...,  -4.9491,  -1.0108,  -4.4212],\n",
      "         [ -0.5756,   8.0790,  -2.1884,  ...,  -9.6809,   0.4690,  -3.2666],\n",
      "         [  0.7667,   5.0400,  -1.3023,  ...,  -6.3726,   1.1094,  -3.8144],\n",
      "         ...,\n",
      "         [ -1.1070,   3.9809,  -1.5242,  ...,  -7.4360,   1.3622,  -2.9749],\n",
      "         [  0.8770,   6.9349,   0.7284,  ...,  -5.0756,   0.2706,  -4.8182],\n",
      "         [  2.9951,   4.8439,  -1.8186,  ...,  -7.9908,  -1.0528,  -3.4767]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 91])\n",
      "Mask ---> torch.Size([512, 1, 91])\n",
      "Mask new --> torch.Size([512, 1, 1, 91])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 92])\n",
      "Mask ---> torch.Size([512, 92, 92])\n",
      "Mask new --> torch.Size([512, 1, 92, 92])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 91])\n",
      "Mask ---> torch.Size([512, 1, 91])\n",
      "Mask new --> torch.Size([512, 1, 1, 91])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 92])\n",
      "Mask ---> torch.Size([512, 92, 92])\n",
      "Mask new --> torch.Size([512, 1, 92, 92])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 91])\n",
      "Mask ---> torch.Size([512, 1, 91])\n",
      "Mask new --> torch.Size([512, 1, 1, 91])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 92])\n",
      "Mask ---> torch.Size([512, 92, 92])\n",
      "Mask new --> torch.Size([512, 1, 92, 92])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 91])\n",
      "Mask ---> torch.Size([512, 1, 91])\n",
      "Mask new --> torch.Size([512, 1, 1, 91])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 92])\n",
      "Mask ---> torch.Size([512, 92, 92])\n",
      "Mask new --> torch.Size([512, 1, 92, 92])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 91])\n",
      "Mask ---> torch.Size([512, 1, 91])\n",
      "Mask new --> torch.Size([512, 1, 1, 91])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 92])\n",
      "Mask ---> torch.Size([512, 92, 92])\n",
      "Mask new --> torch.Size([512, 1, 92, 92])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 91])\n",
      "Mask ---> torch.Size([512, 1, 91])\n",
      "Mask new --> torch.Size([512, 1, 1, 91])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 92])\n",
      "Mask ---> torch.Size([512, 92, 92])\n",
      "Mask new --> torch.Size([512, 1, 92, 92])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 91])\n",
      "Mask ---> torch.Size([512, 1, 91])\n",
      "Mask new --> torch.Size([512, 1, 1, 91])\n",
      "predictions size : tensor([[-0.4811, -0.4970, -0.0055,  ..., -0.3388, -0.4049,  0.0539],\n",
      "        [-0.2989, -0.4472,  0.0123,  ..., -0.4189, -0.4882,  0.1125],\n",
      "        [-0.4950, -0.4173, -0.0757,  ..., -0.3363, -0.4559,  0.0254],\n",
      "        ...,\n",
      "        [-0.4777, -0.3007,  0.0169,  ..., -0.2634, -0.2698,  0.1255],\n",
      "        [-0.5599, -0.4573,  0.0468,  ..., -0.3186, -0.3177,  0.1021],\n",
      "        [-0.5171, -0.4177,  0.0481,  ..., -0.2719, -0.2610,  0.0628]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "targets size : torch.Size([47104])\n",
      "Loss.data ----> = 8.358562469482422\n",
      "Epoch - 1\n",
      "--Encoder x after PE : tensor([[[-0.5186,  0.6457,  0.6549,  ...,  0.0000,  0.0533,  1.1660],\n",
      "         [ 1.3081,  0.4407,  0.4658,  ...,  0.7913, -0.4291,  0.0000],\n",
      "         [ 0.4648, -0.0000,  0.9879,  ...,  1.6763,  0.4943,  1.2303],\n",
      "         ...,\n",
      "         [ 0.0000, -1.1531,  1.5235,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [ 1.3376, -0.2617,  1.7185,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0000,  0.6715,  1.0508,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.2413,  0.8721,  0.2442,  ...,  0.8461, -0.4593,  1.0868],\n",
      "         [ 0.6750,  0.2308,  0.7998,  ...,  0.4835, -0.6009,  0.5357],\n",
      "         [ 1.0603, -0.6865,  0.8495,  ...,  1.6607, -0.6232,  1.4063],\n",
      "         ...,\n",
      "         [ 0.6096, -1.1531,  1.5235,  ...,  0.0000,  0.1775,  0.5406],\n",
      "         [ 1.3376, -0.2617,  1.7185,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.0763,  0.0000,  1.0508,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.1218,  0.9281,  0.1226,  ...,  1.2315,  0.1485,  0.8161],\n",
      "         [ 0.7540,  0.0199,  0.5268,  ...,  0.0000,  0.1683,  1.1536],\n",
      "         [ 0.9995, -0.5144,  1.0761,  ...,  1.6469, -0.3283,  1.7547],\n",
      "         ...,\n",
      "         [ 0.0000, -1.1500,  0.2107,  ...,  1.1871, -0.0822,  1.1506],\n",
      "         [ 0.6187,  0.2091,  1.1781,  ...,  1.2108, -0.5943,  0.7130],\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.5624,  1.7542,  0.0940,  ...,  1.3312,  0.4885,  1.2060],\n",
      "         [ 0.9591,  0.5478,  0.8513,  ...,  1.3844, -0.4949,  1.0200],\n",
      "         [ 0.8294, -1.0030,  0.7004,  ...,  1.2170,  0.1683,  0.0000],\n",
      "         ...,\n",
      "         [ 0.6096, -1.1531,  1.5235,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.3376, -0.2617,  1.7185,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0000,  0.6715,  1.0508,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.5725,  1.2786,  0.1892,  ...,  0.8988, -0.2443,  0.5503],\n",
      "         [ 0.4875,  1.1208,  0.3600,  ...,  1.7116,  0.2793,  0.0000],\n",
      "         [ 0.0000, -0.0123,  0.4582,  ...,  0.0000, -0.4485,  0.5728],\n",
      "         ...,\n",
      "         [ 0.0000, -1.1531,  1.5235,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.3376, -0.2617,  1.7185,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  0.0000,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.0227,  1.6915, -0.0354,  ...,  0.7558, -0.1357,  0.7974],\n",
      "         [ 1.3269,  0.9530,  0.7390,  ...,  0.8474,  0.6387,  0.7068],\n",
      "         [ 0.4648, -0.5617,  0.9879,  ...,  1.6763,  0.4943,  1.2303],\n",
      "         ...,\n",
      "         [ 0.6096, -1.1531,  1.5235,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.3376, -0.2617,  1.7185,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  1.0595,  0.0000,  0.0000]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "loop within encoder. Iteration -- 0\n",
      "this is x in EncoderLayer-----> tensor([[[-0.5186,  0.6457,  0.6549,  ...,  0.0000,  0.0533,  1.1660],\n",
      "         [ 1.3081,  0.4407,  0.4658,  ...,  0.7913, -0.4291,  0.0000],\n",
      "         [ 0.4648, -0.0000,  0.9879,  ...,  1.6763,  0.4943,  1.2303],\n",
      "         ...,\n",
      "         [ 0.0000, -1.1531,  1.5235,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [ 1.3376, -0.2617,  1.7185,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0000,  0.6715,  1.0508,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.2413,  0.8721,  0.2442,  ...,  0.8461, -0.4593,  1.0868],\n",
      "         [ 0.6750,  0.2308,  0.7998,  ...,  0.4835, -0.6009,  0.5357],\n",
      "         [ 1.0603, -0.6865,  0.8495,  ...,  1.6607, -0.6232,  1.4063],\n",
      "         ...,\n",
      "         [ 0.6096, -1.1531,  1.5235,  ...,  0.0000,  0.1775,  0.5406],\n",
      "         [ 1.3376, -0.2617,  1.7185,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.0763,  0.0000,  1.0508,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.1218,  0.9281,  0.1226,  ...,  1.2315,  0.1485,  0.8161],\n",
      "         [ 0.7540,  0.0199,  0.5268,  ...,  0.0000,  0.1683,  1.1536],\n",
      "         [ 0.9995, -0.5144,  1.0761,  ...,  1.6469, -0.3283,  1.7547],\n",
      "         ...,\n",
      "         [ 0.0000, -1.1500,  0.2107,  ...,  1.1871, -0.0822,  1.1506],\n",
      "         [ 0.6187,  0.2091,  1.1781,  ...,  1.2108, -0.5943,  0.7130],\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.5624,  1.7542,  0.0940,  ...,  1.3312,  0.4885,  1.2060],\n",
      "         [ 0.9591,  0.5478,  0.8513,  ...,  1.3844, -0.4949,  1.0200],\n",
      "         [ 0.8294, -1.0030,  0.7004,  ...,  1.2170,  0.1683,  0.0000],\n",
      "         ...,\n",
      "         [ 0.6096, -1.1531,  1.5235,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.3376, -0.2617,  1.7185,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0000,  0.6715,  1.0508,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.5725,  1.2786,  0.1892,  ...,  0.8988, -0.2443,  0.5503],\n",
      "         [ 0.4875,  1.1208,  0.3600,  ...,  1.7116,  0.2793,  0.0000],\n",
      "         [ 0.0000, -0.0123,  0.4582,  ...,  0.0000, -0.4485,  0.5728],\n",
      "         ...,\n",
      "         [ 0.0000, -1.1531,  1.5235,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.3376, -0.2617,  1.7185,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  0.0000,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.0227,  1.6915, -0.0354,  ...,  0.7558, -0.1357,  0.7974],\n",
      "         [ 1.3269,  0.9530,  0.7390,  ...,  0.8474,  0.6387,  0.7068],\n",
      "         [ 0.4648, -0.5617,  0.9879,  ...,  1.6763,  0.4943,  1.2303],\n",
      "         ...,\n",
      "         [ 0.6096, -1.1531,  1.5235,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.3376, -0.2617,  1.7185,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  1.0595,  0.0000,  0.0000]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 85, 64]) , torch.Size([512, 8, 85, 64]), torch.Size([512, 8, 85, 64])\n",
      "Score shape -- torch.Size([512, 8, 85, 85])\n",
      "Mask ---> torch.Size([512, 1, 85])\n",
      "Mask new --> torch.Size([512, 1, 1, 85])\n",
      "loop within encoder. Iteration -- 1\n",
      "this is x in EncoderLayer-----> tensor([[[-2.1976,  2.5591,  0.3927,  ..., -2.2731,  2.7858, -0.5604],\n",
      "         [-0.2242,  2.4969,  0.8843,  ..., -1.9493,  2.6745, -0.8387],\n",
      "         [-1.3791,  3.0000,  0.2680,  ...,  0.6029,  3.6076, -0.0449],\n",
      "         ...,\n",
      "         [-0.8730,  1.7221,  1.0840,  ..., -2.2269,  2.3624, -1.1058],\n",
      "         [ 0.1763,  0.8389,  0.9725,  ..., -1.6070,  2.3835, -1.1101],\n",
      "         [ 0.7611,  2.8033,  0.2617,  ..., -1.8959,  2.7572, -1.3224]],\n",
      "\n",
      "        [[ 0.3786,  3.5808, -0.3085,  ..., -1.1137,  2.5914, -0.4031],\n",
      "         [-0.4938,  2.3084,  0.1610,  ..., -1.6537,  3.1305, -0.1391],\n",
      "         [-0.6922,  0.5020,  0.6091,  ..., -1.2432,  1.8859, -0.0690],\n",
      "         ...,\n",
      "         [-1.2030,  1.8428,  1.1505,  ..., -3.1172,  2.4157, -1.3324],\n",
      "         [ 1.9398,  2.5052,  1.2508,  ..., -1.9153,  1.7835, -1.6869],\n",
      "         [ 0.1219,  1.5268,  0.0621,  ..., -1.1746,  2.4688, -0.8226]],\n",
      "\n",
      "        [[-1.8621,  3.6272,  0.1835,  ..., -0.1026,  2.6819, -0.4713],\n",
      "         [-1.0007,  2.8422,  1.4329,  ..., -0.3731,  2.6384,  0.6779],\n",
      "         [-1.0199,  1.1778,  0.7678,  ...,  1.2841,  2.1051,  0.4661],\n",
      "         ...,\n",
      "         [-0.6067,  1.4208, -0.0192,  ..., -0.5875,  2.2159,  0.2050],\n",
      "         [ 1.6545,  2.2202,  0.7556,  ..., -0.1424,  2.2225, -0.8137],\n",
      "         [-0.0730,  3.2621,  0.7984,  ..., -0.9271,  2.5077, -2.0128]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.7991,  4.6360,  1.0614,  ..., -1.3874,  3.2998,  0.2905],\n",
      "         [-0.6371,  2.1616,  1.3539,  ..., -1.6827,  2.9604, -0.4550],\n",
      "         [-1.0493,  1.7425,  0.4743,  ..., -1.4508,  3.9239, -1.0205],\n",
      "         ...,\n",
      "         [-0.6625,  1.7209,  0.6593,  ..., -1.9080,  2.6435,  0.0911],\n",
      "         [ 0.1771,  0.8992,  1.0869,  ..., -1.7633,  2.4496, -1.4931],\n",
      "         [-1.3689,  4.2551,  1.5532,  ..., -2.2039,  2.0587, -1.4879]],\n",
      "\n",
      "        [[-1.1525,  3.7501, -0.1554,  ..., -0.7096,  1.9614,  0.2425],\n",
      "         [-1.8884,  3.2621,  0.2253,  ..., -0.0230,  1.9069, -1.4767],\n",
      "         [-2.5623,  2.7359, -0.0374,  ..., -2.2549,  2.5188, -0.3631],\n",
      "         ...,\n",
      "         [-2.6015,  1.5912,  1.3774,  ..., -1.2377,  2.3442, -2.1406],\n",
      "         [-0.1828,  2.7134,  0.9684,  ..., -1.3059,  2.6488,  0.1525],\n",
      "         [-0.4147,  3.3880,  0.4611,  ..., -2.0845,  2.5820, -1.2176]],\n",
      "\n",
      "        [[-1.0556,  2.8358, -0.3631,  ..., -1.4352,  3.1943, -1.2350],\n",
      "         [-0.1166,  3.3211, -0.8006,  ..., -0.8299,  2.3420, -0.6034],\n",
      "         [-0.8237,  0.5476, -0.5488,  ..., -0.3172,  3.1560,  1.1819],\n",
      "         ...,\n",
      "         [ 0.3188,  2.2398,  1.1962,  ..., -1.5111,  2.0431, -1.5942],\n",
      "         [ 0.1073,  2.5849,  1.7185,  ..., -1.5447,  2.6987,  0.1242],\n",
      "         [ 0.3066,  3.7304,  1.2005,  ..., -1.6104,  2.7074, -1.6633]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 85, 64]) , torch.Size([512, 8, 85, 64]), torch.Size([512, 8, 85, 64])\n",
      "Score shape -- torch.Size([512, 8, 85, 85])\n",
      "Mask ---> torch.Size([512, 1, 85])\n",
      "Mask new --> torch.Size([512, 1, 1, 85])\n",
      "loop within encoder. Iteration -- 2\n",
      "this is x in EncoderLayer-----> tensor([[[-1.5456,  3.4415,  0.5971,  ..., -4.2432,  2.6462, -1.9300],\n",
      "         [ 0.5021,  3.6522,  1.2839,  ..., -3.9985,  2.6825, -2.0972],\n",
      "         [-1.0661,  4.4074,  0.2980,  ..., -1.4099,  3.0225, -1.4004],\n",
      "         ...,\n",
      "         [-0.0927,  3.6681,  0.6742,  ..., -4.2212,  2.3097, -1.7871],\n",
      "         [ 0.8433,  2.4944,  0.6114,  ..., -3.6708,  2.0371, -1.4314],\n",
      "         [ 1.2709,  4.1242, -0.4078,  ..., -3.7407,  3.0307, -2.5579]],\n",
      "\n",
      "        [[ 1.8706,  6.0957, -0.3039,  ..., -2.4526,  2.7149, -2.3709],\n",
      "         [ 0.9577,  3.9885,  0.0420,  ..., -3.8407,  2.5430, -2.6174],\n",
      "         [-0.6922,  0.8737,  0.6911,  ..., -3.2363,  1.6924, -0.6518],\n",
      "         ...,\n",
      "         [-1.0996,  4.3412,  0.1011,  ..., -4.5100,  1.7356, -2.6716],\n",
      "         [ 2.5753,  4.8390,  0.9017,  ..., -3.2077,  2.5664, -2.9298],\n",
      "         [ 1.2438,  3.5903, -1.2584,  ..., -2.8346,  2.3319, -1.4812]],\n",
      "\n",
      "        [[-1.7625,  5.6813, -0.6300,  ..., -1.8582,  2.0182, -1.8634],\n",
      "         [-0.6251,  4.1030,  1.4314,  ..., -1.8255,  2.2272,  0.3007],\n",
      "         [-0.7317,  3.0237, -0.0692,  ..., -0.3984,  1.7064, -0.6389],\n",
      "         ...,\n",
      "         [-0.9637,  3.8301, -0.0798,  ..., -2.6716,  1.9995, -0.2096],\n",
      "         [ 1.6651,  4.2156,  0.5304,  ..., -1.8531,  2.2443, -1.4831],\n",
      "         [-0.1201,  5.3589, -0.1969,  ..., -2.4392,  1.6368, -2.7897]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.8084,  6.3784,  0.5179,  ..., -3.2787,  3.3152, -1.2236],\n",
      "         [-0.2551,  3.1507,  0.7184,  ..., -4.0093,  3.0324, -2.2144],\n",
      "         [-0.4529,  2.8617,  0.2207,  ..., -1.4290,  3.9286, -2.5355],\n",
      "         ...,\n",
      "         [-0.7026,  3.1309,  0.4835,  ..., -4.1361,  2.8613, -0.6780],\n",
      "         [ 0.1574,  2.3758,  0.0593,  ..., -3.3195,  2.6984, -3.1380],\n",
      "         [-0.5381,  4.4775,  1.1499,  ..., -3.7275,  1.8696, -2.4304]],\n",
      "\n",
      "        [[-0.6728,  4.6804, -0.3986,  ..., -1.9547,  1.7779, -1.2976],\n",
      "         [-1.5975,  4.3451, -0.3116,  ..., -2.3851,  1.9069, -2.8548],\n",
      "         [-1.8103,  4.5579, -0.9024,  ..., -4.5685,  1.8916, -1.0260],\n",
      "         ...,\n",
      "         [-1.8562,  3.1062,  0.8412,  ..., -3.1664,  1.5501, -3.7263],\n",
      "         [ 0.7955,  4.2075,  0.3108,  ..., -3.3973,  2.7625, -1.0556],\n",
      "         [-0.1712,  4.7340, -0.1674,  ..., -3.4137,  2.3316, -2.2323]],\n",
      "\n",
      "        [[-0.5991,  4.1246, -0.7097,  ..., -3.0895,  2.5773, -3.3057],\n",
      "         [-0.1595,  4.3517, -1.1103,  ..., -2.5194,  2.4040, -1.4992],\n",
      "         [-0.8615,  1.6145, -1.5566,  ..., -2.2204,  3.3177, -0.4171],\n",
      "         ...,\n",
      "         [ 0.8048,  4.0418,  1.9150,  ..., -3.1998,  1.7467, -1.9199],\n",
      "         [ 0.0546,  4.3266,  0.9551,  ..., -3.1618,  2.3772, -0.8186],\n",
      "         [ 0.4102,  5.6394,  1.8484,  ..., -3.0708,  2.3919, -2.8874]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 85, 64]) , torch.Size([512, 8, 85, 64]), torch.Size([512, 8, 85, 64])\n",
      "Score shape -- torch.Size([512, 8, 85, 85])\n",
      "Mask ---> torch.Size([512, 1, 85])\n",
      "Mask new --> torch.Size([512, 1, 1, 85])\n",
      "loop within encoder. Iteration -- 3\n",
      "this is x in EncoderLayer-----> tensor([[[-1.2573,  5.3145,  0.7703,  ..., -6.7176,  1.3153, -3.0017],\n",
      "         [ 0.6670,  5.7008,  0.7562,  ..., -6.7012,  3.3452, -3.7995],\n",
      "         [-0.5337,  6.0649, -0.2935,  ..., -4.8609,  1.4073, -2.9089],\n",
      "         ...,\n",
      "         [ 0.8577,  4.6663,  1.4870,  ..., -6.9227,  0.6251, -2.9525],\n",
      "         [ 1.3757,  3.0936,  0.8913,  ..., -4.3057,  0.1042, -2.6757],\n",
      "         [ 1.6903,  5.6945, -0.4611,  ..., -6.0019,  1.2914, -3.9597]],\n",
      "\n",
      "        [[ 2.6910,  6.7124, -0.5227,  ..., -4.8679,  1.1358, -3.7753],\n",
      "         [ 1.8036,  4.8577,  0.2360,  ..., -6.5952,  2.0393, -4.0415],\n",
      "         [-0.2433,  1.8063,  0.8887,  ..., -3.2363,  0.2469, -2.0049],\n",
      "         ...,\n",
      "         [ 0.4368,  5.5251,  0.7027,  ..., -6.2708,  1.0574, -3.8608],\n",
      "         [ 4.1174,  6.1887,  0.9828,  ..., -5.7526,  0.8765, -4.1573],\n",
      "         [ 2.0745,  4.6150, -0.4915,  ..., -5.5956,  1.2850, -2.3970]],\n",
      "\n",
      "        [[-1.6425,  7.0172, -1.1176,  ..., -5.0446,  0.3461, -3.6332],\n",
      "         [ 0.5311,  5.7004,  1.3236,  ..., -4.2316, -0.0472, -1.5145],\n",
      "         [-0.2091,  4.2497,  0.0148,  ..., -2.9510,  0.4604, -2.7452],\n",
      "         ...,\n",
      "         [-0.1022,  4.8835, -0.2558,  ..., -5.5182,  0.1748, -1.9918],\n",
      "         [ 2.4935,  5.6444,  0.3182,  ..., -3.9876,  0.1496, -3.3015],\n",
      "         [ 0.2720,  6.4600,  0.3179,  ..., -5.6083, -0.0872, -4.3622]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.7826,  7.7003,  0.0676,  ..., -6.4182,  2.0401, -2.3243],\n",
      "         [ 0.1855,  4.8462,  1.3621,  ..., -6.9783,  2.3000, -3.4218],\n",
      "         [ 0.3077,  3.2141,  0.6866,  ..., -3.8044,  3.2012, -3.7721],\n",
      "         ...,\n",
      "         [-0.8607,  3.7820,  0.8916,  ..., -4.8193,  1.8278, -1.4430],\n",
      "         [ 0.7325,  3.3056,  0.5038,  ..., -4.0606,  0.8786, -3.7868],\n",
      "         [ 0.3810,  5.6382,  2.1886,  ..., -6.5008,  0.1261, -2.6263]],\n",
      "\n",
      "        [[ 0.1173,  4.9785,  0.0991,  ..., -4.9883,  0.3614, -2.6733],\n",
      "         [-1.9976,  5.5603, -0.6997,  ..., -5.2608,  0.5884, -4.3461],\n",
      "         [-1.7936,  4.9776, -1.2333,  ..., -7.6184,  0.7774, -3.0910],\n",
      "         ...,\n",
      "         [-2.0113,  4.4898,  0.7788,  ..., -6.3177, -0.6275, -4.4131],\n",
      "         [ 1.2544,  5.8377,  0.7535,  ..., -6.3197,  0.8228, -1.7875],\n",
      "         [ 0.3456,  6.4744,  0.0246,  ..., -6.6362,  0.7785, -4.3162]],\n",
      "\n",
      "        [[-0.4303,  6.2790, -1.1781,  ..., -6.2337,  1.4791, -4.5813],\n",
      "         [ 0.5902,  4.8927, -0.9846,  ..., -3.6682,  2.2965, -3.3433],\n",
      "         [-0.4867,  3.1404, -1.7035,  ..., -5.0365,  1.6841, -1.8297],\n",
      "         ...,\n",
      "         [ 1.4186,  5.4574,  1.8681,  ..., -3.9641,  0.2522, -2.9947],\n",
      "         [ 0.1530,  6.4215,  1.1978,  ..., -5.7970,  0.3595, -1.8962],\n",
      "         [ 1.0527,  7.6788,  1.9311,  ..., -5.7087,  0.7313, -4.1370]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 85, 64]) , torch.Size([512, 8, 85, 64]), torch.Size([512, 8, 85, 64])\n",
      "Score shape -- torch.Size([512, 8, 85, 85])\n",
      "Mask ---> torch.Size([512, 1, 85])\n",
      "Mask new --> torch.Size([512, 1, 1, 85])\n",
      "loop within encoder. Iteration -- 4\n",
      "this is x in EncoderLayer-----> tensor([[[-1.7085,  7.0158, -1.0439,  ..., -7.1148,  2.5824, -5.9323],\n",
      "         [-0.4820,  5.8807, -1.1300,  ..., -7.0672,  2.8479, -7.0368],\n",
      "         [-1.6970,  8.0645, -1.9503,  ..., -5.1937,  0.9671, -4.5056],\n",
      "         ...,\n",
      "         [-0.4416,  7.2892, -0.3391,  ..., -7.5251, -0.1825, -6.1127],\n",
      "         [ 0.5499,  4.5944, -1.4619,  ..., -5.5054, -0.3419, -4.6653],\n",
      "         [ 0.7827,  7.5054, -2.9694,  ..., -6.6654,  0.5169, -6.5053]],\n",
      "\n",
      "        [[ 2.1427,  8.5361, -2.3990,  ..., -5.1560, -0.5980, -6.5402],\n",
      "         [ 1.1042,  6.9650, -1.8802,  ..., -6.7765,  1.5229, -6.5188],\n",
      "         [-0.9003,  4.1985, -1.6616,  ..., -3.3668,  0.2860, -4.5479],\n",
      "         ...,\n",
      "         [-0.3055,  7.4118, -1.5506,  ..., -6.7265,  0.4709, -6.6314],\n",
      "         [ 3.7674,  7.7748, -0.8669,  ..., -6.2609,  0.4554, -6.9402],\n",
      "         [ 2.6573,  6.7545, -2.8705,  ..., -5.9274,  1.9785, -4.3885]],\n",
      "\n",
      "        [[-2.4444,  8.7007, -3.4344,  ..., -5.1979, -1.2046, -6.7213],\n",
      "         [-0.2074,  7.0882, -1.1942,  ..., -4.5715, -1.5462, -4.5121],\n",
      "         [-0.7664,  5.7131, -1.9526,  ..., -3.4048,  0.1515, -5.6461],\n",
      "         ...,\n",
      "         [-0.5034,  6.5866, -3.0530,  ..., -5.6175, -0.6979, -5.1327],\n",
      "         [ 2.8386,  7.2371, -2.4159,  ..., -4.1104, -0.9739, -4.3523],\n",
      "         [-0.8404,  6.6085, -0.2144,  ..., -5.9448, -1.6083, -6.1748]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.1400,  9.8661, -2.0646,  ..., -6.4575,  1.2650, -5.0311],\n",
      "         [-0.4209,  6.5116, -1.1633,  ..., -7.3899,  1.6482, -6.3090],\n",
      "         [-0.7742,  5.0635,  0.5243,  ..., -3.6658,  1.6834, -6.2211],\n",
      "         ...,\n",
      "         [-1.7077,  5.2028, -1.7977,  ..., -5.2632,  1.2333, -3.5720],\n",
      "         [-0.1126,  5.2699, -2.0390,  ..., -3.7103, -0.0708, -5.6508],\n",
      "         [-0.2329,  7.8730, -0.2501,  ..., -6.8216, -0.7096, -5.1941]],\n",
      "\n",
      "        [[-0.3428,  7.0958, -2.1999,  ..., -5.3167, -0.1214, -4.3906],\n",
      "         [-3.0681,  7.3402, -1.4324,  ..., -6.3898,  2.1168, -7.1264],\n",
      "         [-2.3787,  6.5491, -2.7025,  ..., -7.7098, -0.0208, -5.8279],\n",
      "         ...,\n",
      "         [-3.0995,  6.1932, -1.4713,  ..., -6.4944, -2.3188, -6.7374],\n",
      "         [ 0.6377,  7.1387, -1.4745,  ..., -6.3876,  0.8228, -4.3390],\n",
      "         [-0.4742,  8.0242, -2.0680,  ..., -6.5101, -0.1212, -6.7831]],\n",
      "\n",
      "        [[-0.8989,  7.7592, -2.8871,  ..., -6.1679,  0.8585, -7.5287],\n",
      "         [ 0.2990,  6.9821, -3.1589,  ..., -3.6566,  0.8601, -5.3034],\n",
      "         [-1.7629,  5.3193, -1.9770,  ..., -5.3374,  1.4198, -4.5719],\n",
      "         ...,\n",
      "         [ 0.6281,  7.3173, -0.8746,  ..., -4.9096, -0.3906, -4.3163],\n",
      "         [-0.8872,  8.0038, -1.2253,  ..., -6.2056, -0.1874, -4.7371],\n",
      "         [-0.1987,  9.8592, -0.2027,  ..., -5.8623,  0.6849, -7.0205]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 85, 64]) , torch.Size([512, 8, 85, 64]), torch.Size([512, 8, 85, 64])\n",
      "Score shape -- torch.Size([512, 8, 85, 85])\n",
      "Mask ---> torch.Size([512, 1, 85])\n",
      "Mask new --> torch.Size([512, 1, 1, 85])\n",
      "loop within encoder. Iteration -- 5\n",
      "this is x in EncoderLayer-----> tensor([[[-1.0913e+00,  6.1053e+00,  1.4995e-01,  ..., -8.7613e+00,\n",
      "           2.7894e+00, -4.2606e+00],\n",
      "         [ 3.5400e-01,  5.2658e+00, -4.9791e-01,  ..., -9.3482e+00,\n",
      "           3.6528e+00, -5.4061e+00],\n",
      "         [-1.8299e-01,  6.7693e+00, -7.2480e-01,  ..., -7.6650e+00,\n",
      "           1.6800e+00, -2.1314e+00],\n",
      "         ...,\n",
      "         [ 6.2900e-01,  7.5455e+00,  8.7472e-01,  ..., -8.9913e+00,\n",
      "          -1.7647e-01, -4.4380e+00],\n",
      "         [ 1.4120e+00,  3.9050e+00, -1.1472e+00,  ..., -7.3497e+00,\n",
      "           3.0271e-01, -2.6759e+00],\n",
      "         [ 1.7626e+00,  6.3417e+00, -3.5968e+00,  ..., -8.7077e+00,\n",
      "           9.6415e-01, -4.7166e+00]],\n",
      "\n",
      "        [[ 3.1205e+00,  8.5167e+00, -1.5639e+00,  ..., -7.5433e+00,\n",
      "          -8.9157e-01, -5.6883e+00],\n",
      "         [ 2.5114e+00,  5.5517e+00, -1.0043e+00,  ..., -9.2640e+00,\n",
      "           2.0130e+00, -4.5865e+00],\n",
      "         [ 6.3867e-01,  2.9840e+00, -6.2787e-01,  ..., -5.5077e+00,\n",
      "           5.4572e-01, -2.6557e+00],\n",
      "         ...,\n",
      "         [ 4.8906e-01,  6.2560e+00, -4.9559e-01,  ..., -9.2994e+00,\n",
      "           7.4480e-01, -5.2294e+00],\n",
      "         [ 5.1504e+00,  6.6525e+00,  1.2080e-02,  ..., -6.9403e+00,\n",
      "           9.2443e-02, -5.5903e+00],\n",
      "         [ 3.2617e+00,  5.9799e+00, -1.6514e+00,  ..., -7.6861e+00,\n",
      "           1.9632e+00, -2.3699e+00]],\n",
      "\n",
      "        [[-1.8108e+00,  7.9393e+00, -1.8741e+00,  ..., -7.7855e+00,\n",
      "          -8.5034e-01, -5.1782e+00],\n",
      "         [ 1.0511e+00,  6.3578e+00,  1.4285e-01,  ..., -6.1646e+00,\n",
      "          -2.1597e+00, -3.0481e+00],\n",
      "         [-3.4259e-01,  5.0233e+00, -1.0701e+00,  ..., -5.8661e+00,\n",
      "           7.6439e-01, -5.2432e+00],\n",
      "         ...,\n",
      "         [ 6.3042e-01,  5.8070e+00, -1.9731e+00,  ..., -8.3430e+00,\n",
      "           1.0821e-01, -3.6325e+00],\n",
      "         [ 3.5274e+00,  6.5308e+00, -1.1325e+00,  ..., -5.9726e+00,\n",
      "          -1.0214e+00, -2.3676e+00],\n",
      "         [-8.7193e-01,  5.7009e+00,  1.2862e+00,  ..., -8.1785e+00,\n",
      "          -1.6732e+00, -4.5434e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-8.9756e-01,  8.7236e+00, -5.6525e-01,  ..., -8.9320e+00,\n",
      "           2.0733e+00, -2.9743e+00],\n",
      "         [ 4.7588e-01,  5.4464e+00,  4.0820e-02,  ..., -9.3543e+00,\n",
      "           2.0422e+00, -4.3716e+00],\n",
      "         [ 8.2145e-01,  4.2341e+00,  2.0767e+00,  ..., -6.0639e+00,\n",
      "           2.7137e+00, -3.9795e+00],\n",
      "         ...,\n",
      "         [-3.3468e-01,  4.4131e+00, -7.6483e-01,  ..., -7.2433e+00,\n",
      "           7.5982e-01, -3.5720e+00],\n",
      "         [ 5.1043e-01,  4.2512e+00, -9.6259e-01,  ..., -5.9997e+00,\n",
      "           4.4639e-01, -4.3042e+00],\n",
      "         [ 1.0772e+00,  6.9638e+00,  1.5180e+00,  ..., -8.7455e+00,\n",
      "           1.4539e-01, -3.0775e+00]],\n",
      "\n",
      "        [[ 5.6707e-01,  6.0467e+00, -1.0583e+00,  ..., -7.7310e+00,\n",
      "           4.3636e-01, -2.5313e+00],\n",
      "         [-2.5794e+00,  6.6439e+00,  1.5593e-01,  ..., -9.1191e+00,\n",
      "           2.6370e+00, -5.1075e+00],\n",
      "         [-1.5301e+00,  6.1459e+00, -1.2250e+00,  ..., -8.4547e+00,\n",
      "           2.5429e-01, -3.6606e+00],\n",
      "         ...,\n",
      "         [-1.6548e+00,  5.0722e+00, -4.3669e-01,  ..., -8.9574e+00,\n",
      "          -2.3760e+00, -5.3267e+00],\n",
      "         [ 1.5854e+00,  6.5689e+00, -8.8579e-03,  ..., -8.7796e+00,\n",
      "           3.8408e-01, -2.6075e+00],\n",
      "         [ 7.0932e-01,  7.0639e+00, -4.4025e-01,  ..., -9.1342e+00,\n",
      "          -8.8537e-01, -4.9165e+00]],\n",
      "\n",
      "        [[ 5.1566e-02,  7.0567e+00, -1.3888e+00,  ..., -8.8666e+00,\n",
      "           1.4524e+00, -7.5287e+00],\n",
      "         [ 1.3153e+00,  6.2306e+00, -2.2641e+00,  ..., -5.5370e+00,\n",
      "           2.5229e+00, -5.3034e+00],\n",
      "         [-9.6116e-01,  3.4994e+00, -8.2144e-01,  ..., -7.8689e+00,\n",
      "           2.0845e+00, -2.6024e+00],\n",
      "         ...,\n",
      "         [ 9.8526e-01,  6.3785e+00,  1.0751e-01,  ..., -7.8084e+00,\n",
      "          -3.4197e-01, -3.8195e+00],\n",
      "         [-1.9413e-01,  6.9929e+00,  5.3425e-01,  ..., -8.4090e+00,\n",
      "           6.6055e-01, -2.6017e+00],\n",
      "         [ 8.4073e-01,  8.8709e+00,  1.0354e+00,  ..., -8.4810e+00,\n",
      "           1.0893e+00, -5.7071e+00]]], grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 85, 64]) , torch.Size([512, 8, 85, 64]), torch.Size([512, 8, 85, 64])\n",
      "Score shape -- torch.Size([512, 8, 85, 85])\n",
      "Mask ---> torch.Size([512, 1, 85])\n",
      "Mask new --> torch.Size([512, 1, 1, 85])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 86, 64]) , torch.Size([512, 8, 86, 64]), torch.Size([512, 8, 86, 64])\n",
      "Score shape -- torch.Size([512, 8, 86, 86])\n",
      "Mask ---> torch.Size([512, 86, 86])\n",
      "Mask new --> torch.Size([512, 1, 86, 86])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 86, 64]) , torch.Size([512, 8, 85, 64]), torch.Size([512, 8, 85, 64])\n",
      "Score shape -- torch.Size([512, 8, 86, 85])\n",
      "Mask ---> torch.Size([512, 1, 85])\n",
      "Mask new --> torch.Size([512, 1, 1, 85])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 86, 64]) , torch.Size([512, 8, 86, 64]), torch.Size([512, 8, 86, 64])\n",
      "Score shape -- torch.Size([512, 8, 86, 86])\n",
      "Mask ---> torch.Size([512, 86, 86])\n",
      "Mask new --> torch.Size([512, 1, 86, 86])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 86, 64]) , torch.Size([512, 8, 85, 64]), torch.Size([512, 8, 85, 64])\n",
      "Score shape -- torch.Size([512, 8, 86, 85])\n",
      "Mask ---> torch.Size([512, 1, 85])\n",
      "Mask new --> torch.Size([512, 1, 1, 85])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 86, 64]) , torch.Size([512, 8, 86, 64]), torch.Size([512, 8, 86, 64])\n",
      "Score shape -- torch.Size([512, 8, 86, 86])\n",
      "Mask ---> torch.Size([512, 86, 86])\n",
      "Mask new --> torch.Size([512, 1, 86, 86])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 86, 64]) , torch.Size([512, 8, 85, 64]), torch.Size([512, 8, 85, 64])\n",
      "Score shape -- torch.Size([512, 8, 86, 85])\n",
      "Mask ---> torch.Size([512, 1, 85])\n",
      "Mask new --> torch.Size([512, 1, 1, 85])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 86, 64]) , torch.Size([512, 8, 86, 64]), torch.Size([512, 8, 86, 64])\n",
      "Score shape -- torch.Size([512, 8, 86, 86])\n",
      "Mask ---> torch.Size([512, 86, 86])\n",
      "Mask new --> torch.Size([512, 1, 86, 86])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 86, 64]) , torch.Size([512, 8, 85, 64]), torch.Size([512, 8, 85, 64])\n",
      "Score shape -- torch.Size([512, 8, 86, 85])\n",
      "Mask ---> torch.Size([512, 1, 85])\n",
      "Mask new --> torch.Size([512, 1, 1, 85])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 86, 64]) , torch.Size([512, 8, 86, 64]), torch.Size([512, 8, 86, 64])\n",
      "Score shape -- torch.Size([512, 8, 86, 86])\n",
      "Mask ---> torch.Size([512, 86, 86])\n",
      "Mask new --> torch.Size([512, 1, 86, 86])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 86, 64]) , torch.Size([512, 8, 85, 64]), torch.Size([512, 8, 85, 64])\n",
      "Score shape -- torch.Size([512, 8, 86, 85])\n",
      "Mask ---> torch.Size([512, 1, 85])\n",
      "Mask new --> torch.Size([512, 1, 1, 85])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 86, 64]) , torch.Size([512, 8, 86, 64]), torch.Size([512, 8, 86, 64])\n",
      "Score shape -- torch.Size([512, 8, 86, 86])\n",
      "Mask ---> torch.Size([512, 86, 86])\n",
      "Mask new --> torch.Size([512, 1, 86, 86])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 86, 64]) , torch.Size([512, 8, 85, 64]), torch.Size([512, 8, 85, 64])\n",
      "Score shape -- torch.Size([512, 8, 86, 85])\n",
      "Mask ---> torch.Size([512, 1, 85])\n",
      "Mask new --> torch.Size([512, 1, 1, 85])\n",
      "predictions size : tensor([[-0.4109, -0.4910, -0.0831,  ..., -0.2874, -0.3573,  0.2298],\n",
      "        [-0.5072, -0.4477, -0.0122,  ..., -0.2521, -0.4148,  0.0690],\n",
      "        [-0.2663, -0.5048, -0.0843,  ..., -0.3730, -0.4271,  0.0407],\n",
      "        ...,\n",
      "        [-0.4648, -0.5439,  0.0016,  ..., -0.2545, -0.4185, -0.0126],\n",
      "        [-0.5732, -0.4564, -0.0595,  ..., -0.2308, -0.2976, -0.0460],\n",
      "        [-0.5048, -0.4695, -0.1144,  ..., -0.3423, -0.2712, -0.0039]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "targets size : torch.Size([44032])\n",
      "Loss.data ----> = 8.298086166381836\n",
      "--Encoder x after PE : tensor([[[-0.0433,  1.2168, -0.0000,  ...,  0.8918, -0.1615,  0.4952],\n",
      "         [ 0.0000,  0.0953,  0.0000,  ...,  1.5577,  0.1347,  1.5498],\n",
      "         [ 0.4460, -0.6287,  1.4339,  ...,  1.5992,  0.5688,  1.0683],\n",
      "         ...,\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.3129,  0.0000,  0.0000,  ...,  0.6881,  0.0000,  0.0000],\n",
      "         [ 1.2856,  0.2515,  1.4868,  ...,  0.8331,  0.2711,  0.0000],\n",
      "         [ 1.3742,  0.0646,  0.6919,  ...,  0.5222,  0.5191,  0.6669],\n",
      "         ...,\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.5731,  1.2781,  0.0000,  ...,  0.8990, -0.2433,  0.5490],\n",
      "         [ 0.7431,  0.0192,  1.0512,  ...,  1.7539,  0.0480,  1.6365],\n",
      "         [ 0.7626,  0.2134,  0.4146,  ...,  0.9910,  0.4200,  1.6285],\n",
      "         ...,\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.5268,  0.9170,  0.0000,  ...,  0.5184, -0.6256,  0.7978],\n",
      "         [ 1.5896,  1.2678,  0.7490,  ...,  0.7081, -0.0208,  0.8012],\n",
      "         [ 1.1066, -0.0000,  1.6085,  ...,  1.3321,  0.4595,  0.5766],\n",
      "         ...,\n",
      "         [ 1.0763,  0.6715,  0.0000,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0000,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.0000, -0.4602,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.3793,  0.6241, -0.3198,  ...,  1.6513,  0.2846,  1.0315],\n",
      "         [ 0.6409,  1.2736,  1.2004,  ...,  1.6316,  0.6514,  0.6881],\n",
      "         [ 1.0089, -0.8313,  1.5957,  ...,  0.0000, -0.4128,  1.5523],\n",
      "         ...,\n",
      "         [ 0.0000,  0.6715,  1.0508,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.3748,  0.5203, -0.0000,  ...,  1.5776, -0.3198,  0.8485],\n",
      "         [ 0.6744,  0.0000,  0.7988,  ...,  0.4836, -0.6008,  0.5347],\n",
      "         [ 0.8511, -0.1119,  1.1194,  ...,  1.7415,  0.0198,  0.0000],\n",
      "         ...,\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "loop within encoder. Iteration -- 0\n",
      "this is x in EncoderLayer-----> tensor([[[-0.0433,  1.2168, -0.0000,  ...,  0.8918, -0.1615,  0.4952],\n",
      "         [ 0.0000,  0.0953,  0.0000,  ...,  1.5577,  0.1347,  1.5498],\n",
      "         [ 0.4460, -0.6287,  1.4339,  ...,  1.5992,  0.5688,  1.0683],\n",
      "         ...,\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.3129,  0.0000,  0.0000,  ...,  0.6881,  0.0000,  0.0000],\n",
      "         [ 1.2856,  0.2515,  1.4868,  ...,  0.8331,  0.2711,  0.0000],\n",
      "         [ 1.3742,  0.0646,  0.6919,  ...,  0.5222,  0.5191,  0.6669],\n",
      "         ...,\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.5731,  1.2781,  0.0000,  ...,  0.8990, -0.2433,  0.5490],\n",
      "         [ 0.7431,  0.0192,  1.0512,  ...,  1.7539,  0.0480,  1.6365],\n",
      "         [ 0.7626,  0.2134,  0.4146,  ...,  0.9910,  0.4200,  1.6285],\n",
      "         ...,\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.5268,  0.9170,  0.0000,  ...,  0.5184, -0.6256,  0.7978],\n",
      "         [ 1.5896,  1.2678,  0.7490,  ...,  0.7081, -0.0208,  0.8012],\n",
      "         [ 1.1066, -0.0000,  1.6085,  ...,  1.3321,  0.4595,  0.5766],\n",
      "         ...,\n",
      "         [ 1.0763,  0.6715,  0.0000,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0000,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.0000, -0.4602,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.3793,  0.6241, -0.3198,  ...,  1.6513,  0.2846,  1.0315],\n",
      "         [ 0.6409,  1.2736,  1.2004,  ...,  1.6316,  0.6514,  0.6881],\n",
      "         [ 1.0089, -0.8313,  1.5957,  ...,  0.0000, -0.4128,  1.5523],\n",
      "         ...,\n",
      "         [ 0.0000,  0.6715,  1.0508,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.3748,  0.5203, -0.0000,  ...,  1.5776, -0.3198,  0.8485],\n",
      "         [ 0.6744,  0.0000,  0.7988,  ...,  0.4836, -0.6008,  0.5347],\n",
      "         [ 0.8511, -0.1119,  1.1194,  ...,  1.7415,  0.0198,  0.0000],\n",
      "         ...,\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406]]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "loop within encoder. Iteration -- 1\n",
      "this is x in EncoderLayer-----> tensor([[[-1.8714e+00,  2.4629e+00, -2.9420e-01,  ..., -1.7496e+00,\n",
      "           2.4240e+00, -1.8258e-03],\n",
      "         [-1.7859e+00,  2.1182e+00, -4.0490e-01,  ..., -6.4488e-01,\n",
      "           2.9770e+00,  3.1390e-01],\n",
      "         [-1.2353e+00,  2.3624e+00,  5.8408e-01,  ..., -5.2998e-01,\n",
      "           3.7392e+00,  7.3354e-01],\n",
      "         ...,\n",
      "         [ 1.8916e+00,  3.2726e+00,  8.7419e-01,  ..., -1.8915e+00,\n",
      "           3.0639e+00, -5.2878e-01],\n",
      "         [-1.4541e+00,  3.9330e+00, -7.1348e-01,  ..., -1.6847e+00,\n",
      "           2.6949e+00, -1.0865e+00],\n",
      "         [-2.1342e+00,  3.2897e+00, -6.6573e-01,  ...,  7.3700e-01,\n",
      "           3.1483e+00, -5.6115e-01]],\n",
      "\n",
      "        [[-1.8698e+00,  2.4449e+00, -5.7292e-01,  ..., -1.0023e+00,\n",
      "           2.6006e+00, -1.2296e+00],\n",
      "         [-8.3212e-01,  3.5413e+00,  8.1311e-02,  ..., -1.1986e+00,\n",
      "           2.7896e+00, -1.2705e+00],\n",
      "         [-1.0616e+00,  1.1491e+00,  8.7250e-01,  ..., -1.6858e+00,\n",
      "           2.6981e+00, -7.3166e-01],\n",
      "         ...,\n",
      "         [-2.8865e-01,  6.7152e-01, -4.2767e-01,  ..., -5.1424e-01,\n",
      "           2.7458e+00, -1.7276e+00],\n",
      "         [-2.0685e+00,  3.5597e+00, -5.9344e-01,  ..., -9.7493e-01,\n",
      "           3.0584e+00, -1.3542e+00],\n",
      "         [-2.7225e+00,  3.0371e+00, -7.8192e-01,  ..., -1.2353e+00,\n",
      "           2.4422e+00, -9.6879e-01]],\n",
      "\n",
      "        [[-1.6505e+00,  3.7796e+00, -2.3037e-01,  ..., -2.0294e+00,\n",
      "           2.7281e+00, -4.1101e-01],\n",
      "         [-1.4930e+00,  2.7669e+00,  8.4826e-01,  ..., -1.0209e+00,\n",
      "           1.8039e+00, -3.9976e-01],\n",
      "         [-1.3260e+00,  3.5918e+00,  5.7132e-01,  ...,  6.5415e-01,\n",
      "           3.7371e+00,  3.4311e-01],\n",
      "         ...,\n",
      "         [-1.5031e-01,  4.6484e+00,  1.8470e+00,  ..., -2.1587e+00,\n",
      "           1.8947e+00, -1.3086e+00],\n",
      "         [-1.4210e+00,  4.4006e+00,  1.5292e-01,  ..., -1.5514e+00,\n",
      "           3.2408e+00, -1.1200e+00],\n",
      "         [-2.6071e+00,  3.3299e+00, -1.3449e+00,  ..., -2.1764e+00,\n",
      "           2.6244e+00, -9.5019e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.1959e+00,  1.8330e+00, -6.0832e-01,  ..., -9.8178e-01,\n",
      "           1.5637e+00,  1.5018e-01],\n",
      "         [-1.0968e+00,  4.0465e+00, -5.3663e-02,  ..., -2.3019e+00,\n",
      "           2.5112e+00,  2.7139e-01],\n",
      "         [-1.1031e+00,  1.3099e+00,  8.1443e-01,  ...,  9.8787e-01,\n",
      "           2.5249e+00, -5.8636e-01],\n",
      "         ...,\n",
      "         [-1.0553e+00,  3.9830e+00, -1.1703e-01,  ...,  2.5600e-01,\n",
      "           2.1156e+00, -1.5584e+00],\n",
      "         [ 4.4862e-01,  3.3309e+00, -4.2233e-01,  ..., -1.0564e+00,\n",
      "           2.4661e+00, -6.0108e-01],\n",
      "         [-2.6920e+00,  1.0757e+00, -1.4276e+00,  ..., -1.0027e+00,\n",
      "           2.7407e+00, -1.0326e+00]],\n",
      "\n",
      "        [[-2.0715e+00,  3.4743e+00, -1.0424e+00,  ..., -1.1186e+00,\n",
      "           2.6595e+00, -7.4953e-01],\n",
      "         [-2.0000e+00,  4.0670e+00, -5.2630e-02,  ..., -1.0689e+00,\n",
      "           3.2715e+00, -8.9826e-01],\n",
      "         [-1.5010e+00,  6.2348e-01,  6.4748e-01,  ..., -2.1865e+00,\n",
      "          -4.1282e-01,  8.5245e-01],\n",
      "         ...,\n",
      "         [-2.2748e+00,  2.2274e+00,  3.2956e-01,  ...,  1.6060e-01,\n",
      "           2.3084e+00, -1.1162e+00],\n",
      "         [-2.9324e-01,  3.5025e+00, -7.5413e-01,  ..., -1.1777e+00,\n",
      "           1.8550e+00, -1.5342e+00],\n",
      "         [-2.7651e+00,  3.0799e+00, -2.8216e-01,  ..., -1.3875e+00,\n",
      "           2.2293e+00, -7.2347e-01]],\n",
      "\n",
      "        [[-1.2445e+00,  2.1261e+00, -2.8818e-01,  ..., -1.6246e+00,\n",
      "           2.7519e+00, -3.2152e-01],\n",
      "         [-2.1909e-01,  8.4369e-01, -1.9610e-03,  ..., -2.5552e+00,\n",
      "           2.7772e+00, -5.8053e-01],\n",
      "         [-1.1576e+00,  1.3799e+00,  2.1402e-01,  ..., -8.3002e-03,\n",
      "           3.4459e+00, -3.7746e-01],\n",
      "         ...,\n",
      "         [-4.9874e-01,  1.8956e+00,  1.3470e+00,  ..., -2.1096e+00,\n",
      "           2.6929e+00, -6.7256e-01],\n",
      "         [-1.0888e+00,  1.9314e+00, -1.1767e+00,  ...,  1.0595e+00,\n",
      "           2.9643e+00, -7.9076e-01],\n",
      "         [-1.7808e+00,  3.0784e+00, -8.9830e-01,  ..., -9.1737e-01,\n",
      "           3.5100e+00, -1.1361e+00]]], grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "loop within encoder. Iteration -- 2\n",
      "this is x in EncoderLayer-----> tensor([[[-1.9128e+00,  3.4249e+00, -4.9381e-01,  ..., -2.8950e+00,\n",
      "           2.6129e+00, -2.0451e+00],\n",
      "         [-1.9401e+00,  3.8081e+00, -1.3111e+00,  ..., -2.9897e+00,\n",
      "           2.6053e+00, -1.5995e+00],\n",
      "         [-7.4005e-01,  3.7032e+00,  3.6602e-02,  ..., -2.4865e+00,\n",
      "           3.7740e+00, -1.5968e+00],\n",
      "         ...,\n",
      "         [ 2.6335e+00,  4.5992e+00,  9.5180e-02,  ..., -4.2463e+00,\n",
      "           3.1382e+00, -2.0494e+00],\n",
      "         [-1.2639e+00,  5.1001e+00, -1.1406e+00,  ..., -3.9405e+00,\n",
      "           2.4124e+00, -2.3362e+00],\n",
      "         [-1.5052e+00,  4.4487e+00, -9.6993e-01,  ..., -1.6425e+00,\n",
      "           2.8408e+00, -1.7271e+00]],\n",
      "\n",
      "        [[-2.0078e+00,  4.4976e+00, -1.2164e+00,  ..., -3.3201e+00,\n",
      "           2.0357e+00, -2.5921e+00],\n",
      "         [-3.3035e-01,  5.2279e+00,  4.2964e-02,  ..., -3.1054e+00,\n",
      "           2.8468e+00, -2.8202e+00],\n",
      "         [-7.1141e-01,  9.4093e-01,  1.0173e+00,  ..., -3.9037e+00,\n",
      "           2.0206e+00, -2.0904e+00],\n",
      "         ...,\n",
      "         [ 1.8276e-01,  2.0483e+00, -1.0160e+00,  ..., -2.5995e+00,\n",
      "           2.9477e+00, -2.1488e+00],\n",
      "         [-1.8980e+00,  4.5717e+00, -1.4901e+00,  ..., -3.2548e+00,\n",
      "           2.7629e+00, -2.4289e+00],\n",
      "         [-2.2290e+00,  4.0927e+00, -2.1312e+00,  ..., -2.8843e+00,\n",
      "           1.8291e+00, -2.2394e+00]],\n",
      "\n",
      "        [[-1.4237e+00,  6.0898e+00, -1.1018e+00,  ..., -3.4021e+00,\n",
      "           3.3279e+00, -1.7922e+00],\n",
      "         [-9.8534e-01,  4.8702e+00,  5.2397e-02,  ..., -2.6731e+00,\n",
      "           1.4332e+00, -2.3258e+00],\n",
      "         [-3.0103e-01,  5.1225e+00,  3.9274e-01,  ...,  3.0550e-01,\n",
      "           3.0710e+00, -8.9138e-01],\n",
      "         ...,\n",
      "         [ 2.3410e-02,  6.8604e+00,  8.6807e-01,  ..., -3.6606e+00,\n",
      "           2.7364e+00, -2.1476e+00],\n",
      "         [-1.0299e+00,  5.8758e+00, -8.9781e-01,  ..., -2.7412e+00,\n",
      "           3.1480e+00, -2.5303e+00],\n",
      "         [-2.5672e+00,  4.9967e+00, -2.8571e+00,  ..., -3.6128e+00,\n",
      "           2.8993e+00, -2.1103e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.3332e+00,  2.9766e+00, -1.2185e+00,  ..., -9.8695e-01,\n",
      "           1.1945e+00, -2.1076e+00],\n",
      "         [ 2.4989e-01,  4.9881e+00, -7.7439e-01,  ..., -3.9587e+00,\n",
      "           2.7430e+00, -2.0389e+00],\n",
      "         [-1.4111e-01,  2.5621e+00,  1.6877e-01,  ..., -1.2055e+00,\n",
      "           2.2152e+00, -2.7330e+00],\n",
      "         ...,\n",
      "         [-4.0797e-01,  5.1409e+00, -9.4233e-01,  ..., -1.5941e+00,\n",
      "           2.1156e+00, -2.8617e+00],\n",
      "         [ 1.5376e+00,  4.5961e+00, -1.6135e+00,  ..., -1.2119e+00,\n",
      "           2.4034e+00, -7.3898e-01],\n",
      "         [-1.7158e+00,  2.0799e+00, -1.9331e+00,  ..., -3.3956e+00,\n",
      "           2.8263e+00, -1.5957e+00]],\n",
      "\n",
      "        [[-1.2992e+00,  5.5452e+00, -1.8381e+00,  ..., -2.7717e+00,\n",
      "           2.4058e+00, -2.6101e+00],\n",
      "         [-1.5610e+00,  5.6131e+00, -8.2957e-01,  ..., -3.0598e+00,\n",
      "           3.1831e+00, -2.7960e+00],\n",
      "         [-1.1606e+00,  1.9350e+00,  7.8213e-02,  ..., -3.7584e+00,\n",
      "          -8.0501e-01,  8.9130e-02],\n",
      "         ...,\n",
      "         [-2.2077e+00,  3.6878e+00,  2.4533e-01,  ..., -1.2447e+00,\n",
      "           2.1333e+00, -2.2150e+00],\n",
      "         [ 3.3478e-02,  5.1574e+00, -2.0048e+00,  ..., -2.5831e+00,\n",
      "           1.5889e+00, -2.9132e+00],\n",
      "         [-2.2956e+00,  4.8642e+00, -7.0706e-01,  ..., -2.5045e+00,\n",
      "           2.8527e+00, -2.0048e+00]],\n",
      "\n",
      "        [[-8.0728e-01,  3.7317e+00, -3.7194e-03,  ..., -3.9531e+00,\n",
      "           2.2954e+00, -1.3461e+00],\n",
      "         [ 9.1112e-01,  2.1223e+00,  1.5299e-02,  ..., -4.4235e+00,\n",
      "           1.7599e+00, -1.3044e+00],\n",
      "         [-1.1022e-01,  3.1331e+00,  1.7416e-02,  ..., -3.1558e+00,\n",
      "           2.6299e+00, -2.3223e+00],\n",
      "         ...,\n",
      "         [ 7.3943e-02,  3.4538e+00,  6.6798e-01,  ..., -4.3163e+00,\n",
      "           1.4468e+00, -2.2712e+00],\n",
      "         [-3.5905e-01,  2.6118e+00, -2.2360e+00,  ..., -6.1770e-01,\n",
      "           1.7717e+00, -2.8285e+00],\n",
      "         [-1.1891e+00,  4.4665e+00, -9.2766e-01,  ..., -3.7827e+00,\n",
      "           2.5218e+00, -2.8414e+00]]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "loop within encoder. Iteration -- 3\n",
      "this is x in EncoderLayer-----> tensor([[[-1.3193e+00,  4.9188e+00,  3.1480e-01,  ..., -5.9032e+00,\n",
      "           1.8303e+00, -3.7092e+00],\n",
      "         [-1.0265e+00,  5.0405e+00, -7.7577e-01,  ..., -5.8742e+00,\n",
      "           2.7929e+00, -3.0687e+00],\n",
      "         [ 3.8471e-01,  5.5965e+00, -1.3990e-01,  ..., -4.6790e+00,\n",
      "           2.8035e+00, -3.5361e+00],\n",
      "         ...,\n",
      "         [ 3.5557e+00,  6.0842e+00, -1.8293e-03,  ..., -7.4530e+00,\n",
      "           1.8839e+00, -3.5025e+00],\n",
      "         [-7.0567e-01,  6.0751e+00, -1.4318e+00,  ..., -6.8296e+00,\n",
      "           1.5271e+00, -2.8095e+00],\n",
      "         [-1.5709e+00,  4.9421e+00, -8.0466e-01,  ..., -4.5618e+00,\n",
      "           1.0730e+00, -2.6790e+00]],\n",
      "\n",
      "        [[-1.3374e+00,  6.3974e+00, -1.3536e+00,  ..., -6.9152e+00,\n",
      "           7.3382e-01, -3.1576e+00],\n",
      "         [-1.4904e-01,  6.8775e+00, -4.3830e-01,  ..., -5.3547e+00,\n",
      "           2.1301e+00, -3.3768e+00],\n",
      "         [-2.9032e-02,  2.2937e+00,  5.0243e-01,  ..., -6.6340e+00,\n",
      "           1.1292e+00, -2.7084e+00],\n",
      "         ...,\n",
      "         [-1.2237e-02,  3.6402e+00, -1.5095e+00,  ..., -5.5250e+00,\n",
      "           1.6200e+00, -3.5780e+00],\n",
      "         [-1.4613e+00,  6.1745e+00, -1.9038e+00,  ..., -6.0606e+00,\n",
      "           1.5034e+00, -3.9667e+00],\n",
      "         [-1.3673e+00,  5.9714e+00, -2.6645e+00,  ..., -5.3563e+00,\n",
      "           6.8036e-01, -3.7201e+00]],\n",
      "\n",
      "        [[-8.6740e-01,  6.7772e+00, -1.0137e+00,  ..., -5.9781e+00,\n",
      "           1.8413e+00, -2.8640e+00],\n",
      "         [-3.4746e-01,  5.8603e+00,  3.1718e-01,  ..., -6.0179e+00,\n",
      "           4.9692e-02, -3.9412e+00],\n",
      "         [-2.1048e-01,  6.4102e+00,  1.1752e+00,  ..., -2.8176e+00,\n",
      "           1.5900e+00, -2.6242e+00],\n",
      "         ...,\n",
      "         [ 2.3410e-02,  8.1873e+00,  1.3304e+00,  ..., -7.3888e+00,\n",
      "           2.7935e+00, -2.7851e+00],\n",
      "         [-2.8740e-01,  7.3898e+00, -1.0217e+00,  ..., -6.2486e+00,\n",
      "           2.7962e+00, -3.1083e+00],\n",
      "         [-1.7732e+00,  6.2203e+00, -2.4275e+00,  ..., -7.2773e+00,\n",
      "           1.0789e+00, -2.8704e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-8.5880e-01,  4.5556e+00, -1.3587e+00,  ..., -4.2351e+00,\n",
      "          -3.4404e-01, -3.8527e+00],\n",
      "         [ 6.6047e-01,  6.6854e+00, -1.0731e+00,  ..., -7.1806e+00,\n",
      "           1.4918e+00, -3.7408e+00],\n",
      "         [ 4.4415e-01,  4.4107e+00,  2.6833e-01,  ..., -4.3627e+00,\n",
      "           1.2853e+00, -4.1350e+00],\n",
      "         ...,\n",
      "         [ 5.0657e-01,  6.3274e+00, -9.8295e-01,  ..., -4.5922e+00,\n",
      "           6.2964e-01, -2.8617e+00],\n",
      "         [ 1.9851e+00,  6.3983e+00, -2.0512e+00,  ..., -4.3177e+00,\n",
      "           8.5232e-01, -1.5803e+00],\n",
      "         [-1.0973e+00,  3.4765e+00, -1.9201e+00,  ..., -6.2283e+00,\n",
      "           1.3378e+00, -2.8195e+00]],\n",
      "\n",
      "        [[-5.3801e-01,  7.0219e+00, -2.3491e+00,  ..., -6.0802e+00,\n",
      "           1.0392e+00, -4.1994e+00],\n",
      "         [-9.5169e-01,  7.2401e+00, -1.3825e+00,  ..., -6.4101e+00,\n",
      "           1.7121e+00, -4.0006e+00],\n",
      "         [-7.2941e-01,  3.5260e+00, -9.0463e-01,  ..., -6.8464e+00,\n",
      "          -7.1623e-01, -1.5947e+00],\n",
      "         ...,\n",
      "         [-1.7661e+00,  4.8684e+00, -4.6738e-02,  ..., -4.6143e+00,\n",
      "           1.0038e+00, -3.6575e+00],\n",
      "         [ 1.2048e+00,  6.7700e+00, -2.5587e+00,  ..., -6.1435e+00,\n",
      "          -4.0282e-02, -4.1516e+00],\n",
      "         [-1.3425e+00,  7.0141e+00,  5.2264e-02,  ..., -4.8996e+00,\n",
      "           1.5378e+00, -3.1061e+00]],\n",
      "\n",
      "        [[-4.5699e-01,  4.8519e+00, -1.5088e-01,  ..., -6.6486e+00,\n",
      "           9.3477e-01, -2.2908e+00],\n",
      "         [ 1.0907e+00,  3.3850e+00,  7.0828e-02,  ..., -7.0705e+00,\n",
      "           5.2541e-01, -2.6787e+00],\n",
      "         [ 9.7298e-02,  4.2301e+00, -2.1759e-01,  ..., -6.0377e+00,\n",
      "           1.2302e+00, -2.9926e+00],\n",
      "         ...,\n",
      "         [ 5.3668e-01,  5.5129e+00,  5.6339e-01,  ..., -7.4976e+00,\n",
      "          -4.0771e-01, -2.7066e+00],\n",
      "         [ 8.9701e-02,  3.8010e+00, -2.4796e+00,  ..., -3.1247e+00,\n",
      "           4.2207e-01, -2.9899e+00],\n",
      "         [-1.0031e+00,  5.9796e+00, -1.5667e+00,  ..., -6.8506e+00,\n",
      "           7.1362e-01, -2.9963e+00]]], grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "loop within encoder. Iteration -- 4\n",
      "this is x in EncoderLayer-----> tensor([[[-1.6230e+00,  6.5523e+00, -1.8553e+00,  ..., -5.9943e+00,\n",
      "           1.1984e+00, -4.8591e+00],\n",
      "         [-2.4424e+00,  6.6555e+00, -3.1977e+00,  ..., -6.4319e+00,\n",
      "           2.2066e+00, -3.0687e+00],\n",
      "         [-6.7356e-01,  7.3017e+00, -2.3320e+00,  ..., -5.3773e+00,\n",
      "           3.6939e+00, -6.2450e+00],\n",
      "         ...,\n",
      "         [ 2.1488e+00,  7.9730e+00, -2.0869e+00,  ..., -7.7205e+00,\n",
      "           1.3462e+00, -6.5724e+00],\n",
      "         [-2.0553e+00,  8.4393e+00, -3.9325e+00,  ..., -6.5840e+00,\n",
      "           9.4464e-01, -5.5413e+00],\n",
      "         [-2.3345e+00,  6.6417e+00, -2.4312e+00,  ..., -4.8795e+00,\n",
      "          -5.3456e-02, -5.3451e+00]],\n",
      "\n",
      "        [[-2.0935e+00,  8.4942e+00, -3.0508e+00,  ..., -6.6976e+00,\n",
      "           7.3382e-01, -5.6539e+00],\n",
      "         [-1.0327e+00,  8.6936e+00, -2.5974e+00,  ..., -5.0593e+00,\n",
      "           1.1887e+00, -6.1035e+00],\n",
      "         [-1.1616e+00,  3.7286e+00, -1.0384e-01,  ..., -6.3824e+00,\n",
      "          -5.8596e-01, -5.5390e+00],\n",
      "         ...,\n",
      "         [-8.5723e-01,  5.6754e+00, -1.5511e+00,  ..., -5.8296e+00,\n",
      "           1.6259e+00, -5.3995e+00],\n",
      "         [-2.6091e+00,  7.9476e+00, -3.9030e+00,  ..., -6.4606e+00,\n",
      "           9.9905e-01, -5.7407e+00],\n",
      "         [-2.4350e+00,  8.1866e+00, -4.8633e+00,  ..., -5.4284e+00,\n",
      "          -5.2417e-01, -6.3300e+00]],\n",
      "\n",
      "        [[-7.7081e-01,  9.0525e+00, -3.0147e+00,  ..., -6.0424e+00,\n",
      "           2.2058e+00, -5.5594e+00],\n",
      "         [-1.0942e+00,  7.4939e+00, -1.0408e+00,  ..., -6.3888e+00,\n",
      "           6.8570e-02, -6.6794e+00],\n",
      "         [-5.5419e-01,  8.4712e+00, -2.5263e-01,  ..., -3.0342e+00,\n",
      "           1.7465e+00, -3.6202e+00],\n",
      "         ...,\n",
      "         [-3.7706e-01,  9.6424e+00, -7.0471e-01,  ..., -7.2513e+00,\n",
      "           2.5836e+00, -4.1505e+00],\n",
      "         [-1.0901e+00,  8.2677e+00, -2.8290e+00,  ..., -6.8671e+00,\n",
      "           2.6515e+00, -5.4962e+00],\n",
      "         [-2.3114e+00,  7.5771e+00, -4.4521e+00,  ..., -7.5548e+00,\n",
      "           7.7997e-01, -5.4882e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.4541e+00,  6.8271e+00, -3.7469e+00,  ..., -4.3676e+00,\n",
      "          -8.4887e-01, -6.6757e+00],\n",
      "         [-1.8464e-02,  8.9669e+00, -1.8420e+00,  ..., -7.5559e+00,\n",
      "           2.0717e+00, -3.7408e+00],\n",
      "         [-7.5370e-01,  6.4046e+00, -1.7392e+00,  ..., -4.8870e+00,\n",
      "          -2.3904e-01, -6.6151e+00],\n",
      "         ...,\n",
      "         [ 2.7651e-01,  8.6487e+00, -1.5858e+00,  ..., -5.3944e+00,\n",
      "          -5.2222e-01, -5.4198e+00],\n",
      "         [ 2.7583e+00,  8.6832e+00, -4.2635e+00,  ..., -4.4668e+00,\n",
      "           9.7832e-01, -3.5143e+00],\n",
      "         [-1.6155e+00,  6.2629e+00, -4.0112e+00,  ..., -6.6816e+00,\n",
      "           2.4645e-01, -5.4326e+00]],\n",
      "\n",
      "        [[-1.1157e+00,  9.2884e+00, -4.6231e+00,  ..., -6.4197e+00,\n",
      "          -2.7473e-01, -7.2677e+00],\n",
      "         [-1.4973e-01,  8.7366e+00, -3.5128e+00,  ..., -6.8398e+00,\n",
      "           1.2581e-01, -6.6834e+00],\n",
      "         [ 3.1244e-02,  5.5261e+00, -3.1870e+00,  ..., -6.5993e+00,\n",
      "          -1.3610e+00, -3.0447e+00],\n",
      "         ...,\n",
      "         [-1.2513e+00,  6.4941e+00, -2.8404e+00,  ..., -5.4731e+00,\n",
      "           5.1269e-01, -6.8868e+00],\n",
      "         [ 9.0150e-01,  9.0735e+00, -5.0867e+00,  ..., -6.5741e+00,\n",
      "          -1.2774e+00, -7.1150e+00],\n",
      "         [-1.9013e+00,  8.9442e+00, -2.4106e+00,  ..., -4.6961e+00,\n",
      "          -3.9908e-01, -5.0172e+00]],\n",
      "\n",
      "        [[-1.1151e+00,  7.2090e+00, -2.2764e+00,  ..., -6.6718e+00,\n",
      "           9.9278e-01, -4.3625e+00],\n",
      "         [-2.4109e-01,  5.3107e+00, -1.6164e+00,  ..., -7.9604e+00,\n",
      "           7.6808e-03, -5.5355e+00],\n",
      "         [-6.4699e-01,  5.1083e+00, -1.6877e+00,  ..., -6.4826e+00,\n",
      "           1.0574e+00, -5.2037e+00],\n",
      "         ...,\n",
      "         [ 4.0008e-02,  7.7167e+00, -1.0243e+00,  ..., -7.4381e+00,\n",
      "          -1.1963e+00, -4.9245e+00],\n",
      "         [-6.6578e-01,  5.8694e+00, -4.6421e+00,  ..., -3.5346e+00,\n",
      "          -2.4461e-03, -5.2977e+00],\n",
      "         [-1.4816e+00,  8.3396e+00, -3.9042e+00,  ..., -7.0319e+00,\n",
      "           8.6979e-01, -5.0610e+00]]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "loop within encoder. Iteration -- 5\n",
      "this is x in EncoderLayer-----> tensor([[[ -1.3903,   5.6126,  -0.3704,  ...,  -7.8654,   1.0943,  -3.3908],\n",
      "         [ -1.6647,   5.7798,  -2.0917,  ...,  -8.0098,   2.8262,  -1.3325],\n",
      "         [ -0.0587,   6.3204,  -0.9151,  ...,  -7.6041,   4.4730,  -5.1742],\n",
      "         ...,\n",
      "         [  3.4992,   7.2594,  -0.5016,  ...,  -9.6756,   1.1729,  -5.7119],\n",
      "         [ -1.1531,   7.8293,  -2.5328,  ...,  -8.8767,   1.1402,  -4.5389],\n",
      "         [ -1.2629,   5.5799,  -0.3538,  ...,  -6.8994,   0.3492,  -4.5422]],\n",
      "\n",
      "        [[ -1.6970,   7.7797,  -1.8598,  ...,  -8.1274,   0.8591,  -4.7080],\n",
      "         [ -0.5731,   8.3185,  -0.6785,  ...,  -7.2480,   1.3575,  -4.3442],\n",
      "         [  0.2278,   3.9958,  -0.1327,  ...,  -8.3495,  -0.8866,  -4.1920],\n",
      "         ...,\n",
      "         [ -0.5393,   4.8732,   0.3020,  ...,  -8.1222,   1.5038,  -3.8178],\n",
      "         [ -1.3952,   7.8116,  -2.7400,  ...,  -8.5128,   0.9836,  -4.3890],\n",
      "         [ -1.6355,   7.7918,  -3.2780,  ...,  -6.9569,  -0.7873,  -4.9217]],\n",
      "\n",
      "        [[  0.1520,   8.1055,  -1.5358,  ...,  -8.1083,   2.6011,  -4.0269],\n",
      "         [ -0.8777,   6.3366,   0.1269,  ...,  -8.5027,  -0.5171,  -5.0079],\n",
      "         [  0.6860,   7.5180,   1.5190,  ...,  -5.2402,   1.5778,  -2.0763],\n",
      "         ...,\n",
      "         [  0.4390,   8.4261,  -0.9302,  ...,  -9.1491,   3.1022,  -4.1505],\n",
      "         [ -0.8499,   7.6598,  -1.7085,  ...,  -8.7941,   2.8801,  -4.2845],\n",
      "         [ -1.2008,   6.6883,  -2.8601,  ...,  -9.5237,   1.1757,  -4.1219]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -0.8287,   6.0298,  -2.5029,  ...,  -6.5984,  -1.0851,  -6.2594],\n",
      "         [  1.2538,   8.8122,  -0.6761,  ...,  -9.7341,   1.5533,  -2.4492],\n",
      "         [  0.3040,   5.6759,  -0.2526,  ...,  -6.7309,  -0.0602,  -5.0785],\n",
      "         ...,\n",
      "         [  1.3101,   8.3059,  -0.2827,  ...,  -7.3791,  -0.9703,  -4.6398],\n",
      "         [  3.8147,   7.7611,  -2.7350,  ...,  -6.9782,   0.9606,  -2.0810],\n",
      "         [ -0.5297,   6.6030,  -2.4142,  ...,  -8.5740,   0.1536,  -4.3248]],\n",
      "\n",
      "        [[ -0.2309,   8.5675,  -3.1596,  ...,  -9.2143,  -0.6198,  -6.3147],\n",
      "         [  0.1292,   7.7668,  -2.4012,  ...,  -8.9803,   0.0912,  -5.2516],\n",
      "         [  1.3269,   4.8005,  -1.2477,  ...,  -9.4081,  -2.1538,  -1.4534],\n",
      "         ...,\n",
      "         [ -0.5925,   6.5911,  -1.3814,  ...,  -7.0363,   0.1450,  -5.5545],\n",
      "         [  2.1540,   8.1572,  -4.3808,  ...,  -8.8978,  -2.0502,  -6.6854],\n",
      "         [ -1.5610,   8.1303,  -0.6825,  ...,  -6.5284,  -0.2638,  -3.7098]],\n",
      "\n",
      "        [[ -0.0851,   6.6504,  -0.6200,  ...,  -8.9004,   0.7754,  -3.3296],\n",
      "         [  0.7769,   4.1088,  -0.2661,  ..., -10.1297,  -0.0420,  -3.9978],\n",
      "         [  0.2505,   4.2885,  -0.6173,  ...,  -8.5678,   1.3566,  -3.1597],\n",
      "         ...,\n",
      "         [  0.6136,   6.1824,   0.7285,  ...,  -9.3606,  -1.5615,  -3.2103],\n",
      "         [  0.3057,   5.5079,  -2.9456,  ...,  -5.3990,  -0.0241,  -4.7093],\n",
      "         [ -0.7961,   7.5739,  -2.1171,  ...,  -9.2945,   0.9667,  -4.1437]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 80, 64]) , torch.Size([512, 8, 80, 64]), torch.Size([512, 8, 80, 64])\n",
      "Score shape -- torch.Size([512, 8, 80, 80])\n",
      "Mask ---> torch.Size([512, 80, 80])\n",
      "Mask new --> torch.Size([512, 1, 80, 80])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 80, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 80, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 80, 64]) , torch.Size([512, 8, 80, 64]), torch.Size([512, 8, 80, 64])\n",
      "Score shape -- torch.Size([512, 8, 80, 80])\n",
      "Mask ---> torch.Size([512, 80, 80])\n",
      "Mask new --> torch.Size([512, 1, 80, 80])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 80, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 80, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 80, 64]) , torch.Size([512, 8, 80, 64]), torch.Size([512, 8, 80, 64])\n",
      "Score shape -- torch.Size([512, 8, 80, 80])\n",
      "Mask ---> torch.Size([512, 80, 80])\n",
      "Mask new --> torch.Size([512, 1, 80, 80])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 80, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 80, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 80, 64]) , torch.Size([512, 8, 80, 64]), torch.Size([512, 8, 80, 64])\n",
      "Score shape -- torch.Size([512, 8, 80, 80])\n",
      "Mask ---> torch.Size([512, 80, 80])\n",
      "Mask new --> torch.Size([512, 1, 80, 80])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 80, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 80, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 80, 64]) , torch.Size([512, 8, 80, 64]), torch.Size([512, 8, 80, 64])\n",
      "Score shape -- torch.Size([512, 8, 80, 80])\n",
      "Mask ---> torch.Size([512, 80, 80])\n",
      "Mask new --> torch.Size([512, 1, 80, 80])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 80, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 80, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 80, 64]) , torch.Size([512, 8, 80, 64]), torch.Size([512, 8, 80, 64])\n",
      "Score shape -- torch.Size([512, 8, 80, 80])\n",
      "Mask ---> torch.Size([512, 80, 80])\n",
      "Mask new --> torch.Size([512, 1, 80, 80])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 80, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 80, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "predictions size : tensor([[-0.2387, -0.5595, -0.0360,  ..., -0.3576, -0.4159,  0.0286],\n",
      "        [-0.5469, -0.6338, -0.1009,  ..., -0.3402, -0.4692,  0.0082],\n",
      "        [-0.4235, -0.5461, -0.1271,  ..., -0.3941, -0.4684,  0.0074],\n",
      "        ...,\n",
      "        [-0.5802, -0.5359,  0.0027,  ..., -0.3219, -0.4670, -0.0188],\n",
      "        [-0.4773, -0.4921, -0.0830,  ..., -0.2269, -0.3955, -0.0700],\n",
      "        [-0.5102, -0.5237, -0.0113,  ..., -0.2813, -0.4264, -0.0106]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "targets size : torch.Size([40960])\n",
      "Loss.data ----> = 8.264494895935059\n",
      "--Encoder x after PE : tensor([[[-0.0219,  1.6916, -0.0331,  ...,  0.7535, -0.1327,  0.7991],\n",
      "         [ 1.4446,  0.9856,  1.3997,  ...,  0.5448,  0.3846,  0.0000],\n",
      "         [ 0.4643, -0.0000,  0.9887,  ...,  1.6739,  0.4963,  1.2293],\n",
      "         ...,\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.0000],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.6515, -0.9060, -0.0868,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.2558,  0.7744,  0.3624,  ...,  1.0584, -0.6393,  0.5873],\n",
      "         [ 0.5742,  0.2648,  0.2865,  ...,  1.5393,  0.3913,  1.2682],\n",
      "         [ 1.3732, -0.7153,  1.2419,  ...,  0.5914, -0.5824,  1.2131],\n",
      "         ...,\n",
      "         [ 0.0660,  0.8434,  0.0000,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.0000,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.6515, -0.9060, -0.0000,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.4877,  0.8208, -0.5825,  ...,  0.5891, -0.0277,  1.5289],\n",
      "         [ 1.3195,  0.0000,  1.4823,  ...,  1.0432, -0.1483,  0.5568],\n",
      "         [ 0.4643, -0.5611,  0.9887,  ...,  0.0000,  0.4963,  1.2293],\n",
      "         ...,\n",
      "         [ 0.0660,  0.0000,  0.0581,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.0000, -0.4602,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.0000, -0.9060, -0.0868,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.3739,  0.0000, -0.4531,  ...,  1.5774, -0.3190,  0.8475],\n",
      "         [ 0.0000,  0.2317,  0.7981,  ...,  0.4836, -0.6008,  0.5338],\n",
      "         [ 1.5291,  0.1187,  0.5518,  ...,  1.2900,  0.6005,  0.6651],\n",
      "         ...,\n",
      "         [ 0.0000,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.0000,  0.1060, -0.4602,  ...,  0.0000,  0.1775,  0.5406],\n",
      "         [-0.6515, -0.9060, -0.0868,  ...,  1.0595,  0.1775,  0.0000]],\n",
      "\n",
      "        [[-0.6117,  1.0925, -0.1832,  ...,  0.7597, -0.1009,  1.1715],\n",
      "         [ 0.2629,  1.0131,  1.0235,  ...,  1.2211, -0.4316,  0.7563],\n",
      "         [ 1.6487,  0.2040,  1.0737,  ...,  1.3605,  0.5733,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0660,  0.0000,  0.0581,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.6515, -0.9060, -0.0868,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.5624,  1.7564,  0.0929,  ...,  0.0000,  0.4875,  1.2055],\n",
      "         [ 0.9613,  0.5468,  0.8494,  ...,  1.3870, -0.4968,  1.0175],\n",
      "         [ 0.8289, -1.0012,  0.7005,  ...,  1.2172,  0.1693,  1.1513],\n",
      "         ...,\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  0.0000,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.0000, -0.0000,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.6515, -0.9060, -0.0868,  ...,  1.0595,  0.1775,  0.5406]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "loop within encoder. Iteration -- 0\n",
      "this is x in EncoderLayer-----> tensor([[[-0.0219,  1.6916, -0.0331,  ...,  0.7535, -0.1327,  0.7991],\n",
      "         [ 1.4446,  0.9856,  1.3997,  ...,  0.5448,  0.3846,  0.0000],\n",
      "         [ 0.4643, -0.0000,  0.9887,  ...,  1.6739,  0.4963,  1.2293],\n",
      "         ...,\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.0000],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.6515, -0.9060, -0.0868,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.2558,  0.7744,  0.3624,  ...,  1.0584, -0.6393,  0.5873],\n",
      "         [ 0.5742,  0.2648,  0.2865,  ...,  1.5393,  0.3913,  1.2682],\n",
      "         [ 1.3732, -0.7153,  1.2419,  ...,  0.5914, -0.5824,  1.2131],\n",
      "         ...,\n",
      "         [ 0.0660,  0.8434,  0.0000,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.0000,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.6515, -0.9060, -0.0000,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.4877,  0.8208, -0.5825,  ...,  0.5891, -0.0277,  1.5289],\n",
      "         [ 1.3195,  0.0000,  1.4823,  ...,  1.0432, -0.1483,  0.5568],\n",
      "         [ 0.4643, -0.5611,  0.9887,  ...,  0.0000,  0.4963,  1.2293],\n",
      "         ...,\n",
      "         [ 0.0660,  0.0000,  0.0581,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.0000, -0.4602,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.0000, -0.9060, -0.0868,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.3739,  0.0000, -0.4531,  ...,  1.5774, -0.3190,  0.8475],\n",
      "         [ 0.0000,  0.2317,  0.7981,  ...,  0.4836, -0.6008,  0.5338],\n",
      "         [ 1.5291,  0.1187,  0.5518,  ...,  1.2900,  0.6005,  0.6651],\n",
      "         ...,\n",
      "         [ 0.0000,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.0000,  0.1060, -0.4602,  ...,  0.0000,  0.1775,  0.5406],\n",
      "         [-0.6515, -0.9060, -0.0868,  ...,  1.0595,  0.1775,  0.0000]],\n",
      "\n",
      "        [[-0.6117,  1.0925, -0.1832,  ...,  0.7597, -0.1009,  1.1715],\n",
      "         [ 0.2629,  1.0131,  1.0235,  ...,  1.2211, -0.4316,  0.7563],\n",
      "         [ 1.6487,  0.2040,  1.0737,  ...,  1.3605,  0.5733,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0660,  0.0000,  0.0581,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.6515, -0.9060, -0.0868,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.5624,  1.7564,  0.0929,  ...,  0.0000,  0.4875,  1.2055],\n",
      "         [ 0.9613,  0.5468,  0.8494,  ...,  1.3870, -0.4968,  1.0175],\n",
      "         [ 0.8289, -1.0012,  0.7005,  ...,  1.2172,  0.1693,  1.1513],\n",
      "         ...,\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  0.0000,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.0000, -0.0000,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.6515, -0.9060, -0.0868,  ...,  1.0595,  0.1775,  0.5406]]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 88, 64]) , torch.Size([512, 8, 88, 64]), torch.Size([512, 8, 88, 64])\n",
      "Score shape -- torch.Size([512, 8, 88, 88])\n",
      "Mask ---> torch.Size([512, 1, 88])\n",
      "Mask new --> torch.Size([512, 1, 1, 88])\n",
      "loop within encoder. Iteration -- 1\n",
      "this is x in EncoderLayer-----> tensor([[[-1.9452e+00,  5.2834e+00, -6.5812e-01,  ..., -1.3562e+00,\n",
      "           2.4810e+00, -3.3064e-01],\n",
      "         [-8.3755e-01,  4.2378e+00,  9.3318e-01,  ...,  1.6966e-01,\n",
      "           2.7990e+00, -1.2550e+00],\n",
      "         [-1.0501e+00,  2.8490e+00,  1.4614e+00,  ..., -1.9033e-01,\n",
      "           2.0257e+00, -5.1548e-02],\n",
      "         ...,\n",
      "         [-1.8453e+00,  3.3252e+00, -1.1286e+00,  ...,  1.7830e-01,\n",
      "           2.8037e+00, -1.3425e+00],\n",
      "         [-3.1085e+00,  2.3967e+00, -8.9296e-01,  ..., -1.1040e+00,\n",
      "           1.8486e+00, -5.1663e-01],\n",
      "         [-2.8494e+00,  1.2356e+00, -1.1534e+00,  ...,  1.0595e+00,\n",
      "           2.1760e+00, -6.9222e-01]],\n",
      "\n",
      "        [[-2.1932e+00,  2.8168e+00,  1.1945e-01,  ..., -1.6359e+00,\n",
      "           2.1782e+00, -1.2412e+00],\n",
      "         [-9.7666e-01,  2.6524e+00,  9.2080e-01,  ..., -1.2497e+00,\n",
      "           3.6250e+00, -4.8057e-02],\n",
      "         [-1.1956e+00,  1.8947e+00,  9.2858e-01,  ..., -1.6267e+00,\n",
      "           1.1110e+00,  6.6120e-01],\n",
      "         ...,\n",
      "         [-1.7222e+00,  4.3567e+00, -1.7388e-01,  ..., -1.8823e+00,\n",
      "           2.9274e+00, -7.5495e-01],\n",
      "         [-1.2989e+00,  1.4612e+00, -8.0464e-01,  ..., -2.3169e+00,\n",
      "           2.4531e+00, -1.0452e+00],\n",
      "         [-1.8832e+00,  2.0286e+00, -2.2461e-02,  ..., -1.5987e+00,\n",
      "           2.8803e+00, -8.4579e-01]],\n",
      "\n",
      "        [[-1.6711e+00,  4.1241e+00, -8.7517e-01,  ..., -1.0898e+00,\n",
      "           2.8235e+00,  4.2127e-01],\n",
      "         [-1.9382e+00,  1.9980e+00,  9.7246e-01,  ..., -7.1077e-01,\n",
      "           2.7268e+00, -6.2440e-01],\n",
      "         [-1.4977e+00,  2.2646e+00,  4.6415e-01,  ..., -1.9369e+00,\n",
      "           3.7958e+00,  4.9253e-01],\n",
      "         ...,\n",
      "         [ 4.1520e-01,  2.8030e+00, -4.4879e-01,  ..., -7.3350e-01,\n",
      "           2.9375e+00, -1.3065e+00],\n",
      "         [-2.0970e+00,  3.2747e+00, -5.7533e-01,  ...,  3.5880e-01,\n",
      "           3.1220e+00, -6.5394e-01],\n",
      "         [-1.7947e+00,  2.5330e+00, -6.4046e-01,  ..., -1.5217e+00,\n",
      "           2.6323e+00, -1.0494e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.2554e+00,  3.0018e+00, -1.0382e+00,  ...,  8.6720e-01,\n",
      "           1.7187e+00, -8.9529e-01],\n",
      "         [-1.8637e+00,  3.0267e+00,  2.1254e-01,  ..., -1.3155e+00,\n",
      "           1.0832e+00, -1.2312e+00],\n",
      "         [-1.6409e-01,  2.4114e+00, -4.9314e-01,  ..., -1.5673e+00,\n",
      "           3.4909e+00, -9.8597e-01],\n",
      "         ...,\n",
      "         [-1.9244e+00,  2.8327e+00, -8.7467e-01,  ...,  5.8490e-01,\n",
      "           2.8696e+00, -1.2742e+00],\n",
      "         [-1.8524e+00,  2.7801e+00, -5.7179e-01,  ..., -2.2376e+00,\n",
      "           3.3258e+00, -1.0378e+00],\n",
      "         [-2.5207e+00,  7.1407e-01,  4.8029e-02,  ..., -1.9527e+00,\n",
      "           2.6422e+00, -6.4712e-01]],\n",
      "\n",
      "        [[-8.7588e-01,  3.0990e+00, -1.5288e+00,  ..., -8.1693e-02,\n",
      "           2.5292e+00, -6.4291e-01],\n",
      "         [-2.1456e+00,  3.6006e+00,  6.7009e-01,  ..., -9.1899e-01,\n",
      "           2.9935e+00, -1.1652e+00],\n",
      "         [ 1.2617e+00,  3.0133e+00,  2.5523e-01,  ..., -9.6739e-01,\n",
      "           3.7179e+00, -1.8902e+00],\n",
      "         ...,\n",
      "         [-1.4913e+00,  2.2341e+00, -7.6230e-01,  ..., -7.9378e-01,\n",
      "           2.4170e+00, -1.6613e+00],\n",
      "         [-2.4785e+00,  2.7201e+00, -1.5629e+00,  ..., -7.8409e-01,\n",
      "           2.7265e+00, -1.5994e+00],\n",
      "         [-2.2170e+00,  2.0946e+00, -8.7750e-01,  ..., -1.1895e+00,\n",
      "           6.4976e-01,  5.4056e-01]],\n",
      "\n",
      "        [[-3.6020e+00,  5.2355e+00, -2.6760e-01,  ..., -2.0901e+00,\n",
      "           2.4082e+00,  6.6866e-02],\n",
      "         [-1.5112e+00,  4.4013e+00,  1.1593e-01,  ..., -1.4335e+00,\n",
      "           2.3398e+00, -1.0949e-01],\n",
      "         [-1.5420e+00,  1.0147e+00, -5.6917e-01,  ...,  2.2089e-01,\n",
      "           3.4291e+00,  3.3842e-01],\n",
      "         ...,\n",
      "         [-1.7384e+00,  2.4904e+00, -8.9928e-01,  ..., -2.5342e-01,\n",
      "           2.9527e+00,  2.3868e-01],\n",
      "         [-3.1069e+00,  3.2528e+00, -1.2859e-01,  ..., -1.2512e+00,\n",
      "           2.7553e+00, -1.3562e+00],\n",
      "         [-5.8337e-01,  2.4078e+00, -1.1866e+00,  ..., -4.0547e-03,\n",
      "           2.5736e+00, -1.3049e+00]]], grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 88, 64]) , torch.Size([512, 8, 88, 64]), torch.Size([512, 8, 88, 64])\n",
      "Score shape -- torch.Size([512, 8, 88, 88])\n",
      "Mask ---> torch.Size([512, 1, 88])\n",
      "Mask new --> torch.Size([512, 1, 1, 88])\n",
      "loop within encoder. Iteration -- 2\n",
      "this is x in EncoderLayer-----> tensor([[[-1.5078,  5.1134, -1.1180,  ..., -3.7973,  2.3064, -2.2290],\n",
      "         [-0.2295,  5.7990,  0.2203,  ..., -2.3763,  2.3466, -3.1023],\n",
      "         [-0.3549,  4.5680,  0.8474,  ..., -2.5567,  1.9137, -1.6821],\n",
      "         ...,\n",
      "         [-1.2886,  5.7463, -1.3498,  ..., -1.9693,  1.7814, -2.3670],\n",
      "         [-1.8935,  4.4941, -2.1980,  ..., -3.1458,  1.9888, -2.1999],\n",
      "         [-2.2950,  3.6774, -2.3245,  ..., -1.4529,  1.7830, -2.1707]],\n",
      "\n",
      "        [[-1.5972,  3.1302, -0.2369,  ..., -3.4504,  1.9914, -2.4778],\n",
      "         [-0.3960,  2.6524,  0.6322,  ..., -2.2950,  3.3300, -0.9220],\n",
      "         [-0.8349,  3.1843,  1.2049,  ..., -3.2370,  0.9249, -0.0338],\n",
      "         ...,\n",
      "         [-1.3783,  5.7889, -1.2113,  ..., -2.8069,  2.8647, -2.0948],\n",
      "         [-1.3696,  2.8155, -1.5012,  ..., -3.2871,  2.2159, -2.4728],\n",
      "         [-1.4970,  3.3423, -0.9123,  ..., -2.7900,  2.5731, -1.6982]],\n",
      "\n",
      "        [[-1.5655,  5.8267, -1.2013,  ..., -2.9739,  2.4665, -0.3173],\n",
      "         [-1.2340,  3.4651,  0.8058,  ..., -3.3047,  2.1502, -1.5172],\n",
      "         [-0.6406,  2.2180, -0.3621,  ..., -4.0983,  3.6426, -0.6799],\n",
      "         ...,\n",
      "         [ 0.9252,  4.8075, -1.1819,  ..., -3.0136,  2.0066, -2.3727],\n",
      "         [-1.4382,  3.2747, -1.3451,  ..., -2.1102,  2.6972, -2.2202],\n",
      "         [-1.3831,  3.8304, -1.5116,  ..., -3.3891,  2.9165, -2.2195]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.0196,  4.8005, -1.3843,  ..., -1.0510,  1.0024, -1.8903],\n",
      "         [-0.8732,  4.5933,  0.1920,  ..., -3.8235,  0.5863, -2.1028],\n",
      "         [-0.1251,  4.3058, -0.3774,  ..., -4.4155,  3.1758, -2.0348],\n",
      "         ...,\n",
      "         [-1.7195,  4.8841, -1.5096,  ..., -1.3250,  2.1582, -2.0726],\n",
      "         [-1.6001,  4.9464, -1.2213,  ..., -2.8011,  3.0186, -1.6847],\n",
      "         [-2.2735,  3.0332,  0.0480,  ..., -3.9721,  2.0598, -1.8983]],\n",
      "\n",
      "        [[-1.0387,  5.0089, -1.6254,  ..., -1.4839,  2.6379, -2.1715],\n",
      "         [-2.1610,  5.6900,  0.8253,  ..., -2.6729,  2.6411, -2.5027],\n",
      "         [ 1.3011,  2.5192, -0.3913,  ..., -2.6941,  3.3397, -2.6143],\n",
      "         ...,\n",
      "         [-1.6646,  3.9825, -1.7862,  ..., -0.9544,  2.2910, -2.3456],\n",
      "         [-2.6822,  5.0237, -1.4661,  ..., -2.8611,  1.9988, -2.4181],\n",
      "         [-1.9255,  4.5877, -2.4836,  ..., -2.6711,  0.0731, -0.8618]],\n",
      "\n",
      "        [[-3.1645,  6.6922, -1.0480,  ..., -4.1305,  2.0239, -1.3364],\n",
      "         [-1.2137,  6.0699, -0.3198,  ..., -3.7347,  1.8767, -0.4378],\n",
      "         [-0.6244,  2.5131, -0.5401,  ..., -2.3300,  3.1892, -1.5791],\n",
      "         ...,\n",
      "         [-1.4727,  2.3735, -0.8993,  ..., -2.6654,  3.1340, -1.2320],\n",
      "         [-2.6402,  3.3113, -1.0600,  ..., -3.3070,  2.9452, -2.4442],\n",
      "         [-0.6059,  4.3506, -1.9728,  ..., -2.0582,  2.2843, -2.7767]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 88, 64]) , torch.Size([512, 8, 88, 64]), torch.Size([512, 8, 88, 64])\n",
      "Score shape -- torch.Size([512, 8, 88, 88])\n",
      "Mask ---> torch.Size([512, 1, 88])\n",
      "Mask new --> torch.Size([512, 1, 1, 88])\n",
      "loop within encoder. Iteration -- 3\n",
      "this is x in EncoderLayer-----> tensor([[[-0.9467,  6.2427, -1.5614,  ..., -7.4513,  1.0470, -3.7034],\n",
      "         [ 0.4190,  6.1359, -0.4170,  ..., -4.9741,  0.9957, -4.3032],\n",
      "         [-0.1330,  6.6085, -0.0550,  ..., -5.3422,  0.0366, -3.0418],\n",
      "         ...,\n",
      "         [-0.7063,  7.4686, -1.4992,  ..., -5.3518,  0.7366, -3.3089],\n",
      "         [-1.3139,  6.2344, -2.2965,  ..., -6.0937,  0.3900, -3.1299],\n",
      "         [-1.9868,  5.3325, -2.8931,  ..., -4.5914, -0.0974, -3.5155]],\n",
      "\n",
      "        [[-0.8935,  5.7013, -0.1958,  ..., -6.0876,  2.4764, -4.0581],\n",
      "         [ 0.1368,  3.6958,  0.6631,  ..., -4.6486,  1.2574, -2.8452],\n",
      "         [ 0.0476,  4.8969,  1.0268,  ..., -4.2021, -0.5584, -1.8253],\n",
      "         ...,\n",
      "         [-0.3735,  7.0611, -0.5380,  ..., -4.8393,  1.2353, -3.3246],\n",
      "         [-0.8772,  3.0829, -1.2008,  ..., -6.3729,  0.3934, -3.9853],\n",
      "         [-0.6494,  5.3703, -0.8369,  ..., -5.8098,  0.0571, -3.0669]],\n",
      "\n",
      "        [[-0.5804,  7.3176, -1.8437,  ..., -5.1083,  0.8261, -1.6015],\n",
      "         [-1.2340,  3.9141,  1.1477,  ..., -6.5199,  2.6047, -3.2592],\n",
      "         [ 0.4589,  3.3500, -0.6225,  ..., -6.9488,  1.7558, -2.5883],\n",
      "         ...,\n",
      "         [ 1.9178,  6.6413, -1.8752,  ..., -3.0136, -0.1503, -3.3524],\n",
      "         [-0.0513,  5.0097, -1.4904,  ..., -5.0945,  1.2666, -3.6239],\n",
      "         [-0.6240,  5.4345, -1.3988,  ..., -5.4831,  1.1555, -3.1569]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.2405,  5.9125, -1.7913,  ..., -1.7010, -0.1698, -3.5871],\n",
      "         [-0.1874,  5.6704,  0.1668,  ..., -6.9042, -0.5664, -3.8539],\n",
      "         [ 0.2094,  5.9753, -0.6034,  ..., -7.2081,  1.9420, -3.7801],\n",
      "         ...,\n",
      "         [-0.5816,  6.6050, -1.6237,  ..., -4.3471,  2.2596, -3.5981],\n",
      "         [-0.8876,  6.7917, -1.3210,  ..., -5.8558,  1.8281, -2.9729],\n",
      "         [-1.6460,  4.0762,  0.1342,  ..., -7.1699,  0.3329, -3.4325]],\n",
      "\n",
      "        [[-0.6199,  6.7066, -2.1197,  ..., -4.1118,  1.0651, -3.9945],\n",
      "         [-1.4867,  7.0388,  1.0532,  ..., -5.7995,  0.6240, -4.9455],\n",
      "         [ 1.7173,  3.7636, -0.2000,  ..., -2.8829,  3.3806, -4.3681],\n",
      "         ...,\n",
      "         [-1.3643,  5.4628, -2.0798,  ..., -4.2388,  0.4501, -3.4363],\n",
      "         [-1.7809,  6.4724, -1.2509,  ..., -4.9074,  0.3852, -3.5250],\n",
      "         [-0.4217,  6.3583, -2.6515,  ..., -6.1094, -1.4256, -2.4500]],\n",
      "\n",
      "        [[-2.5550,  7.4738, -1.5034,  ..., -7.0194,  2.3164, -3.0558],\n",
      "         [-0.2977,  7.6604, -0.1633,  ..., -3.7347,  0.3808, -2.1758],\n",
      "         [-0.1428,  4.3335, -0.1439,  ..., -3.2668,  1.9578, -2.7490],\n",
      "         ...,\n",
      "         [-0.5779,  4.1385, -0.3568,  ..., -5.8374,  1.8646, -2.4892],\n",
      "         [-1.8848,  5.1808, -0.6687,  ..., -3.9720,  1.3937, -3.7549],\n",
      "         [ 0.4682,  6.5040, -1.6785,  ..., -5.7220,  1.1228, -3.7960]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 88, 64]) , torch.Size([512, 8, 88, 64]), torch.Size([512, 8, 88, 64])\n",
      "Score shape -- torch.Size([512, 8, 88, 88])\n",
      "Mask ---> torch.Size([512, 1, 88])\n",
      "Mask new --> torch.Size([512, 1, 1, 88])\n",
      "loop within encoder. Iteration -- 4\n",
      "this is x in EncoderLayer-----> tensor([[[-1.8776,  8.6270, -3.4407,  ..., -7.8015, -0.3668, -5.6261],\n",
      "         [ 0.2214,  8.3490, -1.7243,  ..., -4.8817,  1.2672, -7.3220],\n",
      "         [-0.6025,  8.7304, -2.1545,  ..., -5.8917, -1.3418, -5.9684],\n",
      "         ...,\n",
      "         [-1.4944,  9.7496, -3.8171,  ..., -6.2474,  0.0135, -6.8935],\n",
      "         [-2.5098,  9.0932, -4.6295,  ..., -6.3548,  0.7252, -5.7898],\n",
      "         [-1.5093,  7.2598, -4.9967,  ..., -4.8404, -0.8477, -5.8635]],\n",
      "\n",
      "        [[-1.5729,  7.4058, -2.2549,  ..., -6.4863,  2.0264, -6.3333],\n",
      "         [-0.6868,  6.0668, -1.4837,  ..., -4.8126,  0.7645, -3.6697],\n",
      "         [-1.0229,  6.8784, -0.9867,  ..., -4.6031, -0.7931, -3.6531],\n",
      "         ...,\n",
      "         [-1.0224,  9.1051, -3.3147,  ..., -5.5691,  0.4086, -6.0768],\n",
      "         [-1.7510,  3.5989, -1.5475,  ..., -6.1462,  0.5158, -6.5630],\n",
      "         [-1.4167,  7.7028, -3.7388,  ..., -6.6475,  0.2354, -5.8029]],\n",
      "\n",
      "        [[-1.2958,  9.6072, -3.9919,  ..., -4.9530,  0.1172, -4.7765],\n",
      "         [-0.1741,  5.7759, -1.2074,  ..., -6.3599,  0.7740, -6.0881],\n",
      "         [-0.1562,  5.0121, -3.1543,  ..., -6.8042,  1.1475, -5.2428],\n",
      "         ...,\n",
      "         [ 1.4319,  8.3320, -4.4486,  ..., -2.9932, -1.1185, -6.2484],\n",
      "         [-0.5504,  6.7394, -3.6320,  ..., -5.3077,  0.8924, -6.6424],\n",
      "         [-0.1399,  7.5574, -1.8219,  ..., -5.4212,  0.9153, -5.8958]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.0543,  7.5386, -3.7628,  ..., -1.8681, -0.8548, -6.9537],\n",
      "         [-0.4536,  7.3216, -2.4957,  ..., -7.6267, -1.0427, -7.6470],\n",
      "         [-0.1423,  8.0558, -3.2112,  ..., -7.5477,  1.4532, -7.0456],\n",
      "         ...,\n",
      "         [-1.3391,  8.7115, -3.9852,  ..., -3.9574,  3.9924, -6.1559],\n",
      "         [-1.7642,  8.7654, -3.7861,  ..., -5.5339,  1.1304, -5.9736],\n",
      "         [-2.7558,  5.5314, -0.6844,  ..., -7.4379, -0.8471, -5.8098]],\n",
      "\n",
      "        [[-0.8367,  8.7724, -4.6630,  ..., -4.9310,  0.2220, -7.0275],\n",
      "         [-1.7174,  8.5305, -1.6880,  ..., -5.7238,  0.6240, -7.6346],\n",
      "         [ 0.3984,  5.4467, -2.2100,  ..., -3.2392,  3.1366, -5.5224],\n",
      "         ...,\n",
      "         [-2.2972,  7.5367, -4.9645,  ..., -4.4325, -0.4306, -6.3939],\n",
      "         [-2.3894,  8.1217, -3.6318,  ..., -4.9823, -0.9021, -5.2926],\n",
      "         [-1.6602,  8.3032, -3.3823,  ..., -6.6343, -2.4895, -5.1467]],\n",
      "\n",
      "        [[-3.5575,  9.4135, -3.5695,  ..., -7.6272,  1.1215, -6.0670],\n",
      "         [-1.5154,  7.9997, -2.4207,  ..., -3.9462,  1.0255, -5.2303],\n",
      "         [-1.1785,  6.4140, -2.3611,  ..., -3.6402,  1.0754, -5.7060],\n",
      "         ...,\n",
      "         [-1.3584,  6.3159, -2.7310,  ..., -5.8431,  1.4271, -5.7170],\n",
      "         [-2.4197,  7.2470, -2.5956,  ..., -3.9473,  0.3695, -6.9713],\n",
      "         [-0.2862,  8.2810, -4.0575,  ..., -6.4237,  0.0158, -6.6253]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 88, 64]) , torch.Size([512, 8, 88, 64]), torch.Size([512, 8, 88, 64])\n",
      "Score shape -- torch.Size([512, 8, 88, 88])\n",
      "Mask ---> torch.Size([512, 1, 88])\n",
      "Mask new --> torch.Size([512, 1, 1, 88])\n",
      "loop within encoder. Iteration -- 5\n",
      "this is x in EncoderLayer-----> tensor([[[ -0.4743,   7.5726,  -1.4107,  ..., -10.6081,  -0.3903,  -4.3333],\n",
      "         [  1.6861,   7.7059,   0.0792,  ...,  -7.4687,   1.5811,  -6.3134],\n",
      "         [  0.6143,   7.7629,  -0.4895,  ...,  -7.9346,  -1.7025,  -4.5615],\n",
      "         ...,\n",
      "         [ -0.1148,   8.5247,  -2.3162,  ...,  -7.0319,  -0.7027,  -5.6319],\n",
      "         [ -1.3923,   8.0278,  -3.0044,  ...,  -9.1144,   0.9311,  -4.5729],\n",
      "         [ -0.3723,   6.5167,  -3.5408,  ...,  -6.8768,  -0.5498,  -4.6262]],\n",
      "\n",
      "        [[ -0.8289,   6.7845,  -1.3053,  ...,  -8.8753,   1.4870,  -3.9114],\n",
      "         [  0.6487,   5.5497,   0.0524,  ...,  -7.3687,   0.6189,  -2.9729],\n",
      "         [  0.4087,   6.3779,   0.6774,  ...,  -7.4197,   0.2591,  -1.7643],\n",
      "         ...,\n",
      "         [ -0.2434,   9.2197,  -2.1379,  ...,  -7.6213,   0.3805,  -6.0768],\n",
      "         [ -1.0216,   3.5123,   0.4423,  ...,  -8.0177,   1.0724,  -5.0120],\n",
      "         [ -0.7221,   7.4488,  -2.0126,  ...,  -9.0565,   0.9846,  -4.2588]],\n",
      "\n",
      "        [[ -0.7318,   8.9622,  -2.0060,  ...,  -6.5265,   0.1835,  -4.1900],\n",
      "         [  0.6333,   5.3827,   0.5865,  ...,  -8.6130,   0.7762,  -4.1029],\n",
      "         [  0.7324,   4.1153,  -1.6905,  ...,  -8.5198,   1.4119,  -3.4705],\n",
      "         ...,\n",
      "         [  2.0241,   7.8300,  -2.5015,  ...,  -5.0551,  -0.5676,  -4.8994],\n",
      "         [  0.0439,   5.6528,  -1.7941,  ...,  -7.5277,   0.9933,  -4.9715],\n",
      "         [  0.7586,   6.9951,   0.2662,  ...,  -7.7153,   1.0574,  -4.2101]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -0.6996,   6.6754,  -1.8242,  ...,  -4.3865,  -1.0002,  -5.2968],\n",
      "         [  0.3421,   6.3713,  -1.2221,  ..., -10.1533,  -1.2409,  -7.1705],\n",
      "         [  0.6481,   7.2557,  -1.2804,  ...,  -9.8147,   1.7775,  -5.8582],\n",
      "         ...,\n",
      "         [ -0.8689,   8.0570,  -2.6012,  ...,  -5.9811,   3.5397,  -4.8143],\n",
      "         [ -0.7795,   8.3831,  -2.6176,  ...,  -7.4763,   1.3809,  -4.3343],\n",
      "         [ -1.7789,   4.7668,   0.9374,  ...,  -9.7809,  -0.6269,  -4.4456]],\n",
      "\n",
      "        [[  0.1860,   7.8405,  -3.2469,  ...,  -7.1286,   0.5755,  -4.9929],\n",
      "         [ -0.6484,   8.0397,  -0.4347,  ...,  -7.9837,   0.6983,  -6.3297],\n",
      "         [  0.8539,   5.1154,  -0.8575,  ...,  -5.2228,   3.3354,  -3.9109],\n",
      "         ...,\n",
      "         [ -1.8580,   7.1869,  -3.5298,  ...,  -6.6536,   0.0711,  -5.9010],\n",
      "         [ -1.8475,   7.4473,  -2.4053,  ...,  -6.6653,  -1.0890,  -4.2517],\n",
      "         [ -0.9820,   7.6394,  -2.2285,  ...,  -8.2982,  -2.6625,  -3.7583]],\n",
      "\n",
      "        [[ -2.7598,   8.6003,  -2.4576,  ..., -10.2060,   0.5165,  -5.1613],\n",
      "         [ -0.9085,   7.6652,  -0.8653,  ...,  -6.5465,   1.3592,  -3.8405],\n",
      "         [ -0.7451,   5.7699,  -0.6587,  ...,  -5.5285,   1.4169,  -3.8943],\n",
      "         ...,\n",
      "         [ -0.4562,   6.3159,  -0.6878,  ...,  -8.1472,   1.4934,  -4.3720],\n",
      "         [ -1.9535,   6.3000,  -0.9171,  ...,  -4.6155,   1.2944,  -5.2543],\n",
      "         [  0.4044,   7.4746,  -2.3736,  ...,  -7.9709,  -0.0273,  -4.9011]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 88, 64]) , torch.Size([512, 8, 88, 64]), torch.Size([512, 8, 88, 64])\n",
      "Score shape -- torch.Size([512, 8, 88, 88])\n",
      "Mask ---> torch.Size([512, 1, 88])\n",
      "Mask new --> torch.Size([512, 1, 1, 88])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 94, 64]) , torch.Size([512, 8, 94, 64]), torch.Size([512, 8, 94, 64])\n",
      "Score shape -- torch.Size([512, 8, 94, 94])\n",
      "Mask ---> torch.Size([512, 94, 94])\n",
      "Mask new --> torch.Size([512, 1, 94, 94])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 94, 64]) , torch.Size([512, 8, 88, 64]), torch.Size([512, 8, 88, 64])\n",
      "Score shape -- torch.Size([512, 8, 94, 88])\n",
      "Mask ---> torch.Size([512, 1, 88])\n",
      "Mask new --> torch.Size([512, 1, 1, 88])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 94, 64]) , torch.Size([512, 8, 94, 64]), torch.Size([512, 8, 94, 64])\n",
      "Score shape -- torch.Size([512, 8, 94, 94])\n",
      "Mask ---> torch.Size([512, 94, 94])\n",
      "Mask new --> torch.Size([512, 1, 94, 94])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 94, 64]) , torch.Size([512, 8, 88, 64]), torch.Size([512, 8, 88, 64])\n",
      "Score shape -- torch.Size([512, 8, 94, 88])\n",
      "Mask ---> torch.Size([512, 1, 88])\n",
      "Mask new --> torch.Size([512, 1, 1, 88])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 94, 64]) , torch.Size([512, 8, 94, 64]), torch.Size([512, 8, 94, 64])\n",
      "Score shape -- torch.Size([512, 8, 94, 94])\n",
      "Mask ---> torch.Size([512, 94, 94])\n",
      "Mask new --> torch.Size([512, 1, 94, 94])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 94, 64]) , torch.Size([512, 8, 88, 64]), torch.Size([512, 8, 88, 64])\n",
      "Score shape -- torch.Size([512, 8, 94, 88])\n",
      "Mask ---> torch.Size([512, 1, 88])\n",
      "Mask new --> torch.Size([512, 1, 1, 88])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 94, 64]) , torch.Size([512, 8, 94, 64]), torch.Size([512, 8, 94, 64])\n",
      "Score shape -- torch.Size([512, 8, 94, 94])\n",
      "Mask ---> torch.Size([512, 94, 94])\n",
      "Mask new --> torch.Size([512, 1, 94, 94])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 94, 64]) , torch.Size([512, 8, 88, 64]), torch.Size([512, 8, 88, 64])\n",
      "Score shape -- torch.Size([512, 8, 94, 88])\n",
      "Mask ---> torch.Size([512, 1, 88])\n",
      "Mask new --> torch.Size([512, 1, 1, 88])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 94, 64]) , torch.Size([512, 8, 94, 64]), torch.Size([512, 8, 94, 64])\n",
      "Score shape -- torch.Size([512, 8, 94, 94])\n",
      "Mask ---> torch.Size([512, 94, 94])\n",
      "Mask new --> torch.Size([512, 1, 94, 94])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 94, 64]) , torch.Size([512, 8, 88, 64]), torch.Size([512, 8, 88, 64])\n",
      "Score shape -- torch.Size([512, 8, 94, 88])\n",
      "Mask ---> torch.Size([512, 1, 88])\n",
      "Mask new --> torch.Size([512, 1, 1, 88])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 94, 64]) , torch.Size([512, 8, 94, 64]), torch.Size([512, 8, 94, 64])\n",
      "Score shape -- torch.Size([512, 8, 94, 94])\n",
      "Mask ---> torch.Size([512, 94, 94])\n",
      "Mask new --> torch.Size([512, 1, 94, 94])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 94, 64]) , torch.Size([512, 8, 88, 64]), torch.Size([512, 8, 88, 64])\n",
      "Score shape -- torch.Size([512, 8, 94, 88])\n",
      "Mask ---> torch.Size([512, 1, 88])\n",
      "Mask new --> torch.Size([512, 1, 1, 88])\n",
      "predictions size : tensor([[-0.5431, -0.6141, -0.0941,  ..., -0.5479, -0.4186, -0.0912],\n",
      "        [-0.6145, -0.6604, -0.0815,  ..., -0.3216, -0.6723, -0.2348],\n",
      "        [-0.4853, -0.6222, -0.2927,  ..., -0.3627, -0.5755, -0.1312],\n",
      "        ...,\n",
      "        [-0.5617, -0.5857, -0.1952,  ..., -0.2912, -0.4914, -0.0541],\n",
      "        [-0.5632, -0.5412, -0.1503,  ..., -0.2673, -0.4662, -0.0268],\n",
      "        [-0.5408, -0.7039, -0.2282,  ..., -0.2436, -0.6224, -0.1177]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "targets size : torch.Size([48128])\n",
      "Loss.data ----> = 8.193114280700684\n",
      "--Encoder x after PE : tensor([[[-0.5277,  0.9162,  0.4051,  ...,  0.5172, -0.6235,  0.7998],\n",
      "         [ 0.0000,  0.9088,  0.4819,  ...,  1.6178,  0.2056,  1.3706],\n",
      "         [ 0.4640, -0.5609,  0.9891,  ...,  1.6726,  0.4971,  0.0000],\n",
      "         ...,\n",
      "         [ 0.3009, -1.3217,  0.8777,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2549,  0.0000,  1.6227,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.0000,  1.6917, -0.0321,  ...,  0.7521, -0.1314,  0.8001],\n",
      "         [ 0.0000,  0.9888,  0.4327,  ...,  1.1222,  0.0842,  1.2083],\n",
      "         [ 0.7963, -0.6456,  1.5198,  ...,  1.4374, -0.6158,  0.8053],\n",
      "         ...,\n",
      "         [ 0.3009, -1.3217,  0.8777,  ...,  1.0595,  0.1775,  0.0000],\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  1.0595,  0.1775,  0.0000],\n",
      "         [ 0.0000,  0.0000,  1.6227,  ...,  0.0000,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.3632,  0.6448,  0.6325,  ...,  1.6036,  0.5581,  1.0779],\n",
      "         [ 0.0000,  0.0000,  1.3228,  ...,  0.9924,  0.4649,  1.5228],\n",
      "         [ 0.7487, -0.0000,  0.9709,  ...,  0.4836, -0.6008,  0.5330],\n",
      "         ...,\n",
      "         [ 0.3009, -1.3217,  0.8777,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  1.0595,  0.0000,  0.0000],\n",
      "         [ 1.2549,  0.2458,  1.6227,  ...,  0.0000,  0.1775,  0.5406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.5742,  1.2771,  0.1916,  ...,  0.8993, -0.2420,  0.0000],\n",
      "         [ 0.7413,  0.0183,  0.0000,  ...,  1.7526,  0.0489,  1.6351],\n",
      "         [ 0.9988,  0.1641,  1.1569,  ...,  1.1742,  0.1750,  1.1290],\n",
      "         ...,\n",
      "         [ 0.3009, -1.3217,  0.8777,  ...,  0.0000,  0.1775,  0.5406],\n",
      "         [ 1.2172, -0.0000,  1.6566,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2549,  0.2458,  1.6227,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.0000,  1.7573,  0.0925,  ...,  0.0000,  0.4870,  1.2053],\n",
      "         [ 0.9623,  0.5464,  0.8485,  ...,  1.3882, -0.4976,  1.0164],\n",
      "         [ 0.8286, -1.0004,  0.7005,  ...,  1.2174,  0.1696,  1.1502],\n",
      "         ...,\n",
      "         [ 0.3009, -0.0000,  0.8777,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  0.0000,  0.1775,  0.5406],\n",
      "         [ 1.2549,  0.2458,  1.6227,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.5742,  1.2771,  0.1916,  ...,  0.8993, -0.2420,  0.5467],\n",
      "         [ 0.9828,  0.2694,  1.2194,  ...,  0.8465, -0.3312,  0.0000],\n",
      "         [ 1.0661, -0.8323,  0.8328,  ...,  1.3606,  0.0981,  0.6020],\n",
      "         ...,\n",
      "         [ 0.3009, -1.3217,  0.8777,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  1.0595,  0.0000,  0.0000],\n",
      "         [ 1.2549,  0.2458,  1.6227,  ...,  1.0595,  0.1775,  0.5406]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "loop within encoder. Iteration -- 0\n",
      "this is x in EncoderLayer-----> tensor([[[-0.5277,  0.9162,  0.4051,  ...,  0.5172, -0.6235,  0.7998],\n",
      "         [ 0.0000,  0.9088,  0.4819,  ...,  1.6178,  0.2056,  1.3706],\n",
      "         [ 0.4640, -0.5609,  0.9891,  ...,  1.6726,  0.4971,  0.0000],\n",
      "         ...,\n",
      "         [ 0.3009, -1.3217,  0.8777,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2549,  0.0000,  1.6227,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.0000,  1.6917, -0.0321,  ...,  0.7521, -0.1314,  0.8001],\n",
      "         [ 0.0000,  0.9888,  0.4327,  ...,  1.1222,  0.0842,  1.2083],\n",
      "         [ 0.7963, -0.6456,  1.5198,  ...,  1.4374, -0.6158,  0.8053],\n",
      "         ...,\n",
      "         [ 0.3009, -1.3217,  0.8777,  ...,  1.0595,  0.1775,  0.0000],\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  1.0595,  0.1775,  0.0000],\n",
      "         [ 0.0000,  0.0000,  1.6227,  ...,  0.0000,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.3632,  0.6448,  0.6325,  ...,  1.6036,  0.5581,  1.0779],\n",
      "         [ 0.0000,  0.0000,  1.3228,  ...,  0.9924,  0.4649,  1.5228],\n",
      "         [ 0.7487, -0.0000,  0.9709,  ...,  0.4836, -0.6008,  0.5330],\n",
      "         ...,\n",
      "         [ 0.3009, -1.3217,  0.8777,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  1.0595,  0.0000,  0.0000],\n",
      "         [ 1.2549,  0.2458,  1.6227,  ...,  0.0000,  0.1775,  0.5406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.5742,  1.2771,  0.1916,  ...,  0.8993, -0.2420,  0.0000],\n",
      "         [ 0.7413,  0.0183,  0.0000,  ...,  1.7526,  0.0489,  1.6351],\n",
      "         [ 0.9988,  0.1641,  1.1569,  ...,  1.1742,  0.1750,  1.1290],\n",
      "         ...,\n",
      "         [ 0.3009, -1.3217,  0.8777,  ...,  0.0000,  0.1775,  0.5406],\n",
      "         [ 1.2172, -0.0000,  1.6566,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2549,  0.2458,  1.6227,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.0000,  1.7573,  0.0925,  ...,  0.0000,  0.4870,  1.2053],\n",
      "         [ 0.9623,  0.5464,  0.8485,  ...,  1.3882, -0.4976,  1.0164],\n",
      "         [ 0.8286, -1.0004,  0.7005,  ...,  1.2174,  0.1696,  1.1502],\n",
      "         ...,\n",
      "         [ 0.3009, -0.0000,  0.8777,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  0.0000,  0.1775,  0.5406],\n",
      "         [ 1.2549,  0.2458,  1.6227,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.5742,  1.2771,  0.1916,  ...,  0.8993, -0.2420,  0.5467],\n",
      "         [ 0.9828,  0.2694,  1.2194,  ...,  0.8465, -0.3312,  0.0000],\n",
      "         [ 1.0661, -0.8323,  0.8328,  ...,  1.3606,  0.0981,  0.6020],\n",
      "         ...,\n",
      "         [ 0.3009, -1.3217,  0.8777,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  1.0595,  0.0000,  0.0000],\n",
      "         [ 1.2549,  0.2458,  1.6227,  ...,  1.0595,  0.1775,  0.5406]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 91])\n",
      "Mask ---> torch.Size([512, 1, 91])\n",
      "Mask new --> torch.Size([512, 1, 1, 91])\n",
      "loop within encoder. Iteration -- 1\n",
      "this is x in EncoderLayer-----> tensor([[[-2.6748e+00,  3.4534e+00,  1.2231e-03,  ..., -2.0350e+00,\n",
      "           2.1564e+00, -1.1867e+00],\n",
      "         [-1.8786e+00,  1.9121e+00,  8.4098e-02,  ..., -6.4618e-01,\n",
      "           2.5617e+00, -3.3254e-02],\n",
      "         [-1.5367e+00,  3.0380e+00,  4.5225e-01,  ..., -7.4846e-01,\n",
      "           2.2733e+00, -1.4075e+00],\n",
      "         ...,\n",
      "         [-1.4998e+00, -1.3217e+00,  2.7139e-01,  ..., -2.2254e+00,\n",
      "           2.8126e+00, -1.9188e+00],\n",
      "         [-1.2434e+00,  2.0519e+00,  4.5267e-01,  ..., -2.0581e+00,\n",
      "           2.7105e+00, -1.7941e+00],\n",
      "         [-6.3758e-01,  2.8172e+00,  1.2952e+00,  ..., -1.6643e+00,\n",
      "           2.6326e+00, -1.9760e+00]],\n",
      "\n",
      "        [[-1.6934e+00,  3.9274e+00,  1.0899e+00,  ..., -2.2606e+00,\n",
      "           3.9838e+00, -1.2399e+00],\n",
      "         [-4.7544e-01,  2.8426e+00,  9.7684e-01,  ..., -1.1815e+00,\n",
      "           3.0159e+00, -8.7547e-02],\n",
      "         [-4.0646e-01,  1.3479e+00,  1.1057e+00,  ..., -9.7953e-01,\n",
      "           3.0426e+00, -8.1235e-01],\n",
      "         ...,\n",
      "         [-8.0377e-02,  1.0623e+00,  2.7043e-01,  ..., -1.5694e+00,\n",
      "           1.2685e+00, -8.3464e-01],\n",
      "         [ 2.4109e-01,  1.5519e+00,  1.5702e+00,  ..., -3.8221e-01,\n",
      "           2.4157e+00, -1.0732e+00],\n",
      "         [-1.2150e+00,  2.0372e+00,  2.3644e+00,  ..., -2.6294e+00,\n",
      "           3.4230e+00, -1.8146e+00]],\n",
      "\n",
      "        [[-2.5472e+00,  3.5893e+00,  8.7455e-01,  ..., -1.7235e-01,\n",
      "           3.9808e+00, -1.5757e-01],\n",
      "         [-1.3525e+00,  2.4126e+00,  4.3242e-01,  ..., -1.9368e+00,\n",
      "           4.1409e+00,  9.0635e-01],\n",
      "         [-1.2780e+00,  2.8352e+00,  7.5794e-01,  ..., -2.1308e+00,\n",
      "           3.2332e+00, -3.4174e-01],\n",
      "         ...,\n",
      "         [-2.1647e+00,  1.6071e+00,  9.5345e-01,  ..., -1.4019e+00,\n",
      "           1.1365e+00, -1.6460e+00],\n",
      "         [-7.8561e-02,  2.8565e+00,  1.2821e+00,  ..., -2.2991e-01,\n",
      "           3.2569e+00, -1.7086e+00],\n",
      "         [-7.0175e-01,  3.8166e+00,  2.1865e+00,  ..., -2.4273e+00,\n",
      "           2.9564e+00, -2.9887e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.7710e+00,  4.3517e+00, -3.0814e-01,  ..., -1.0611e+00,\n",
      "           2.0548e+00, -1.6694e+00],\n",
      "         [-2.1762e+00,  2.2524e+00, -6.0793e-01,  ...,  4.9925e-01,\n",
      "           1.6309e+00,  3.7784e-02],\n",
      "         [-1.2275e+00,  2.0197e+00,  9.3728e-01,  ..., -4.9176e-01,\n",
      "           2.9682e+00, -1.9485e-01],\n",
      "         ...,\n",
      "         [-1.3116e+00,  2.2260e+00, -2.3931e-01,  ..., -2.3428e+00,\n",
      "           2.9711e+00, -1.4993e+00],\n",
      "         [-5.1645e-01,  2.9857e+00,  1.4799e+00,  ..., -1.5094e+00,\n",
      "           2.6251e+00, -2.6906e+00],\n",
      "         [-1.0415e+00,  3.1849e+00,  1.4296e+00,  ..., -1.3844e+00,\n",
      "           1.8585e+00, -1.9540e+00]],\n",
      "\n",
      "        [[-1.7937e+00,  4.9686e+00, -9.8274e-01,  ..., -3.0563e+00,\n",
      "           2.0891e+00,  6.4592e-01],\n",
      "         [ 9.6232e-01,  1.6347e+00, -3.4749e-01,  ...,  4.5979e-01,\n",
      "           2.0151e+00, -4.8591e-01],\n",
      "         [-1.1154e+00,  2.1264e+00,  8.4498e-01,  ...,  6.0290e-01,\n",
      "           2.9606e+00, -6.2932e-02],\n",
      "         ...,\n",
      "         [-1.4155e+00,  2.5861e+00, -8.0383e-02,  ..., -1.9940e+00,\n",
      "           2.9272e+00, -9.7060e-01],\n",
      "         [-4.8861e-01,  2.0852e+00,  3.4201e-01,  ..., -2.0029e+00,\n",
      "           2.6270e+00, -1.2166e+00],\n",
      "         [ 9.2427e-01,  3.6911e+00,  3.6298e-01,  ..., -1.9654e+00,\n",
      "           2.9492e+00, -1.3926e+00]],\n",
      "\n",
      "        [[-7.4069e-01,  3.9055e+00, -7.1713e-01,  ..., -1.5351e+00,\n",
      "           1.3458e-01, -9.3344e-01],\n",
      "         [ 9.8047e-01,  1.1071e+00,  8.0523e-01,  ..., -1.5341e+00,\n",
      "           1.4341e+00, -1.1853e+00],\n",
      "         [ 4.1049e-01,  1.1906e+00,  1.0058e+00,  ...,  4.3535e-01,\n",
      "           3.5466e+00, -1.1369e+00],\n",
      "         ...,\n",
      "         [-1.0041e+00,  1.2311e+00,  7.2842e-01,  ..., -7.6126e-01,\n",
      "           1.3204e+00, -1.4822e+00],\n",
      "         [-1.0306e-01,  1.9517e+00,  1.5289e+00,  ..., -1.0627e+00,\n",
      "           3.1886e+00, -2.0981e+00],\n",
      "         [ 2.0958e-01,  2.5432e+00,  1.9374e+00,  ..., -1.3530e+00,\n",
      "           2.9658e+00, -1.4969e+00]]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 91])\n",
      "Mask ---> torch.Size([512, 1, 91])\n",
      "Mask new --> torch.Size([512, 1, 1, 91])\n",
      "loop within encoder. Iteration -- 2\n",
      "this is x in EncoderLayer-----> tensor([[[-2.6449,  5.1748, -0.9969,  ..., -3.8290,  1.8258, -2.8344],\n",
      "         [-2.1691,  3.4980, -0.9987,  ..., -2.2050,  2.4439, -0.9558],\n",
      "         [-1.4020,  4.7874, -0.4158,  ..., -2.7465,  2.1503, -3.1683],\n",
      "         ...,\n",
      "         [-1.7118,  0.7396, -0.4798,  ..., -4.5157,  2.9608, -3.2554],\n",
      "         [-1.5777,  4.0100, -1.1794,  ..., -3.7457,  2.2052, -2.8601],\n",
      "         [-0.2008,  5.5793, -0.1632,  ..., -2.7820,  2.2708, -3.0655]],\n",
      "\n",
      "        [[-1.2175,  5.2090,  2.0965,  ..., -5.1404,  3.9378, -3.9468],\n",
      "         [ 1.0390,  4.1585,  1.0347,  ..., -4.1727,  2.0023, -3.3988],\n",
      "         [ 0.5790,  3.0890,  1.1473,  ..., -3.7335,  2.1928, -3.0502],\n",
      "         ...,\n",
      "         [ 1.3996,  2.8312, -0.9723,  ..., -3.8287,  0.5715, -3.6290],\n",
      "         [ 1.8580,  2.7288,  1.1227,  ..., -2.9877,  1.8027, -3.9130],\n",
      "         [-0.0208,  3.5790,  1.2604,  ..., -5.4947,  2.9142, -4.7131]],\n",
      "\n",
      "        [[-2.1253,  5.4184,  1.0574,  ..., -2.4755,  2.9634, -1.2709],\n",
      "         [-0.7861,  4.2675,  0.1099,  ..., -3.6599,  3.5919, -0.8648],\n",
      "         [-0.4971,  4.8354,  0.9869,  ..., -4.2450,  2.1498, -1.9448],\n",
      "         ...,\n",
      "         [-1.3641,  3.1157,  0.2409,  ..., -3.0559,  0.6365, -2.6765],\n",
      "         [-0.0580,  4.3039,  0.4199,  ..., -1.8449,  2.4664, -3.4351],\n",
      "         [-0.2877,  5.4459,  0.9677,  ..., -4.4382,  2.5694, -2.0945]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.1525,  6.1688, -0.7209,  ..., -1.9773,  1.0558, -3.2885],\n",
      "         [-2.1865,  4.7846, -1.2648,  ..., -1.8103,  0.6316, -2.0132],\n",
      "         [-0.7847,  4.2219,  0.0777,  ..., -2.7794,  2.0907, -2.1360],\n",
      "         ...,\n",
      "         [-0.9096,  4.0822, -0.9680,  ..., -4.5653,  3.5203, -2.3605],\n",
      "         [-0.6771,  4.9740,  0.5871,  ..., -3.4380,  1.6160, -4.3736],\n",
      "         [-1.0588,  5.1326,  0.4262,  ..., -3.2424,  1.1123, -3.5227]],\n",
      "\n",
      "        [[-1.3358,  7.2711, -1.3628,  ..., -5.6897,  2.4788, -1.3459],\n",
      "         [ 1.2319,  3.7407, -1.3414,  ..., -2.2504,  1.7900, -1.8188],\n",
      "         [-1.1990,  4.0869,  0.4875,  ..., -1.9139,  2.4088, -1.7630],\n",
      "         ...,\n",
      "         [-0.9133,  4.7422, -0.8094,  ..., -2.5162,  2.8632, -1.9738],\n",
      "         [-0.6597,  4.1775, -0.6722,  ..., -4.0482,  2.1148, -2.8921],\n",
      "         [ 1.1273,  5.8718, -0.4345,  ..., -2.2421,  2.6839, -2.3340]],\n",
      "\n",
      "        [[ 0.2382,  5.5266, -0.4235,  ..., -2.0498, -0.1862, -1.5181],\n",
      "         [ 2.1385,  2.9563,  0.7414,  ..., -4.9169,  0.6777, -4.1140],\n",
      "         [ 1.6382,  1.1368,  0.2229,  ..., -1.2453,  2.9234, -2.5813],\n",
      "         ...,\n",
      "         [ 0.3401,  2.8186, -0.1835,  ..., -3.5320,  1.0043, -3.4816],\n",
      "         [ 1.2608,  3.9105,  0.8005,  ..., -3.9286,  2.2469, -4.0620],\n",
      "         [ 1.1856,  4.4175,  2.1735,  ..., -1.7738,  2.2727, -3.4065]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 91])\n",
      "Mask ---> torch.Size([512, 1, 91])\n",
      "Mask new --> torch.Size([512, 1, 1, 91])\n",
      "loop within encoder. Iteration -- 3\n",
      "this is x in EncoderLayer-----> tensor([[[-2.5283,  5.7445, -1.0091,  ..., -7.1445,  0.3631, -4.5698],\n",
      "         [-1.2927,  4.7690, -0.6687,  ..., -2.9896,  1.1371, -1.9764],\n",
      "         [-0.9341,  6.6909, -0.6761,  ..., -4.9091,  0.8005, -4.7092],\n",
      "         ...,\n",
      "         [-1.0345,  2.5062,  0.0551,  ..., -7.7724,  1.2795, -4.7173],\n",
      "         [-1.1844,  5.5098, -1.6761,  ..., -6.8985,  0.1875, -4.6743],\n",
      "         [ 0.1055,  7.2996, -0.4462,  ..., -5.7174,  2.3115, -4.3599]],\n",
      "\n",
      "        [[-1.3452,  5.2543,  2.0514,  ..., -8.1364,  3.4758, -4.7261],\n",
      "         [ 2.0224,  5.6577,  1.2668,  ..., -5.0224,  1.4079, -4.4464],\n",
      "         [ 1.4934,  4.2657,  1.0434,  ..., -7.2434,  0.6910, -3.8168],\n",
      "         ...,\n",
      "         [ 2.0963,  4.1433, -0.8408,  ..., -7.0410, -0.5560, -4.3613],\n",
      "         [ 2.5869,  3.4842,  1.9658,  ..., -6.5166,  0.5652, -5.0615],\n",
      "         [ 0.6232,  4.9525,  1.6851,  ..., -9.1038,  1.1397, -5.5173]],\n",
      "\n",
      "        [[-1.5538,  7.0820,  0.6856,  ..., -4.7840,  3.3254, -2.6316],\n",
      "         [-0.3224,  5.2484,  0.2114,  ..., -4.1854,  2.2694, -1.6318],\n",
      "         [ 0.1787,  6.2887,  0.8723,  ..., -7.9176,  2.1567, -3.4491],\n",
      "         ...,\n",
      "         [-1.0617,  3.1157,  0.5928,  ..., -5.1859, -1.1355, -3.6537],\n",
      "         [ 0.7782,  5.7716, -0.0917,  ..., -4.0858,  0.4180, -4.0630],\n",
      "         [ 0.5124,  6.6367,  1.0529,  ..., -7.7907,  0.9046, -3.3802]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3372,  8.0827, -0.7180,  ..., -5.0627, -0.1461, -3.9785],\n",
      "         [-1.8560,  6.2477, -1.0531,  ..., -4.8187, -0.9078, -4.4534],\n",
      "         [-0.2544,  6.1716, -0.3509,  ..., -5.6326, -0.2135, -3.5308],\n",
      "         ...,\n",
      "         [-0.2960,  5.1513, -1.0664,  ..., -7.5632,  1.2392, -3.6397],\n",
      "         [ 0.1520,  6.0766,  0.8596,  ..., -5.6400, -0.3108, -5.6778],\n",
      "         [-0.1008,  6.8764,  0.3069,  ..., -4.1787, -1.7011, -4.4086]],\n",
      "\n",
      "        [[-0.1254,  9.2790, -1.9921,  ..., -8.3867,  1.3040, -1.3459],\n",
      "         [ 1.8168,  5.2671, -1.8371,  ..., -5.1132,  0.7007, -3.2087],\n",
      "         [-0.2506,  5.6369,  0.2677,  ..., -4.9650,  1.9413, -3.7268],\n",
      "         ...,\n",
      "         [ 0.1038,  6.0648, -1.0880,  ..., -6.0822,  1.6281, -3.6503],\n",
      "         [ 0.4590,  5.7687, -0.7053,  ..., -6.9135,  0.9872, -4.2334],\n",
      "         [ 2.1557,  7.2089, -0.2722,  ..., -3.2465,  1.2013, -3.3721]],\n",
      "\n",
      "        [[ 1.1085,  6.2911,  0.0236,  ..., -4.2904, -1.5774, -2.3121],\n",
      "         [ 2.4690,  3.6866,  0.9920,  ..., -8.3593, -1.2338, -5.4848],\n",
      "         [ 1.9685,  2.8852,  0.6404,  ..., -4.3614,  1.2685, -3.9463],\n",
      "         ...,\n",
      "         [ 1.3859,  4.0755,  0.5913,  ..., -3.5320,  1.1313, -3.4816],\n",
      "         [ 2.4159,  4.6651,  1.4354,  ..., -6.8031,  0.7226, -5.1115],\n",
      "         [ 1.7002,  5.5319,  2.5875,  ..., -5.3578, -0.2708, -4.4357]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 91])\n",
      "Mask ---> torch.Size([512, 1, 91])\n",
      "Mask new --> torch.Size([512, 1, 1, 91])\n",
      "loop within encoder. Iteration -- 4\n",
      "this is x in EncoderLayer-----> tensor([[[-3.1306,  8.0990, -3.3256,  ..., -7.1521, -1.4131, -7.1709],\n",
      "         [-2.0560,  7.3125, -1.2985,  ..., -3.3967,  2.2274, -5.0123],\n",
      "         [-1.0293,  8.8483, -2.8353,  ..., -5.7150,  2.1109, -7.6384],\n",
      "         ...,\n",
      "         [-1.7650,  4.1494, -1.7874,  ..., -8.2177, -0.2105, -8.0011],\n",
      "         [-1.8122,  7.6867, -4.2315,  ..., -7.4320, -1.6261, -6.5285],\n",
      "         [-0.9709,  9.0458, -2.7677,  ..., -6.1377,  1.6483, -7.0581]],\n",
      "\n",
      "        [[-1.7271,  7.6790, -0.4347,  ..., -8.1249,  2.0748, -7.6885],\n",
      "         [ 2.0622,  7.6995, -0.6148,  ..., -4.7935,  0.3364, -5.9827],\n",
      "         [ 1.0894,  6.4884, -1.4278,  ..., -8.0031,  0.1206, -6.4124],\n",
      "         ...,\n",
      "         [ 2.6521,  5.5341, -2.7560,  ..., -7.7670, -1.3074, -7.0100],\n",
      "         [ 2.5653,  5.7420, -0.4819,  ..., -6.6080, -1.2869, -7.2692],\n",
      "         [ 0.0945,  7.4275, -0.8093,  ..., -9.5177, -0.1325, -7.6937]],\n",
      "\n",
      "        [[-1.7863,  9.4068, -1.2039,  ..., -5.0087,  2.6623, -5.0140],\n",
      "         [-0.7957,  8.3157, -1.6597,  ..., -5.2845,  1.2573, -2.6817],\n",
      "         [-1.0372,  8.9878, -1.3496,  ..., -8.7590,  1.4159, -6.6304],\n",
      "         ...,\n",
      "         [-1.2114,  5.7343, -1.3458,  ..., -5.3662, -2.1906, -6.5951],\n",
      "         [ 0.5323,  7.8648, -2.9026,  ..., -4.6891, -1.0318, -7.5521],\n",
      "         [-0.2096,  6.8475, -1.2972,  ..., -8.1333,  1.6649, -4.1788]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0643, 10.1308, -3.2520,  ..., -5.2719, -0.8721, -7.0695],\n",
      "         [-2.4516,  8.7689, -2.8876,  ..., -5.4208, -2.0745, -5.6549],\n",
      "         [ 0.2275,  8.4181, -2.5964,  ..., -5.5429, -0.2766, -6.5668],\n",
      "         ...,\n",
      "         [-1.7820,  7.3363, -3.4310,  ..., -7.4485,  0.9483, -6.8045],\n",
      "         [-0.6497,  7.5246, -1.0641,  ..., -5.4797, -0.9379, -7.4829],\n",
      "         [-0.8676,  8.4375, -1.9742,  ..., -3.9314, -3.1282, -7.4908]],\n",
      "\n",
      "        [[-1.4591, 11.9578, -3.7532,  ..., -8.8991,  1.0540, -4.5374],\n",
      "         [ 0.5874,  7.0589, -3.9019,  ..., -5.3353,  0.2013, -5.8753],\n",
      "         [-1.5052,  7.2799, -1.8706,  ..., -5.2185,  0.9678, -6.4189],\n",
      "         ...,\n",
      "         [ 0.5380,  8.4715, -3.7194,  ..., -5.9317,  0.3492, -4.9358],\n",
      "         [-0.6065,  7.5555, -3.2286,  ..., -7.4151,  2.1020, -6.9014],\n",
      "         [ 2.6611,  9.1152, -2.7751,  ..., -3.8518,  0.5264, -6.7421]],\n",
      "\n",
      "        [[ 0.9681,  6.8727, -2.5940,  ..., -3.7871, -2.2410, -3.9617],\n",
      "         [ 2.3956,  6.4159, -1.3795,  ..., -7.8012, -2.1975, -6.2175],\n",
      "         [ 1.7148,  5.3704, -1.3706,  ..., -4.5462,  0.6110, -6.3555],\n",
      "         ...,\n",
      "         [ 0.7905,  5.9327,  0.2695,  ..., -3.4424,  1.8761, -5.2502],\n",
      "         [ 1.7110,  6.5699, -0.4652,  ..., -6.8080,  0.2080, -7.0363],\n",
      "         [ 0.5906,  7.8362,  0.5782,  ..., -5.8145, -1.5942, -5.2131]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 91])\n",
      "Mask ---> torch.Size([512, 1, 91])\n",
      "Mask new --> torch.Size([512, 1, 1, 91])\n",
      "loop within encoder. Iteration -- 5\n",
      "this is x in EncoderLayer-----> tensor([[[ -2.1863,   8.0491,  -1.7766,  ...,  -8.7726,  -1.3795,  -5.2643],\n",
      "         [ -1.8059,   7.2329,   0.6603,  ...,  -5.5070,   2.3880,  -3.0699],\n",
      "         [ -0.5995,   8.0245,  -1.2959,  ...,  -7.6227,   2.1897,  -6.1441],\n",
      "         ...,\n",
      "         [ -1.4187,   3.2671,  -0.3478,  ...,  -9.8617,   0.1211,  -6.3570],\n",
      "         [ -1.6488,   6.8139,  -2.3745,  ...,  -8.8127,  -1.9079,  -4.9700],\n",
      "         [ -0.5214,   8.3847,  -1.7060,  ...,  -7.9625,   1.7992,  -5.2928]],\n",
      "\n",
      "        [[  0.0895,   7.4381,  -0.5348,  ..., -10.9240,   1.9352,  -5.9091],\n",
      "         [  2.9703,   7.1427,   0.2976,  ...,  -7.6295,   0.0724,  -5.2040],\n",
      "         [  2.6488,   6.0379,  -0.5372,  ..., -10.7564,   0.0385,  -5.4028],\n",
      "         ...,\n",
      "         [  3.5210,   4.6742,  -3.1932,  ...,  -7.5439,  -0.7647,  -5.9478],\n",
      "         [  3.8839,   4.7269,   0.4668,  ...,  -8.6951,  -1.2340,  -4.9770],\n",
      "         [  1.4050,   6.8533,   0.3405,  ..., -11.9790,  -0.1529,  -5.9052]],\n",
      "\n",
      "        [[ -0.4015,   8.6952,  -1.5709,  ...,  -7.3854,   2.4964,  -3.4719],\n",
      "         [ -0.2528,   7.8445,  -0.1068,  ...,  -8.1554,   2.2772,  -0.8836],\n",
      "         [  0.4394,   8.0189,  -0.1497,  ..., -10.7600,   1.0427,  -5.2631],\n",
      "         ...,\n",
      "         [  0.3552,   4.7557,   0.6303,  ...,  -8.0544,  -2.4622,  -5.0793],\n",
      "         [  0.5323,   7.1954,  -1.6597,  ...,  -7.1472,  -1.2915,  -6.0636],\n",
      "         [  1.0634,   5.6021,   0.1545,  ..., -10.6336,   1.3541,  -3.0900]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0.9683,  10.2924,  -1.2820,  ...,  -6.9248,  -0.8946,  -5.2097],\n",
      "         [ -1.8776,   8.0068,  -0.9912,  ...,  -7.4578,  -2.7384,  -5.1062],\n",
      "         [  0.8490,   7.7740,  -0.9513,  ...,  -6.0273,   0.2098,  -4.9775],\n",
      "         ...,\n",
      "         [ -1.5366,   6.7664,  -1.8581,  ...,  -8.8948,   0.9129,  -5.8657],\n",
      "         [ -0.0796,   7.1116,   0.2539,  ...,  -7.1915,  -0.9940,  -6.8793],\n",
      "         [ -0.4293,   8.5631,  -0.2804,  ...,  -5.6489,  -3.1282,  -5.8525]],\n",
      "\n",
      "        [[ -0.2586,  11.4501,  -1.8527,  ..., -11.0010,   1.4438,  -2.7976],\n",
      "         [  0.9446,   6.4974,  -2.7682,  ...,  -7.2306,   0.4454,  -3.6855],\n",
      "         [ -1.1912,   6.4225,  -2.0743,  ...,  -7.4233,   1.0661,  -4.6448],\n",
      "         ...,\n",
      "         [  0.9917,   7.7348,  -1.9164,  ...,  -7.7880,   0.3090,  -4.2919],\n",
      "         [ -0.3208,   7.3838,  -1.9090,  ...,  -8.8656,   2.6127,  -5.4164],\n",
      "         [  3.4862,   8.3715,  -1.3694,  ...,  -5.9588,   0.4069,  -5.4565]],\n",
      "\n",
      "        [[  1.9791,   5.9071,  -1.1321,  ...,  -5.4567,  -2.6363,  -2.4711],\n",
      "         [  3.1425,   5.7291,   0.4966,  ...,  -9.7374,  -1.8029,  -4.1915],\n",
      "         [  2.9836,   4.8456,   0.2263,  ...,  -6.2246,   0.6335,  -5.4803],\n",
      "         ...,\n",
      "         [  1.2789,   5.7264,   1.2276,  ...,  -5.2123,   1.6007,  -3.3966],\n",
      "         [  3.0412,   5.6839,   1.4234,  ...,  -8.3187,  -0.1569,  -5.0522],\n",
      "         [  1.5748,   7.3527,   2.2821,  ...,  -7.4216,  -1.4322,  -3.2695]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 91])\n",
      "Mask ---> torch.Size([512, 1, 91])\n",
      "Mask new --> torch.Size([512, 1, 1, 91])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 90, 64]) , torch.Size([512, 8, 90, 64]), torch.Size([512, 8, 90, 64])\n",
      "Score shape -- torch.Size([512, 8, 90, 90])\n",
      "Mask ---> torch.Size([512, 90, 90])\n",
      "Mask new --> torch.Size([512, 1, 90, 90])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 90, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 90, 91])\n",
      "Mask ---> torch.Size([512, 1, 91])\n",
      "Mask new --> torch.Size([512, 1, 1, 91])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 90, 64]) , torch.Size([512, 8, 90, 64]), torch.Size([512, 8, 90, 64])\n",
      "Score shape -- torch.Size([512, 8, 90, 90])\n",
      "Mask ---> torch.Size([512, 90, 90])\n",
      "Mask new --> torch.Size([512, 1, 90, 90])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 90, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 90, 91])\n",
      "Mask ---> torch.Size([512, 1, 91])\n",
      "Mask new --> torch.Size([512, 1, 1, 91])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 90, 64]) , torch.Size([512, 8, 90, 64]), torch.Size([512, 8, 90, 64])\n",
      "Score shape -- torch.Size([512, 8, 90, 90])\n",
      "Mask ---> torch.Size([512, 90, 90])\n",
      "Mask new --> torch.Size([512, 1, 90, 90])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 90, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 90, 91])\n",
      "Mask ---> torch.Size([512, 1, 91])\n",
      "Mask new --> torch.Size([512, 1, 1, 91])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 90, 64]) , torch.Size([512, 8, 90, 64]), torch.Size([512, 8, 90, 64])\n",
      "Score shape -- torch.Size([512, 8, 90, 90])\n",
      "Mask ---> torch.Size([512, 90, 90])\n",
      "Mask new --> torch.Size([512, 1, 90, 90])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 90, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 90, 91])\n",
      "Mask ---> torch.Size([512, 1, 91])\n",
      "Mask new --> torch.Size([512, 1, 1, 91])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 90, 64]) , torch.Size([512, 8, 90, 64]), torch.Size([512, 8, 90, 64])\n",
      "Score shape -- torch.Size([512, 8, 90, 90])\n",
      "Mask ---> torch.Size([512, 90, 90])\n",
      "Mask new --> torch.Size([512, 1, 90, 90])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 90, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 90, 91])\n",
      "Mask ---> torch.Size([512, 1, 91])\n",
      "Mask new --> torch.Size([512, 1, 1, 91])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 90, 64]) , torch.Size([512, 8, 90, 64]), torch.Size([512, 8, 90, 64])\n",
      "Score shape -- torch.Size([512, 8, 90, 90])\n",
      "Mask ---> torch.Size([512, 90, 90])\n",
      "Mask new --> torch.Size([512, 1, 90, 90])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 90, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 90, 91])\n",
      "Mask ---> torch.Size([512, 1, 91])\n",
      "Mask new --> torch.Size([512, 1, 1, 91])\n",
      "predictions size : tensor([[-0.6011, -0.6313, -0.1938,  ..., -0.5506, -0.5639, -0.1259],\n",
      "        [-0.6186, -0.6796, -0.2237,  ..., -0.4871, -0.4838, -0.1130],\n",
      "        [-0.5908, -0.6838, -0.0987,  ..., -0.3585, -0.4273, -0.2526],\n",
      "        ...,\n",
      "        [-0.6540, -0.7652, -0.2534,  ..., -0.2992, -0.4279, -0.0341],\n",
      "        [-0.6343, -0.6320, -0.3707,  ..., -0.3385, -0.5581, -0.1402],\n",
      "        [-0.6415, -0.7246, -0.2422,  ..., -0.2747, -0.6051, -0.0867]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "targets size : torch.Size([46080])\n",
      "Loss.data ----> = 8.13225269317627\n",
      "--Encoder x after PE : tensor([[[ 0.3135,  1.4595,  0.5675,  ...,  0.6910,  0.2265,  1.0971],\n",
      "         [ 0.0000,  0.2538,  0.0000,  ...,  0.8308,  0.2722,  1.3434],\n",
      "         [ 1.0073,  0.2023,  1.5578,  ...,  0.9061, -0.2425,  1.2492],\n",
      "         ...,\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2549,  0.2458,  1.6227,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.3794,  0.8800,  0.8033,  ...,  0.0000,  0.1775,  0.0000]],\n",
      "\n",
      "        [[ 0.3526,  0.7337, -0.5270,  ...,  0.7679,  0.2852,  0.7487],\n",
      "         [ 0.8239,  0.2165,  0.8879,  ...,  1.2735, -0.5049,  0.0000],\n",
      "         [ 1.1376,  0.1903,  0.5105,  ...,  1.6167, -0.1941,  0.5047],\n",
      "         ...,\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2549,  0.2458,  1.6227,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0000,  0.8800,  0.8033,  ...,  0.0000,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.5231,  0.6473,  0.0000,  ...,  1.1666,  0.0000,  1.1629],\n",
      "         [ 0.8680,  0.0000,  0.0000,  ...,  1.5824, -0.2404,  1.0051],\n",
      "         [ 0.4422,  0.1585,  0.9806,  ...,  0.0000, -0.0245,  0.8012],\n",
      "         ...,\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  1.0595,  0.1775,  0.0000],\n",
      "         [ 1.2549,  0.2458,  0.0000,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.3794,  0.0000,  0.8033,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.3722,  0.5208, -0.0000,  ...,  1.5769, -0.0000,  0.8458],\n",
      "         [ 0.6728,  0.2329,  0.7968,  ...,  0.4835, -0.6010,  0.5322],\n",
      "         [ 1.4808, -0.8419,  1.6981,  ...,  1.5538,  0.4751,  1.6290],\n",
      "         ...,\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2549,  0.2458,  1.6227,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.3794,  0.0000,  0.8033,  ...,  0.0000,  0.0000,  0.5406]],\n",
      "\n",
      "        [[-0.5623,  1.7583,  0.0921,  ...,  1.3366,  0.4865,  1.2050],\n",
      "         [ 0.9633,  0.5462,  0.8477,  ...,  1.3893, -0.4985,  1.0154],\n",
      "         [ 0.0000, -0.0000,  0.7004,  ...,  1.2176,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 1.2172, -0.0000,  1.6566,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0000,  0.2458,  1.6227,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0000,  0.8800,  0.8033,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.5282,  0.9159,  0.4047,  ...,  0.5166, -0.6225,  0.8007],\n",
      "         [ 1.3402,  1.1945,  0.8152,  ...,  1.2083,  0.2410,  1.7054],\n",
      "         [ 0.7482, -0.7900,  0.9703,  ...,  0.4835, -0.6010,  0.5322],\n",
      "         ...,\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2549,  0.2458,  1.6227,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.3794,  0.8800,  0.8033,  ...,  1.0595,  0.1775,  0.0000]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "loop within encoder. Iteration -- 0\n",
      "this is x in EncoderLayer-----> tensor([[[ 0.3135,  1.4595,  0.5675,  ...,  0.6910,  0.2265,  1.0971],\n",
      "         [ 0.0000,  0.2538,  0.0000,  ...,  0.8308,  0.2722,  1.3434],\n",
      "         [ 1.0073,  0.2023,  1.5578,  ...,  0.9061, -0.2425,  1.2492],\n",
      "         ...,\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2549,  0.2458,  1.6227,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.3794,  0.8800,  0.8033,  ...,  0.0000,  0.1775,  0.0000]],\n",
      "\n",
      "        [[ 0.3526,  0.7337, -0.5270,  ...,  0.7679,  0.2852,  0.7487],\n",
      "         [ 0.8239,  0.2165,  0.8879,  ...,  1.2735, -0.5049,  0.0000],\n",
      "         [ 1.1376,  0.1903,  0.5105,  ...,  1.6167, -0.1941,  0.5047],\n",
      "         ...,\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2549,  0.2458,  1.6227,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0000,  0.8800,  0.8033,  ...,  0.0000,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.5231,  0.6473,  0.0000,  ...,  1.1666,  0.0000,  1.1629],\n",
      "         [ 0.8680,  0.0000,  0.0000,  ...,  1.5824, -0.2404,  1.0051],\n",
      "         [ 0.4422,  0.1585,  0.9806,  ...,  0.0000, -0.0245,  0.8012],\n",
      "         ...,\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  1.0595,  0.1775,  0.0000],\n",
      "         [ 1.2549,  0.2458,  0.0000,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.3794,  0.0000,  0.8033,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.3722,  0.5208, -0.0000,  ...,  1.5769, -0.0000,  0.8458],\n",
      "         [ 0.6728,  0.2329,  0.7968,  ...,  0.4835, -0.6010,  0.5322],\n",
      "         [ 1.4808, -0.8419,  1.6981,  ...,  1.5538,  0.4751,  1.6290],\n",
      "         ...,\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2549,  0.2458,  1.6227,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.3794,  0.0000,  0.8033,  ...,  0.0000,  0.0000,  0.5406]],\n",
      "\n",
      "        [[-0.5623,  1.7583,  0.0921,  ...,  1.3366,  0.4865,  1.2050],\n",
      "         [ 0.9633,  0.5462,  0.8477,  ...,  1.3893, -0.4985,  1.0154],\n",
      "         [ 0.0000, -0.0000,  0.7004,  ...,  1.2176,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 1.2172, -0.0000,  1.6566,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0000,  0.2458,  1.6227,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0000,  0.8800,  0.8033,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.5282,  0.9159,  0.4047,  ...,  0.5166, -0.6225,  0.8007],\n",
      "         [ 1.3402,  1.1945,  0.8152,  ...,  1.2083,  0.2410,  1.7054],\n",
      "         [ 0.7482, -0.7900,  0.9703,  ...,  0.4835, -0.6010,  0.5322],\n",
      "         ...,\n",
      "         [ 1.2172, -0.7834,  1.6566,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.2549,  0.2458,  1.6227,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.3794,  0.8800,  0.8033,  ...,  1.0595,  0.1775,  0.0000]]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 92])\n",
      "Mask ---> torch.Size([512, 1, 92])\n",
      "Mask new --> torch.Size([512, 1, 1, 92])\n",
      "loop within encoder. Iteration -- 1\n",
      "this is x in EncoderLayer-----> tensor([[[-1.4086,  4.1158, -0.2836,  ..., -1.5342,  2.4786, -0.0483],\n",
      "         [ 0.0000,  3.1911, -0.7216,  ..., -1.6402,  2.5061, -0.4230],\n",
      "         [-1.1287,  2.7834,  0.6090,  ..., -1.2901,  2.3230,  0.6143],\n",
      "         ...,\n",
      "         [-0.4633,  2.4606,  0.7785,  ..., -1.4066,  2.0725, -1.3408],\n",
      "         [-1.0705,  3.6249,  1.2449,  ..., -1.7326,  1.6873, -1.7975],\n",
      "         [-2.0130,  1.9748,  0.8033,  ..., -2.4801,  1.4893, -2.1408]],\n",
      "\n",
      "        [[ 0.9579,  3.2353, -0.8412,  ..., -1.4823,  3.4379,  0.0705],\n",
      "         [-1.2698,  2.4843,  0.5506,  ...,  1.2735,  2.9973, -1.6000],\n",
      "         [-0.8395,  2.9840,  0.6271,  ..., -0.9484,  2.5812, -1.1096],\n",
      "         ...,\n",
      "         [-0.2770,  1.9582,  2.0508,  ..., -1.5680,  2.5623, -1.6253],\n",
      "         [-0.3055,  3.2049,  1.2392,  ..., -1.3849,  3.1104, -1.5989],\n",
      "         [-1.2025,  3.6879, -0.0783,  ..., -2.5242,  2.4650, -1.8448]],\n",
      "\n",
      "        [[-2.8941,  3.6191,  0.6498,  ..., -0.8350,  2.5842, -0.0680],\n",
      "         [-0.8845,  3.5016, -0.9094,  ..., -0.9125,  2.8865, -0.0800],\n",
      "         [-1.5486,  2.1544,  0.3645,  ..., -1.6693,  0.8089, -0.1946],\n",
      "         ...,\n",
      "         [-0.2272,  2.2011,  2.1283,  ..., -1.7665,  2.9516, -2.1272],\n",
      "         [-1.0101,  3.2522, -0.4989,  ..., -1.3213,  2.6398, -1.1820],\n",
      "         [-1.6543,  3.0210,  0.0437,  ..., -0.9357,  2.3412, -1.3215]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.7768,  1.7142, -0.7395,  ...,  0.8747,  0.9635, -0.7422],\n",
      "         [-1.3399,  2.6395,  0.5862,  ..., -2.4333,  2.7566, -0.0827],\n",
      "         [-0.6466,  1.9769,  0.0678,  ..., -1.0365,  4.1847,  0.6708],\n",
      "         ...,\n",
      "         [ 0.0103,  2.0129,  2.4634,  ..., -1.6235,  2.9341, -2.2754],\n",
      "         [-0.1249,  2.9489,  0.5802,  ..., -1.7503,  3.1994, -1.5370],\n",
      "         [-0.7931,  3.2439,  0.7672,  ..., -2.9991,  2.8020, -0.9005]],\n",
      "\n",
      "        [[-2.0552,  5.0033, -0.6396,  ..., -2.1046,  3.4692,  0.2872],\n",
      "         [-1.1519,  3.8150,  0.3994,  ..., -1.4324,  0.4656, -0.3126],\n",
      "         [-1.5480,  2.1142,  1.1262,  ..., -1.2333,  1.6229, -0.9738],\n",
      "         ...,\n",
      "         [-0.5597,  1.8008,  0.8743,  ..., -2.1208,  3.6213, -2.0043],\n",
      "         [-1.0570,  2.3033,  0.9506,  ..., -1.6358,  2.7461, -1.7793],\n",
      "         [-2.1806,  3.6916,  0.9303,  ..., -1.6938,  3.2652, -1.6594]],\n",
      "\n",
      "        [[-1.5638,  1.8852,  1.0417,  ..., -2.0094,  3.0479, -1.1403],\n",
      "         [ 1.5785,  3.2506,  0.0537,  ..., -1.6099,  3.2219, -0.3295],\n",
      "         [-0.3378, -0.0107,  1.4162,  ..., -2.5185,  1.0549, -0.2485],\n",
      "         ...,\n",
      "         [ 0.0124,  0.1130,  2.9267,  ..., -2.7198,  2.9972, -0.3720],\n",
      "         [-0.1442,  2.1222,  1.8825,  ..., -1.1173,  2.8138, -1.6246],\n",
      "         [-1.0764,  3.8337,  1.6874,  ..., -2.2170,  3.2840, -2.3239]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 92])\n",
      "Mask ---> torch.Size([512, 1, 92])\n",
      "Mask new --> torch.Size([512, 1, 1, 92])\n",
      "loop within encoder. Iteration -- 2\n",
      "this is x in EncoderLayer-----> tensor([[[-0.6494,  6.3225, -1.4337,  ..., -4.3132,  1.2893, -1.5429],\n",
      "         [ 0.5104,  3.6945, -1.8217,  ..., -4.1653,  2.8744, -2.1721],\n",
      "         [-0.8760,  4.9070,  0.0579,  ..., -3.2913,  1.1044, -0.0314],\n",
      "         ...,\n",
      "         [-0.8418,  4.4301, -0.8130,  ..., -4.4275,  1.4963, -2.4298],\n",
      "         [-1.0531,  6.1663,  0.2719,  ..., -4.1565,  1.4453, -2.8051],\n",
      "         [-1.8423,  1.6993,  0.2018,  ..., -5.4602,  0.9839, -3.1005]],\n",
      "\n",
      "        [[ 1.5753,  5.5213, -1.3785,  ..., -1.7879,  3.4312, -2.0763],\n",
      "         [-0.7074,  4.2679, -0.4523,  ..., -0.5708,  2.7083, -3.6781],\n",
      "         [-0.1559,  4.6329,  0.5655,  ..., -3.3628,  2.2865, -2.2190],\n",
      "         ...,\n",
      "         [ 0.1147,  4.0195,  0.8301,  ..., -3.5750,  2.1483, -3.0855],\n",
      "         [ 0.2578,  3.6618,  1.2093,  ..., -3.7841,  3.1188, -3.0720],\n",
      "         [-1.2025,  4.7235, -1.1871,  ..., -4.6457,  2.1351, -3.0621]],\n",
      "\n",
      "        [[-1.9108,  5.2583, -0.1606,  ..., -3.7661,  1.9974, -2.2350],\n",
      "         [ 0.0477,  5.4731, -1.7819,  ..., -3.3739,  2.3819, -1.9449],\n",
      "         [-1.5292,  4.1560,  0.0963,  ..., -3.7789,  0.1774, -1.1816],\n",
      "         ...,\n",
      "         [ 0.3370,  4.2691,  1.2095,  ..., -3.7289,  2.5883, -3.4142],\n",
      "         [-0.6817,  5.6063, -1.5644,  ..., -3.6302,  2.0119, -3.0040],\n",
      "         [-1.3451,  5.4450, -1.1285,  ..., -3.3254,  2.8279, -3.2459]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.1347,  1.5345, -1.2427,  ..., -1.9842,  0.2074, -2.6060],\n",
      "         [-0.1351,  4.1327,  0.1362,  ..., -4.9071,  1.9680, -1.2158],\n",
      "         [ 0.1880,  1.9769, -1.1206,  ..., -3.6589,  3.6945, -0.5372],\n",
      "         ...,\n",
      "         [ 0.4662,  4.4959,  1.6385,  ..., -4.7165,  2.7593, -3.4513],\n",
      "         [-0.1249,  4.7551, -0.4620,  ..., -3.8452,  2.7407, -2.6303],\n",
      "         [-0.7931,  5.5390,  0.1705,  ..., -5.6050,  2.6502, -2.3755]],\n",
      "\n",
      "        [[-2.4240,  7.2306, -1.0595,  ..., -2.1046,  3.3249, -0.7922],\n",
      "         [-0.5300,  5.6298, -0.2493,  ..., -2.8878, -0.6824, -1.0127],\n",
      "         [-1.5337,  3.8198,  0.5482,  ..., -2.8073,  1.2021, -3.2447],\n",
      "         ...,\n",
      "         [-0.5589,  3.8651, -0.0923,  ..., -4.1832,  3.4677, -3.6855],\n",
      "         [-0.8132,  4.4647, -0.1048,  ..., -1.3401,  2.7741, -2.4517],\n",
      "         [-2.3868,  5.8582,  0.2265,  ..., -3.6740,  3.2714, -2.7969]],\n",
      "\n",
      "        [[-1.1016,  3.1715,  0.1333,  ..., -5.3498,  2.2432, -3.7661],\n",
      "         [ 2.5893,  4.1350, -0.6674,  ..., -5.1089,  2.8619, -3.2233],\n",
      "         [ 0.3739, -0.0107,  1.0832,  ..., -5.9088,  0.7944, -2.8144],\n",
      "         ...,\n",
      "         [ 1.4648,  1.0239,  1.5708,  ..., -5.8940,  2.9618, -3.2092],\n",
      "         [ 0.5076,  2.4530,  0.9348,  ..., -4.8635,  2.5670, -3.8963],\n",
      "         [-0.1948,  4.9024,  0.5825,  ..., -5.9152,  3.0006, -4.2064]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 92])\n",
      "Mask ---> torch.Size([512, 1, 92])\n",
      "Mask new --> torch.Size([512, 1, 1, 92])\n",
      "loop within encoder. Iteration -- 3\n",
      "this is x in EncoderLayer-----> tensor([[[ 0.2574,  8.3090, -1.7013,  ..., -7.2817, -0.8398, -2.0747],\n",
      "         [ 1.0015,  5.5125, -2.1231,  ..., -5.7395,  1.0716, -3.4866],\n",
      "         [ 0.3204,  6.9361, -0.1495,  ..., -6.3945,  1.3228, -1.0835],\n",
      "         ...,\n",
      "         [-0.5465,  4.5085, -0.7272,  ..., -7.6273, -0.4527, -3.6759],\n",
      "         [-0.0581,  8.0257,  0.0286,  ..., -7.1715, -0.8871, -3.4314],\n",
      "         [-1.3656,  3.6476,  0.2018,  ..., -9.0410, -1.4124, -3.6542]],\n",
      "\n",
      "        [[ 2.3639,  6.7510, -2.0076,  ..., -5.4792,  1.1063, -3.6270],\n",
      "         [ 0.1924,  5.5301, -0.1559,  ..., -3.1310,  0.9253, -5.2849],\n",
      "         [ 1.1816,  5.9917,  0.7323,  ..., -6.5701,  0.3166, -2.6193],\n",
      "         ...,\n",
      "         [ 1.1638,  5.6559,  0.6758,  ..., -7.3149, -0.2980, -4.5218],\n",
      "         [ 0.7239,  4.7075,  1.3840,  ..., -7.1341,  0.6398, -4.6531],\n",
      "         [-0.7523,  6.4296, -1.5678,  ..., -8.0171, -0.0658, -4.4458]],\n",
      "\n",
      "        [[-0.6697,  6.3501, -0.2455,  ..., -4.5346,  2.0600, -3.8043],\n",
      "         [ 0.7741,  7.0493, -1.6663,  ..., -6.5483,  0.2105, -3.7608],\n",
      "         [-0.6447,  4.5689, -0.3848,  ..., -7.0569, -1.9454, -2.8829],\n",
      "         ...,\n",
      "         [ 0.9886,  5.8432,  1.3245,  ..., -6.5248,  0.6420, -3.9313],\n",
      "         [ 0.0875,  7.0403, -1.8378,  ..., -6.8290,  0.2779, -4.2460],\n",
      "         [-0.1792,  7.1680, -0.7393,  ..., -6.8367,  0.6863, -4.1477]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2572,  3.2860, -1.6721,  ..., -4.9953, -1.3054, -3.1698],\n",
      "         [ 0.0952,  5.3824,  0.3518,  ..., -7.4432,  0.4759, -2.4344],\n",
      "         [ 0.5445,  3.4970, -0.8092,  ..., -7.2605,  1.7153, -2.3148],\n",
      "         ...,\n",
      "         [ 0.7641,  5.7454,  1.6693,  ..., -7.7889,  0.8393, -4.6755],\n",
      "         [ 0.4785,  4.6756, -0.3407,  ..., -7.2110,  1.0623, -3.2961],\n",
      "         [-0.2675,  6.8287,  0.4861,  ..., -9.2268,  0.4400, -3.9597]],\n",
      "\n",
      "        [[-1.4796,  7.7626, -1.4273,  ..., -2.6567,  1.5354, -1.4728],\n",
      "         [-0.5300,  7.3902, -0.2959,  ..., -6.0009, -0.3984, -2.7199],\n",
      "         [-0.3584,  5.5350,  0.5963,  ..., -5.1819, -0.0453, -4.3389],\n",
      "         ...,\n",
      "         [ 0.3286,  5.3891, -0.1006,  ..., -6.5423,  2.1158, -4.6356],\n",
      "         [-0.3028,  6.4672, -0.7589,  ..., -4.1298,  0.9543, -3.0997],\n",
      "         [-1.9925,  6.2327,  0.2562,  ..., -6.2953,  1.5254, -3.6029]],\n",
      "\n",
      "        [[-0.4770,  4.5859,  0.3719,  ..., -8.3986,  0.2706, -5.4706],\n",
      "         [ 4.2744,  5.0223, -1.1129,  ..., -8.5965,  1.3294, -4.6008],\n",
      "         [ 1.6122,  1.5367,  0.8642,  ..., -6.9297, -1.0509, -3.4607],\n",
      "         ...,\n",
      "         [ 1.5193,  2.7498,  1.6569,  ..., -8.4520,  2.7069, -4.3601],\n",
      "         [ 1.6882,  4.0752,  0.8888,  ..., -8.2307,  0.8677, -5.0420],\n",
      "         [ 0.7934,  5.8955,  0.3826,  ..., -6.4614,  0.3491, -4.5470]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 92])\n",
      "Mask ---> torch.Size([512, 1, 92])\n",
      "Mask new --> torch.Size([512, 1, 1, 92])\n",
      "loop within encoder. Iteration -- 4\n",
      "this is x in EncoderLayer-----> tensor([[[-0.6121,  9.9768, -3.6174,  ..., -7.7469, -2.5564, -5.5744],\n",
      "         [ 1.0015,  7.2330, -4.1955,  ..., -6.3740,  0.6102, -6.3771],\n",
      "         [-0.8968,  8.1064, -2.2652,  ..., -6.9423,  0.7422, -4.0610],\n",
      "         ...,\n",
      "         [-1.8110,  6.8103, -1.7582,  ..., -8.2376, -0.8630, -6.2015],\n",
      "         [-0.7005, 10.5129, -2.0811,  ..., -7.5168, -1.6788, -7.1722],\n",
      "         [-1.6995,  5.6743, -2.2728,  ..., -9.0631, -2.0386, -5.5632]],\n",
      "\n",
      "        [[ 1.5937,  9.2377, -4.6533,  ..., -6.9635,  0.4655, -6.9765],\n",
      "         [-0.2970,  7.6094, -1.9076,  ..., -4.1504,  0.3305, -7.4949],\n",
      "         [ 0.6528,  6.6810, -1.9632,  ..., -7.2652, -0.1232, -5.3838],\n",
      "         ...,\n",
      "         [ 0.8282,  7.1942, -0.9925,  ..., -7.9768, -0.4753, -6.2539],\n",
      "         [ 0.0235,  6.6939, -1.6000,  ..., -7.2936, -0.4411, -6.1365],\n",
      "         [-2.0818,  8.5446, -4.3664,  ..., -9.1598, -0.6215, -7.3575]],\n",
      "\n",
      "        [[-1.0835,  9.1428, -0.7484,  ..., -4.9747,  1.0065, -6.2904],\n",
      "         [ 0.5427,  9.0391, -4.0543,  ..., -6.3282, -0.6003, -7.0714],\n",
      "         [-1.3245,  6.3000, -2.7168,  ..., -7.4742, -0.7686, -6.5248],\n",
      "         ...,\n",
      "         [ 0.5037,  8.3687, -0.7079,  ..., -6.7799,  0.1818, -7.1224],\n",
      "         [-1.1203,  9.4396, -4.1990,  ..., -7.5674, -1.3882, -7.5236],\n",
      "         [-0.6415,  9.0870, -3.5674,  ..., -6.8925,  0.3817, -6.1185]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.4567,  5.3165, -4.1484,  ..., -4.8226, -1.9153, -6.6290],\n",
      "         [-0.9704,  7.0421, -2.0291,  ..., -7.4943, -0.9488, -5.2282],\n",
      "         [ 0.3023,  5.2938, -3.3413,  ..., -7.2330,  1.1322, -5.9615],\n",
      "         ...,\n",
      "         [ 0.0203,  6.3156, -0.3765,  ..., -7.7719, -0.0648, -7.3756],\n",
      "         [-0.0776,  6.3601, -0.3407,  ..., -7.4670, -0.7448, -6.0625],\n",
      "         [-0.8426,  9.2354, -2.0306,  ..., -9.2169,  0.0352, -4.7520]],\n",
      "\n",
      "        [[-2.2057,  9.5309, -3.8750,  ..., -3.0494,  0.6744, -4.7617],\n",
      "         [-1.7239,  9.6171, -2.2777,  ..., -6.5476, -0.9275, -6.0461],\n",
      "         [-1.2090,  5.6302, -1.7870,  ..., -5.5764, -0.6961, -6.8246],\n",
      "         ...,\n",
      "         [-1.3031,  7.5711, -2.6159,  ..., -6.9066,  1.1885, -7.3301],\n",
      "         [-1.2471,  8.4494, -3.2597,  ..., -4.4799,  0.5754, -5.8951],\n",
      "         [-2.4551,  8.2014, -2.6233,  ..., -6.8964,  0.6737, -6.2637]],\n",
      "\n",
      "        [[-0.8800,  6.2038, -2.0101,  ..., -8.4106, -0.7851, -8.4896],\n",
      "         [ 3.7391,  5.6199, -3.6572,  ..., -8.9134,  0.7109, -5.3152],\n",
      "         [ 1.4769,  3.4436, -2.0479,  ..., -7.5457, -2.8396, -5.6641],\n",
      "         ...,\n",
      "         [ 0.9247,  3.4479,  1.2604,  ..., -9.3823,  1.8964, -6.1226],\n",
      "         [ 1.6333,  5.3620, -2.1065,  ..., -8.8442,  0.0148, -7.7830],\n",
      "         [ 0.5176,  7.6780,  0.1854,  ..., -6.8208, -0.5782, -7.1321]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 92])\n",
      "Mask ---> torch.Size([512, 1, 92])\n",
      "Mask new --> torch.Size([512, 1, 1, 92])\n",
      "loop within encoder. Iteration -- 5\n",
      "this is x in EncoderLayer-----> tensor([[[-8.5586e-02,  9.9768e+00, -2.1975e+00,  ..., -9.2270e+00,\n",
      "          -2.5337e+00, -3.3122e+00],\n",
      "         [ 1.7411e+00,  7.6490e+00, -2.9440e+00,  ..., -8.0068e+00,\n",
      "           6.4436e-01, -4.9457e+00],\n",
      "         [ 2.0357e-01,  7.5911e+00,  2.0019e-01,  ..., -9.4035e+00,\n",
      "           9.3114e-01, -2.5540e+00],\n",
      "         ...,\n",
      "         [-1.0937e+00,  6.6787e+00, -2.3842e-01,  ..., -9.0488e+00,\n",
      "          -9.3867e-01, -4.8100e+00],\n",
      "         [ 6.3479e-01,  9.9223e+00, -3.5089e-01,  ..., -7.5168e+00,\n",
      "          -2.4188e+00, -5.6496e+00],\n",
      "         [-1.5505e+00,  5.0588e+00, -9.7973e-01,  ..., -1.0664e+01,\n",
      "          -1.4331e+00, -4.3409e+00]],\n",
      "\n",
      "        [[ 2.4874e+00,  8.4750e+00, -3.6261e+00,  ..., -9.3319e+00,\n",
      "          -5.5786e-03, -4.6603e+00],\n",
      "         [ 2.8658e-01,  6.7267e+00, -1.3539e-02,  ..., -6.6018e+00,\n",
      "          -4.2326e-01, -5.4360e+00],\n",
      "         [ 1.7903e+00,  7.6651e+00, -9.7709e-02,  ..., -9.4099e+00,\n",
      "          -1.9820e-01, -3.4604e+00],\n",
      "         ...,\n",
      "         [ 1.2369e+00,  6.2872e+00,  1.5801e-01,  ..., -9.6957e+00,\n",
      "          -1.1627e+00, -4.6244e+00],\n",
      "         [ 4.4925e-01,  5.7342e+00, -2.1965e-01,  ..., -9.1168e+00,\n",
      "           7.3759e-01, -4.2216e+00],\n",
      "         [-1.8971e+00,  7.7499e+00, -2.6922e+00,  ..., -1.1681e+01,\n",
      "          -4.4108e-01, -5.1569e+00]],\n",
      "\n",
      "        [[-3.3798e-01,  8.6125e+00, -6.1969e-01,  ..., -7.2006e+00,\n",
      "           1.3256e+00, -3.9688e+00],\n",
      "         [ 1.5103e+00,  8.0832e+00, -2.5506e+00,  ..., -8.9533e+00,\n",
      "          -6.7412e-01, -5.6052e+00],\n",
      "         [-9.5558e-01,  5.5074e+00, -9.2773e-01,  ..., -9.0196e+00,\n",
      "          -2.1809e-01, -4.8017e+00],\n",
      "         ...,\n",
      "         [ 1.4787e+00,  8.0821e+00,  1.2738e+00,  ..., -8.5915e+00,\n",
      "           4.0581e-02, -6.4831e+00],\n",
      "         [-6.0502e-01,  9.0689e+00, -2.6227e+00,  ..., -9.8343e+00,\n",
      "          -1.2017e+00, -5.6342e+00],\n",
      "         [-4.8051e-02,  9.1718e+00, -8.9672e-01,  ..., -8.8193e+00,\n",
      "          -2.7371e-01, -4.5326e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.7074e-01,  4.4589e+00, -2.5037e+00,  ..., -5.3797e+00,\n",
      "          -2.8334e+00, -4.7255e+00],\n",
      "         [-1.1867e+00,  6.9501e+00,  2.1147e-01,  ..., -9.9589e+00,\n",
      "          -2.3533e-01, -3.6852e+00],\n",
      "         [ 1.0092e+00,  5.1662e+00, -1.8776e+00,  ..., -7.7941e+00,\n",
      "           6.1813e-01, -5.9615e+00],\n",
      "         ...,\n",
      "         [ 8.6810e-01,  6.8805e+00,  9.7849e-01,  ..., -1.0401e+01,\n",
      "          -2.3875e-01, -6.8686e+00],\n",
      "         [ 8.6228e-01,  6.3601e+00,  1.0412e+00,  ..., -9.8369e+00,\n",
      "          -1.0135e+00, -5.0092e+00],\n",
      "         [-2.5098e-01,  9.1534e+00, -3.5556e-01,  ..., -1.1689e+01,\n",
      "          -3.7722e-01, -3.1068e+00]],\n",
      "\n",
      "        [[-2.0661e+00,  8.8199e+00, -4.4540e+00,  ..., -4.9589e+00,\n",
      "           8.2510e-01, -3.0952e+00],\n",
      "         [-1.1574e+00,  9.2229e+00, -2.7516e+00,  ..., -8.6691e+00,\n",
      "          -9.5604e-01, -4.3696e+00],\n",
      "         [-3.2086e-01,  5.3530e+00, -2.5888e-01,  ..., -8.1968e+00,\n",
      "          -5.5754e-01, -5.5166e+00],\n",
      "         ...,\n",
      "         [-1.2076e+00,  7.6578e+00, -1.1173e+00,  ..., -7.4526e+00,\n",
      "           1.0051e+00, -6.1289e+00],\n",
      "         [-6.7068e-01,  8.2752e+00, -1.8165e+00,  ..., -6.5560e+00,\n",
      "           6.6928e-01, -4.2812e+00],\n",
      "         [-1.9255e+00,  7.2532e+00, -8.0566e-01,  ..., -8.9928e+00,\n",
      "           3.8027e-01, -4.5120e+00]],\n",
      "\n",
      "        [[ 1.3322e-01,  5.9192e+00, -2.6552e+00,  ..., -1.0392e+01,\n",
      "          -8.5150e-01, -6.7220e+00],\n",
      "         [ 5.0621e+00,  5.4639e+00, -2.1112e+00,  ..., -1.1090e+01,\n",
      "           4.9135e-01, -3.0838e+00],\n",
      "         [ 2.9951e+00,  2.2189e+00, -4.3695e-01,  ..., -9.4862e+00,\n",
      "          -3.5660e+00, -4.2827e+00],\n",
      "         ...,\n",
      "         [ 1.5920e+00,  2.6179e+00,  2.8087e+00,  ..., -1.1504e+01,\n",
      "           1.5651e+00, -4.5823e+00],\n",
      "         [ 2.7656e+00,  4.2844e+00, -4.8045e-01,  ..., -1.0967e+01,\n",
      "          -5.4991e-01, -6.9202e+00],\n",
      "         [ 1.5144e+00,  7.7032e+00,  1.3418e+00,  ..., -8.9402e+00,\n",
      "          -1.5295e+00, -6.5574e+00]]], grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 92])\n",
      "Mask ---> torch.Size([512, 1, 92])\n",
      "Mask new --> torch.Size([512, 1, 1, 92])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 95, 64]) , torch.Size([512, 8, 95, 64]), torch.Size([512, 8, 95, 64])\n",
      "Score shape -- torch.Size([512, 8, 95, 95])\n",
      "Mask ---> torch.Size([512, 95, 95])\n",
      "Mask new --> torch.Size([512, 1, 95, 95])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 95, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 95, 92])\n",
      "Mask ---> torch.Size([512, 1, 92])\n",
      "Mask new --> torch.Size([512, 1, 1, 92])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 95, 64]) , torch.Size([512, 8, 95, 64]), torch.Size([512, 8, 95, 64])\n",
      "Score shape -- torch.Size([512, 8, 95, 95])\n",
      "Mask ---> torch.Size([512, 95, 95])\n",
      "Mask new --> torch.Size([512, 1, 95, 95])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 95, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 95, 92])\n",
      "Mask ---> torch.Size([512, 1, 92])\n",
      "Mask new --> torch.Size([512, 1, 1, 92])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 95, 64]) , torch.Size([512, 8, 95, 64]), torch.Size([512, 8, 95, 64])\n",
      "Score shape -- torch.Size([512, 8, 95, 95])\n",
      "Mask ---> torch.Size([512, 95, 95])\n",
      "Mask new --> torch.Size([512, 1, 95, 95])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 95, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 95, 92])\n",
      "Mask ---> torch.Size([512, 1, 92])\n",
      "Mask new --> torch.Size([512, 1, 1, 92])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 95, 64]) , torch.Size([512, 8, 95, 64]), torch.Size([512, 8, 95, 64])\n",
      "Score shape -- torch.Size([512, 8, 95, 95])\n",
      "Mask ---> torch.Size([512, 95, 95])\n",
      "Mask new --> torch.Size([512, 1, 95, 95])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 95, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 95, 92])\n",
      "Mask ---> torch.Size([512, 1, 92])\n",
      "Mask new --> torch.Size([512, 1, 1, 92])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 95, 64]) , torch.Size([512, 8, 95, 64]), torch.Size([512, 8, 95, 64])\n",
      "Score shape -- torch.Size([512, 8, 95, 95])\n",
      "Mask ---> torch.Size([512, 95, 95])\n",
      "Mask new --> torch.Size([512, 1, 95, 95])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 95, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 95, 92])\n",
      "Mask ---> torch.Size([512, 1, 92])\n",
      "Mask new --> torch.Size([512, 1, 1, 92])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 95, 64]) , torch.Size([512, 8, 95, 64]), torch.Size([512, 8, 95, 64])\n",
      "Score shape -- torch.Size([512, 8, 95, 95])\n",
      "Mask ---> torch.Size([512, 95, 95])\n",
      "Mask new --> torch.Size([512, 1, 95, 95])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 95, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 95, 92])\n",
      "Mask ---> torch.Size([512, 1, 92])\n",
      "Mask new --> torch.Size([512, 1, 1, 92])\n",
      "predictions size : tensor([[-0.7542, -0.7012, -0.2959,  ..., -0.4027, -0.5759, -0.0756],\n",
      "        [-0.7439, -0.6445, -0.3069,  ..., -0.4016, -0.5905, -0.2150],\n",
      "        [-0.7777, -0.6730, -0.2541,  ..., -0.4886, -0.5988, -0.2099],\n",
      "        ...,\n",
      "        [-0.7672, -0.8618, -0.2669,  ..., -0.3698, -0.5363, -0.1599],\n",
      "        [-0.7855, -0.7046, -0.3383,  ..., -0.3333, -0.5465, -0.2158],\n",
      "        [-0.7623, -0.6994, -0.3061,  ..., -0.2370, -0.5980, -0.0786]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "targets size : torch.Size([48640])\n",
      "Loss.data ----> = 8.081218719482422\n",
      "--Encoder x after PE : tensor([[[-0.5240,  0.6478,  0.6548,  ...,  1.1667,  0.0558,  1.1623],\n",
      "         [ 1.3957,  1.1080,  0.7533,  ...,  0.7654, -0.0110,  0.9540],\n",
      "         [ 0.6905,  0.0000,  1.5774,  ...,  1.0289,  0.5082,  1.6599],\n",
      "         ...,\n",
      "         [ 1.3376, -0.0000,  1.7185,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0000,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.5240,  0.6478,  0.6548,  ...,  1.1667,  0.0558,  1.1623],\n",
      "         [ 1.3035,  0.5987,  0.4843,  ...,  1.5115,  0.4999,  1.4786],\n",
      "         [ 0.9421, -0.0000,  1.7150,  ...,  1.3720,  0.5803,  0.0000],\n",
      "         ...,\n",
      "         [ 1.3376, -0.2617,  1.7185,  ...,  1.0595,  0.1775,  0.0000],\n",
      "         [ 1.0763,  0.0000,  1.0508,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.5403,  1.2288, -0.2368,  ...,  0.5425,  0.5006,  1.3638],\n",
      "         [ 0.7674,  1.2505,  1.3936,  ...,  0.7930,  0.2821,  1.7450],\n",
      "         [ 1.1040, -0.3824,  1.6112,  ...,  0.0000,  0.4632,  0.0000],\n",
      "         ...,\n",
      "         [ 1.3376, -0.2617,  1.7185,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  1.0595,  0.1775,  0.0000],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.6236,  1.7611, -0.0184,  ...,  0.7050, -0.1536,  0.5098],\n",
      "         [ 0.0000,  0.3338,  0.0000,  ...,  0.6704, -0.0000,  0.9101],\n",
      "         [ 0.0000, -0.5129,  1.0720,  ...,  1.6471, -0.3341,  1.7524],\n",
      "         ...,\n",
      "         [ 1.3376, -0.2617,  1.7185,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.0000,  0.5406]],\n",
      "\n",
      "        [[-0.5912,  0.8914,  0.1501,  ...,  0.4724, -0.4000,  1.1066],\n",
      "         [ 0.7528,  0.0239,  0.5267,  ...,  1.2179,  0.1699,  1.1484],\n",
      "         [ 0.4901, -0.0000,  0.0000,  ...,  1.1204,  0.6046,  1.3960],\n",
      "         ...,\n",
      "         [ 1.3376, -0.2617,  1.7185,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.0763,  0.0000,  1.0508,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.0000,  0.0581,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.1514,  0.6747, -0.2631,  ...,  1.3249,  0.3008,  0.8278],\n",
      "         [ 1.0863,  0.8566,  0.4523,  ...,  0.0000, -0.4116,  0.8678],\n",
      "         [ 0.8282, -0.9990,  0.7002,  ...,  1.2179,  0.1699,  1.1484],\n",
      "         ...,\n",
      "         [ 1.3376, -0.2617,  1.7185,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [ 0.0660,  0.0000,  0.0581,  ...,  1.0595,  0.1775,  0.5406]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "loop within encoder. Iteration -- 0\n",
      "this is x in EncoderLayer-----> tensor([[[-0.5240,  0.6478,  0.6548,  ...,  1.1667,  0.0558,  1.1623],\n",
      "         [ 1.3957,  1.1080,  0.7533,  ...,  0.7654, -0.0110,  0.9540],\n",
      "         [ 0.6905,  0.0000,  1.5774,  ...,  1.0289,  0.5082,  1.6599],\n",
      "         ...,\n",
      "         [ 1.3376, -0.0000,  1.7185,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0000,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.5240,  0.6478,  0.6548,  ...,  1.1667,  0.0558,  1.1623],\n",
      "         [ 1.3035,  0.5987,  0.4843,  ...,  1.5115,  0.4999,  1.4786],\n",
      "         [ 0.9421, -0.0000,  1.7150,  ...,  1.3720,  0.5803,  0.0000],\n",
      "         ...,\n",
      "         [ 1.3376, -0.2617,  1.7185,  ...,  1.0595,  0.1775,  0.0000],\n",
      "         [ 1.0763,  0.0000,  1.0508,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.5403,  1.2288, -0.2368,  ...,  0.5425,  0.5006,  1.3638],\n",
      "         [ 0.7674,  1.2505,  1.3936,  ...,  0.7930,  0.2821,  1.7450],\n",
      "         [ 1.1040, -0.3824,  1.6112,  ...,  0.0000,  0.4632,  0.0000],\n",
      "         ...,\n",
      "         [ 1.3376, -0.2617,  1.7185,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  1.0595,  0.1775,  0.0000],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.6236,  1.7611, -0.0184,  ...,  0.7050, -0.1536,  0.5098],\n",
      "         [ 0.0000,  0.3338,  0.0000,  ...,  0.6704, -0.0000,  0.9101],\n",
      "         [ 0.0000, -0.5129,  1.0720,  ...,  1.6471, -0.3341,  1.7524],\n",
      "         ...,\n",
      "         [ 1.3376, -0.2617,  1.7185,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.0000,  0.5406]],\n",
      "\n",
      "        [[-0.5912,  0.8914,  0.1501,  ...,  0.4724, -0.4000,  1.1066],\n",
      "         [ 0.7528,  0.0239,  0.5267,  ...,  1.2179,  0.1699,  1.1484],\n",
      "         [ 0.4901, -0.0000,  0.0000,  ...,  1.1204,  0.6046,  1.3960],\n",
      "         ...,\n",
      "         [ 1.3376, -0.2617,  1.7185,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.0763,  0.0000,  1.0508,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.0000,  0.0581,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.1514,  0.6747, -0.2631,  ...,  1.3249,  0.3008,  0.8278],\n",
      "         [ 1.0863,  0.8566,  0.4523,  ...,  0.0000, -0.4116,  0.8678],\n",
      "         [ 0.8282, -0.9990,  0.7002,  ...,  1.2179,  0.1699,  1.1484],\n",
      "         ...,\n",
      "         [ 1.3376, -0.2617,  1.7185,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [ 0.0660,  0.0000,  0.0581,  ...,  1.0595,  0.1775,  0.5406]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 86, 64]) , torch.Size([512, 8, 86, 64]), torch.Size([512, 8, 86, 64])\n",
      "Score shape -- torch.Size([512, 8, 86, 86])\n",
      "Mask ---> torch.Size([512, 1, 86])\n",
      "Mask new --> torch.Size([512, 1, 1, 86])\n",
      "loop within encoder. Iteration -- 1\n",
      "this is x in EncoderLayer-----> tensor([[[-2.5810,  3.0245,  0.7523,  ...,  0.4805,  1.8462, -0.5799],\n",
      "         [-0.7140,  3.6039, -0.4459,  ..., -1.4413,  2.6690, -1.1637],\n",
      "         [-1.7768,  2.1678,  0.9990,  ..., -1.4487,  3.0249,  0.5996],\n",
      "         ...,\n",
      "         [-0.3850,  2.9821,  0.9541,  ..., -1.5989,  2.1876, -0.1043],\n",
      "         [-0.7865,  3.3147,  0.8941,  ..., -0.4894,  1.3816, -1.4399],\n",
      "         [-2.0074,  4.1695, -0.7580,  ..., -1.1101,  2.2020, -1.7946]],\n",
      "\n",
      "        [[-2.2643,  2.0211,  0.0905,  ...,  1.4944,  2.7525, -0.0729],\n",
      "         [-1.8158,  2.8813, -0.3181,  ..., -0.7023,  2.8204,  0.2125],\n",
      "         [-1.7211,  1.2564,  0.6263,  ..., -1.5685,  3.8340, -2.2644],\n",
      "         ...,\n",
      "         [ 0.1543,  1.4052,  0.8349,  ..., -2.2239,  3.6291, -1.5159],\n",
      "         [-0.6063,  2.1423,  1.3671,  ..., -1.7154,  2.8632, -0.6273],\n",
      "         [-1.4182,  2.5588, -0.9420,  ..., -1.3524,  3.2226, -1.0824]],\n",
      "\n",
      "        [[-0.6904,  4.1306,  0.1093,  ...,  0.3222,  4.1613, -0.5415],\n",
      "         [-1.4045,  3.7203,  1.1589,  ..., -0.8907,  3.4803,  0.4057],\n",
      "         [-0.5525,  2.7268,  1.8121,  ..., -1.1109,  3.9658, -0.9054],\n",
      "         ...,\n",
      "         [ 1.3376,  2.8173,  1.9098,  ...,  1.0595,  0.2937, -0.6565],\n",
      "         [ 0.4482,  3.8581,  0.8859,  ..., -0.9172,  3.0093, -0.3230],\n",
      "         [-0.1353,  2.2681, -0.0274,  ..., -1.2634,  2.8043, -1.7866]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.5970,  3.4949, -0.8841,  ..., -0.6302, -0.1536,  0.1838],\n",
      "         [-1.6975,  4.1341, -0.3460,  ..., -1.9250,  2.0582,  0.0232],\n",
      "         [-2.0420,  1.0216,  0.6705,  ..., -1.4748,  2.7135,  1.3258],\n",
      "         ...,\n",
      "         [ 0.7301,  3.2051,  0.5870,  ..., -0.0576,  1.9773, -1.3798],\n",
      "         [-0.3664,  3.8672,  0.4437,  ..., -1.6383,  2.5411, -0.5962],\n",
      "         [-0.8307,  3.6570, -0.9611,  ..., -1.8307,  2.7705, -1.3219]],\n",
      "\n",
      "        [[-2.0864,  3.6579, -0.8023,  ..., -2.2612,  1.5906, -0.1952],\n",
      "         [-1.3348,  3.1873, -0.1704,  ...,  0.2046,  2.6292,  0.0125],\n",
      "         [ 0.1850,  3.0093, -1.0630,  ..., -1.3732,  3.8303, -0.0364],\n",
      "         ...,\n",
      "         [-0.5735,  2.3561,  1.0338,  ..., -2.1643,  2.2980, -0.9996],\n",
      "         [-0.4216,  2.5655,  0.2303,  ..., -1.1014,  3.0475, -1.3511],\n",
      "         [-1.6446,  3.2821, -0.6657,  ..., -0.1882,  2.3933, -0.7922]],\n",
      "\n",
      "        [[-2.3041,  2.6648, -1.5167,  ..., -1.2287,  1.7145, -0.2026],\n",
      "         [-0.7681,  3.3567, -1.2192,  ..., -1.7652,  1.2026, -0.6273],\n",
      "         [-1.0284,  1.6841, -0.1389,  ..., -1.2870,  3.7302, -0.3676],\n",
      "         ...,\n",
      "         [-0.6717,  2.4340,  0.4445,  ..., -1.8608,  2.7264, -2.1682],\n",
      "         [-0.5444,  4.3116,  0.3193,  ..., -0.5872,  0.9603, -2.2053],\n",
      "         [-1.5113,  2.6121, -0.4944,  ..., -1.1926,  2.1259, -1.8312]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 86, 64]) , torch.Size([512, 8, 86, 64]), torch.Size([512, 8, 86, 64])\n",
      "Score shape -- torch.Size([512, 8, 86, 86])\n",
      "Mask ---> torch.Size([512, 1, 86])\n",
      "Mask new --> torch.Size([512, 1, 1, 86])\n",
      "loop within encoder. Iteration -- 2\n",
      "this is x in EncoderLayer-----> tensor([[[-2.0316e+00,  3.5005e+00, -2.2128e-01,  ...,  1.1462e-01,\n",
      "           1.1863e+00, -3.0005e+00],\n",
      "         [-4.9837e-01,  5.6812e+00, -1.0985e+00,  ..., -4.2968e+00,\n",
      "           1.7931e+00, -2.5892e+00],\n",
      "         [-1.4153e+00,  3.8224e+00,  1.7933e-01,  ..., -3.8981e+00,\n",
      "           2.4583e+00, -2.2093e-01],\n",
      "         ...,\n",
      "         [-5.7911e-01,  4.7085e+00,  2.0488e-01,  ..., -3.9183e+00,\n",
      "           1.8028e+00, -1.5705e+00],\n",
      "         [-6.9561e-01,  4.9688e+00,  1.0569e-01,  ..., -2.4402e+00,\n",
      "           2.3169e-01, -3.0089e+00],\n",
      "         [-1.8460e+00,  5.7032e+00, -1.8515e+00,  ..., -3.0403e+00,\n",
      "           1.1858e+00, -2.8055e+00]],\n",
      "\n",
      "        [[-1.1250e+00,  3.7216e+00, -1.0692e-01,  ..., -9.7649e-01,\n",
      "           2.1621e+00, -2.1044e+00],\n",
      "         [-8.7656e-01,  4.3577e+00, -1.2133e+00,  ..., -2.6532e+00,\n",
      "           1.9111e+00, -1.6858e+00],\n",
      "         [-1.2728e+00,  2.7810e+00, -4.3665e-01,  ..., -3.6443e+00,\n",
      "           3.3023e+00, -4.4493e+00],\n",
      "         ...,\n",
      "         [ 1.5133e-01,  3.4897e+00,  1.0985e+00,  ..., -4.6137e+00,\n",
      "           3.0779e+00, -2.6928e+00],\n",
      "         [ 3.7185e-01,  1.7538e+00,  3.6659e-01,  ..., -3.7378e+00,\n",
      "           2.2078e+00, -1.6802e+00],\n",
      "         [-4.2230e-01,  4.6949e+00, -1.6318e+00,  ..., -3.5426e+00,\n",
      "           3.0806e+00, -2.0627e+00]],\n",
      "\n",
      "        [[-5.7677e-03,  6.4497e+00, -5.5852e-01,  ..., -1.9312e+00,\n",
      "           3.9950e+00, -2.7217e+00],\n",
      "         [-2.2429e-01,  5.7959e+00, -8.3036e-02,  ..., -4.0593e+00,\n",
      "           1.7334e+00, -1.7651e+00],\n",
      "         [-2.2882e-01,  5.1657e+00,  1.3396e+00,  ..., -3.5033e+00,\n",
      "           3.3206e+00, -3.9836e+00],\n",
      "         ...,\n",
      "         [ 1.6692e+00,  5.0556e+00,  9.4619e-01,  ..., -1.7022e+00,\n",
      "          -2.1100e-01, -1.8308e+00],\n",
      "         [ 1.3451e+00,  5.7903e+00,  1.7686e-01,  ..., -3.3297e+00,\n",
      "           1.8177e+00, -1.6309e+00],\n",
      "         [ 2.3022e-01,  3.7571e+00, -8.7429e-01,  ..., -4.4261e+00,\n",
      "           2.5582e+00, -2.9671e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.6952e+00,  5.6161e+00, -1.9317e+00,  ..., -3.0021e+00,\n",
      "          -9.2756e-02, -1.3499e+00],\n",
      "         [-1.1597e+00,  5.4324e+00, -7.1060e-01,  ..., -3.8350e+00,\n",
      "           1.3369e+00, -1.4068e+00],\n",
      "         [-1.3699e+00,  3.1273e+00,  1.4240e-01,  ..., -4.6809e+00,\n",
      "           2.1353e+00, -5.7316e-01],\n",
      "         ...,\n",
      "         [ 3.6557e-01,  5.8477e+00, -4.4101e-01,  ..., -2.6999e+00,\n",
      "           1.3343e+00, -2.6869e+00],\n",
      "         [-6.1148e-01,  6.1025e+00, -7.1059e-01,  ..., -1.7256e+00,\n",
      "           1.8476e+00, -1.9871e+00],\n",
      "         [-2.3229e-01,  5.5309e+00, -2.0106e+00,  ..., -4.1684e+00,\n",
      "           2.1593e+00, -2.8140e+00]],\n",
      "\n",
      "        [[-1.5885e+00,  5.0296e+00, -1.5988e+00,  ..., -4.6553e+00,\n",
      "           9.1213e-01, -1.4091e+00],\n",
      "         [-1.0841e+00,  5.5205e+00, -9.9802e-01,  ..., -1.7229e+00,\n",
      "           1.6259e+00, -1.9470e+00],\n",
      "         [ 1.0013e+00,  3.2624e+00, -1.8367e+00,  ..., -2.6268e+00,\n",
      "           3.5164e+00, -1.9707e+00],\n",
      "         ...,\n",
      "         [-4.8702e-01,  2.1756e+00, -2.5095e-01,  ..., -4.0593e+00,\n",
      "           1.5913e+00, -2.8210e+00],\n",
      "         [-2.3982e-01,  4.3072e+00, -8.0284e-01,  ..., -3.3404e+00,\n",
      "           2.2277e+00, -2.5434e+00],\n",
      "         [-1.6993e+00,  5.1735e+00, -1.3712e+00,  ..., -2.1658e+00,\n",
      "           1.4048e+00, -2.3473e+00]],\n",
      "\n",
      "        [[-2.1839e+00,  5.6492e+00, -2.2454e+00,  ..., -3.7348e+00,\n",
      "           1.0047e+00, -1.3521e+00],\n",
      "         [-5.4062e-01,  5.6589e+00, -1.3945e+00,  ..., -4.2241e+00,\n",
      "           8.6885e-01, -1.7668e+00],\n",
      "         [-5.7945e-01,  4.4341e+00, -4.4559e-01,  ..., -4.2025e+00,\n",
      "           2.5881e+00, -9.1929e-01],\n",
      "         ...,\n",
      "         [ 6.7035e-01,  4.9181e+00, -4.4668e-01,  ..., -3.8105e+00,\n",
      "           1.9856e+00, -3.1689e+00],\n",
      "         [-6.4436e-01,  7.3764e+00, -6.7399e-01,  ..., -4.2330e-01,\n",
      "           5.5290e-02, -3.3717e+00],\n",
      "         [-1.5582e+00,  5.0071e+00, -1.4230e+00,  ..., -3.2900e+00,\n",
      "           1.7182e+00, -3.1385e+00]]], grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 86, 64]) , torch.Size([512, 8, 86, 64]), torch.Size([512, 8, 86, 64])\n",
      "Score shape -- torch.Size([512, 8, 86, 86])\n",
      "Mask ---> torch.Size([512, 1, 86])\n",
      "Mask new --> torch.Size([512, 1, 1, 86])\n",
      "loop within encoder. Iteration -- 3\n",
      "this is x in EncoderLayer-----> tensor([[[-2.0316e+00,  4.8818e+00, -5.5932e-01,  ..., -3.7592e+00,\n",
      "          -7.4691e-01, -4.0094e+00],\n",
      "         [ 4.4322e-01,  7.5461e+00, -9.0498e-01,  ..., -7.4953e+00,\n",
      "           5.5270e-01, -3.0645e+00],\n",
      "         [-1.0140e+00,  5.1847e+00,  1.7279e-01,  ..., -7.4013e+00,\n",
      "           2.3402e+00, -1.5012e+00],\n",
      "         ...,\n",
      "         [ 1.1545e-01,  5.1250e+00,  1.9390e-01,  ..., -4.6779e+00,\n",
      "          -4.5981e-01, -3.2685e+00],\n",
      "         [-1.5026e-01,  6.6778e+00, -3.7688e-01,  ..., -5.7626e+00,\n",
      "          -1.3128e+00, -4.4564e+00],\n",
      "         [-1.0654e+00,  7.4203e+00, -1.7795e+00,  ..., -5.5574e+00,\n",
      "          -5.5758e-01, -4.0054e+00]],\n",
      "\n",
      "        [[-1.0412e+00,  5.7306e+00, -5.2803e-01,  ..., -3.5871e+00,\n",
      "           1.3166e-02, -3.5244e+00],\n",
      "         [-8.7947e-01,  5.4048e+00, -9.8541e-01,  ..., -3.2902e+00,\n",
      "           2.6016e-01, -2.7700e+00],\n",
      "         [-5.5885e-01,  4.1235e+00, -7.3966e-01,  ..., -6.8671e+00,\n",
      "           1.6069e+00, -5.7205e+00],\n",
      "         ...,\n",
      "         [ 8.3036e-01,  5.4589e+00,  1.1471e+00,  ..., -8.3299e+00,\n",
      "           9.9193e-01, -4.2574e+00],\n",
      "         [ 6.2966e-01,  3.5170e+00,  5.6966e-01,  ..., -7.1309e+00,\n",
      "           1.9430e+00, -2.8297e+00],\n",
      "         [-5.5337e-02,  5.9508e+00, -1.5314e+00,  ..., -6.9204e+00,\n",
      "           9.4988e-01, -2.9846e+00]],\n",
      "\n",
      "        [[-9.4674e-02,  7.5067e+00,  5.0558e-02,  ..., -5.1242e+00,\n",
      "           2.0688e+00, -3.9398e+00],\n",
      "         [ 4.4766e-01,  7.3725e+00,  9.1163e-01,  ..., -6.7871e+00,\n",
      "          -4.9901e-01, -2.2497e+00],\n",
      "         [ 4.9011e-01,  5.3757e+00,  1.8091e+00,  ..., -7.0071e+00,\n",
      "           1.2886e+00, -3.9836e+00],\n",
      "         ...,\n",
      "         [ 2.4341e+00,  5.5987e+00,  9.0125e-01,  ..., -5.0103e+00,\n",
      "          -1.5529e+00, -3.2635e+00],\n",
      "         [ 1.9387e+00,  6.2493e+00,  8.9966e-01,  ..., -6.8998e+00,\n",
      "           1.9932e-03, -3.2473e+00],\n",
      "         [ 6.4460e-01,  5.8381e+00, -4.5977e-01,  ..., -7.4740e+00,\n",
      "          -2.3786e-01, -4.7371e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.9206e+00,  6.6442e+00, -1.9900e+00,  ..., -6.0197e+00,\n",
      "          -1.6941e+00, -2.1299e+00],\n",
      "         [-5.0966e-01,  7.1753e+00, -5.6130e-01,  ..., -6.9229e+00,\n",
      "           1.0736e+00, -2.7988e+00],\n",
      "         [-5.1533e-01,  5.1404e+00, -8.8527e-02,  ..., -7.7378e+00,\n",
      "           2.0121e+00, -2.1209e+00],\n",
      "         ...,\n",
      "         [ 1.4554e+00,  7.0404e+00, -4.7410e-02,  ..., -5.0611e+00,\n",
      "          -6.4869e-01, -3.0156e+00],\n",
      "         [ 3.0950e-01,  7.8147e+00, -6.7154e-01,  ..., -4.2643e+00,\n",
      "           2.6898e-01, -2.8285e+00],\n",
      "         [ 7.7318e-01,  7.1879e+00, -1.9242e+00,  ..., -8.0084e+00,\n",
      "           4.8141e-01, -4.0271e+00]],\n",
      "\n",
      "        [[-1.2980e+00,  6.7705e+00, -2.0945e+00,  ..., -7.5501e+00,\n",
      "           1.1696e+00, -2.7167e+00],\n",
      "         [-7.9060e-01,  6.4663e+00, -1.2612e+00,  ..., -4.6936e+00,\n",
      "          -2.3981e-02, -3.3459e+00],\n",
      "         [ 1.6807e+00,  4.2361e+00, -1.1905e+00,  ..., -2.6268e+00,\n",
      "           1.2030e+00, -2.9967e+00],\n",
      "         ...,\n",
      "         [-2.5928e-01,  3.8767e+00,  2.4291e-01,  ..., -7.3339e+00,\n",
      "          -3.9769e-01, -3.9876e+00],\n",
      "         [ 4.3823e-01,  5.6790e+00, -9.5131e-01,  ..., -6.6933e+00,\n",
      "           2.1958e-01, -3.9788e+00],\n",
      "         [-1.0119e+00,  6.8448e+00, -9.9121e-01,  ..., -5.0612e+00,\n",
      "           1.4396e+00, -3.0257e+00]],\n",
      "\n",
      "        [[-1.6675e+00,  7.5923e+00, -2.2152e+00,  ..., -4.4076e+00,\n",
      "          -1.4899e+00, -3.2967e+00],\n",
      "         [-1.4486e-03,  6.6682e+00, -1.5040e+00,  ..., -7.3502e+00,\n",
      "          -1.3791e+00, -2.9642e+00],\n",
      "         [ 2.8748e-01,  6.3672e+00, -6.2437e-01,  ..., -7.4229e+00,\n",
      "           8.3990e-01, -3.2506e+00],\n",
      "         ...,\n",
      "         [ 1.0396e+00,  6.4752e+00, -3.2815e-01,  ..., -7.2774e+00,\n",
      "           1.4599e-01, -4.5576e+00],\n",
      "         [ 5.6176e-02,  9.2208e+00, -3.5228e-01,  ..., -1.4296e+00,\n",
      "           1.5550e-01, -4.9479e+00],\n",
      "         [-8.5267e-01,  6.3664e+00, -1.2723e+00,  ..., -5.5637e+00,\n",
      "          -8.7482e-01, -4.6108e+00]]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 86, 64]) , torch.Size([512, 8, 86, 64]), torch.Size([512, 8, 86, 64])\n",
      "Score shape -- torch.Size([512, 8, 86, 86])\n",
      "Mask ---> torch.Size([512, 1, 86])\n",
      "Mask new --> torch.Size([512, 1, 1, 86])\n",
      "loop within encoder. Iteration -- 4\n",
      "this is x in EncoderLayer-----> tensor([[[-2.8716e+00,  5.5103e+00, -3.0064e+00,  ..., -3.5344e+00,\n",
      "          -1.9971e+00, -7.2000e+00],\n",
      "         [-5.5943e-01,  9.0508e+00, -2.9907e+00,  ..., -7.8927e+00,\n",
      "           1.1162e-01, -6.2085e+00],\n",
      "         [-1.9651e+00,  7.3072e+00, -2.0956e+00,  ..., -7.8737e+00,\n",
      "           1.7796e+00, -5.2073e+00],\n",
      "         ...,\n",
      "         [-2.7060e-01,  6.9442e+00, -2.0952e+00,  ..., -4.4289e+00,\n",
      "           3.3677e-01, -4.6016e+00],\n",
      "         [-6.2382e-01,  8.9369e+00, -2.8345e+00,  ..., -6.0939e+00,\n",
      "          -2.9148e+00, -6.5951e+00],\n",
      "         [-1.7327e+00,  9.3810e+00, -4.5499e+00,  ..., -5.9721e+00,\n",
      "          -1.3991e+00, -7.0934e+00]],\n",
      "\n",
      "        [[-1.2907e+00,  8.1314e+00, -3.1882e+00,  ..., -3.4846e+00,\n",
      "          -9.3236e-01, -6.3303e+00],\n",
      "         [-3.8586e-01,  7.7934e+00, -3.1266e+00,  ..., -3.1510e+00,\n",
      "          -6.8861e-01, -4.7505e+00],\n",
      "         [-1.1122e+00,  6.2293e+00, -3.5197e+00,  ..., -7.3316e+00,\n",
      "           9.7589e-01, -8.5758e+00],\n",
      "         ...,\n",
      "         [ 2.0416e-01,  7.2013e+00, -1.5186e+00,  ..., -8.2602e+00,\n",
      "           2.4067e-01, -7.2264e+00],\n",
      "         [-6.6316e-01,  5.2826e+00, -2.0966e+00,  ..., -7.9230e+00,\n",
      "           5.9669e-01, -4.7724e+00],\n",
      "         [-4.2863e-01,  8.1296e+00, -3.9360e+00,  ..., -6.9496e+00,\n",
      "          -9.3588e-01, -6.0174e+00]],\n",
      "\n",
      "        [[-5.4774e-01,  9.2987e+00, -2.1607e+00,  ..., -5.8298e+00,\n",
      "           1.1008e+00, -6.8990e+00],\n",
      "         [-6.7457e-01,  8.7656e+00, -1.3573e+00,  ..., -6.8776e+00,\n",
      "          -1.3449e+00, -4.8727e+00],\n",
      "         [-1.5867e-01,  7.3955e+00, -1.8511e-01,  ..., -7.6827e+00,\n",
      "           1.2886e+00, -6.3382e+00],\n",
      "         ...,\n",
      "         [ 1.3095e+00,  7.5273e+00, -1.2619e+00,  ..., -5.1344e+00,\n",
      "          -2.4539e+00, -5.7484e+00],\n",
      "         [ 1.2290e+00,  8.3080e+00, -1.3527e+00,  ..., -7.1239e+00,\n",
      "          -1.3721e+00, -5.9611e+00],\n",
      "         [-3.5602e-01,  7.6685e+00, -3.2111e+00,  ..., -8.0850e+00,\n",
      "          -1.1449e+00, -7.4746e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.7346e+00,  8.8231e+00, -4.3071e+00,  ..., -6.5216e+00,\n",
      "          -1.8996e+00, -4.8516e+00],\n",
      "         [-1.1900e+00,  9.8326e+00, -5.3619e-01,  ..., -7.1648e+00,\n",
      "           2.7584e-01, -5.7481e+00],\n",
      "         [-1.2592e+00,  7.3778e+00, -2.3934e+00,  ..., -8.0594e+00,\n",
      "           1.2444e+00, -5.0672e+00],\n",
      "         ...,\n",
      "         [ 2.3979e-01,  8.9886e+00, -2.2702e+00,  ..., -5.5792e+00,\n",
      "          -1.7547e+00, -4.9756e+00],\n",
      "         [-1.0943e-01,  1.0021e+01, -2.7774e+00,  ..., -4.7202e+00,\n",
      "          -4.7436e-01, -5.7863e+00],\n",
      "         [-3.0586e-01,  8.9984e+00, -3.9495e+00,  ..., -8.8261e+00,\n",
      "          -3.7337e-01, -6.9582e+00]],\n",
      "\n",
      "        [[-2.1415e+00,  7.6476e+00, -4.0625e+00,  ..., -7.4503e+00,\n",
      "          -6.3775e-02, -6.3626e+00],\n",
      "         [-2.2768e+00,  8.3208e+00, -3.9914e+00,  ..., -5.2507e+00,\n",
      "          -1.0217e+00, -6.0362e+00],\n",
      "         [ 4.0099e-01,  6.2900e+00, -2.9534e+00,  ..., -2.7103e+00,\n",
      "          -3.4797e-03, -5.8242e+00],\n",
      "         ...,\n",
      "         [-1.2843e+00,  5.8072e+00, -2.4896e+00,  ..., -7.8384e+00,\n",
      "          -1.8357e+00, -6.8405e+00],\n",
      "         [-3.0015e-01,  7.4774e+00, -3.6725e+00,  ..., -7.3892e+00,\n",
      "          -8.2143e-01, -7.0048e+00],\n",
      "         [-1.7775e+00,  8.8451e+00, -3.3975e+00,  ..., -5.6101e+00,\n",
      "           1.7949e-01, -5.7118e+00]],\n",
      "\n",
      "        [[-2.9354e+00,  8.2276e+00, -4.6292e+00,  ..., -4.6658e+00,\n",
      "          -2.4976e+00, -6.8114e+00],\n",
      "         [ 7.3901e-01,  8.6455e+00, -3.4348e+00,  ..., -7.3938e+00,\n",
      "          -2.6078e+00, -5.9149e+00],\n",
      "         [-8.7889e-01,  8.2413e+00, -2.3701e+00,  ..., -7.4661e+00,\n",
      "          -1.0440e+00, -5.1832e+00],\n",
      "         ...,\n",
      "         [-1.3281e-01,  8.3755e+00, -2.4066e+00,  ..., -7.5767e+00,\n",
      "           1.0814e+00, -7.5058e+00],\n",
      "         [-2.6268e-01,  1.0940e+01, -4.0100e-01,  ..., -1.7560e+00,\n",
      "          -8.0185e-01, -7.7655e+00],\n",
      "         [-1.0484e+00,  7.7824e+00, -3.2834e+00,  ..., -5.5637e+00,\n",
      "          -1.8728e+00, -7.6615e+00]]], grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 86, 64]) , torch.Size([512, 8, 86, 64]), torch.Size([512, 8, 86, 64])\n",
      "Score shape -- torch.Size([512, 8, 86, 86])\n",
      "Mask ---> torch.Size([512, 1, 86])\n",
      "Mask new --> torch.Size([512, 1, 1, 86])\n",
      "loop within encoder. Iteration -- 5\n",
      "this is x in EncoderLayer-----> tensor([[[-2.5568e+00,  4.0714e+00, -1.2131e+00,  ..., -5.3409e+00,\n",
      "          -1.9971e+00, -5.3628e+00],\n",
      "         [ 3.6321e-01,  8.2342e+00, -1.2662e+00,  ..., -1.0327e+01,\n",
      "           7.1383e-01, -4.2679e+00],\n",
      "         [-8.8340e-01,  6.9151e+00, -1.2412e-01,  ..., -9.7457e+00,\n",
      "           2.7486e+00, -3.5923e+00],\n",
      "         ...,\n",
      "         [-7.6987e-02,  6.2499e+00, -4.1029e-01,  ..., -4.8171e+00,\n",
      "           7.9873e-04, -2.4736e+00],\n",
      "         [-3.3054e-01,  8.5979e+00, -6.7302e-01,  ..., -7.5764e+00,\n",
      "          -3.1891e+00, -5.1526e+00],\n",
      "         [-8.5001e-01,  8.6120e+00, -2.5317e+00,  ..., -7.3537e+00,\n",
      "          -1.4174e+00, -6.1811e+00]],\n",
      "\n",
      "        [[-3.7904e-01,  8.0807e+00, -1.2801e+00,  ..., -5.5962e+00,\n",
      "          -1.3973e+00, -4.3979e+00],\n",
      "         [ 6.4064e-01,  7.3154e+00, -1.2962e+00,  ..., -5.3476e+00,\n",
      "          -1.0269e+00, -3.2292e+00],\n",
      "         [ 3.4472e-01,  5.8035e+00, -2.1295e+00,  ..., -9.9339e+00,\n",
      "           5.8852e-01, -6.5769e+00],\n",
      "         ...,\n",
      "         [ 4.8286e-01,  6.7241e+00,  3.4461e-01,  ..., -9.7646e+00,\n",
      "          -6.4504e-03, -6.6345e+00],\n",
      "         [-6.0182e-01,  4.9156e+00, -5.8198e-01,  ..., -1.0235e+01,\n",
      "          -9.6616e-02, -3.6193e+00],\n",
      "         [ 2.8962e-01,  8.2174e+00, -2.3316e+00,  ..., -7.5475e+00,\n",
      "          -9.6529e-01, -4.5981e+00]],\n",
      "\n",
      "        [[ 7.8350e-01,  8.1522e+00, -3.7916e-01,  ..., -7.8848e+00,\n",
      "           1.3587e+00, -4.4442e+00],\n",
      "         [ 4.4053e-01,  7.8703e+00,  1.4615e-01,  ..., -8.9410e+00,\n",
      "          -6.4110e-01, -2.6750e+00],\n",
      "         [ 6.2588e-01,  6.7349e+00,  1.5458e+00,  ..., -1.0221e+01,\n",
      "           1.8356e+00, -4.2354e+00],\n",
      "         ...,\n",
      "         [ 1.8518e+00,  6.4211e+00,  8.8856e-01,  ..., -7.5039e+00,\n",
      "          -2.3445e+00, -5.0961e+00],\n",
      "         [ 2.0007e+00,  7.0641e+00,  4.5604e-01,  ..., -9.0953e+00,\n",
      "          -9.8799e-01, -3.3764e+00],\n",
      "         [ 6.3753e-01,  6.3881e+00, -1.7617e+00,  ..., -1.0026e+01,\n",
      "           6.1211e-02, -5.9406e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.3209e+00,  7.9159e+00, -2.5988e+00,  ..., -8.5630e+00,\n",
      "          -1.8832e+00, -3.3532e+00],\n",
      "         [-3.1205e-01,  8.8165e+00,  1.5081e+00,  ..., -9.7732e+00,\n",
      "           1.8661e-01, -4.0586e+00],\n",
      "         [-1.0251e-01,  7.4135e+00, -3.3788e-01,  ..., -1.0446e+01,\n",
      "           1.2818e+00, -4.5644e+00],\n",
      "         ...,\n",
      "         [ 1.3187e+00,  8.0372e+00, -4.5618e-02,  ..., -7.8254e+00,\n",
      "          -1.8118e+00, -3.7850e+00],\n",
      "         [ 4.6319e-01,  9.1507e+00, -7.9779e-01,  ..., -6.7206e+00,\n",
      "          -4.9634e-01, -5.2389e+00],\n",
      "         [ 5.0427e-01,  8.3982e+00, -1.5205e+00,  ..., -1.1201e+01,\n",
      "          -7.5994e-01, -6.0646e+00]],\n",
      "\n",
      "        [[-1.4740e+00,  6.6941e+00, -2.2871e+00,  ..., -9.4485e+00,\n",
      "          -5.1282e-01, -4.4166e+00],\n",
      "         [-2.1206e+00,  8.9417e+00, -2.0616e+00,  ..., -5.7893e+00,\n",
      "          -1.0237e+00, -4.2026e+00],\n",
      "         [ 1.3428e+00,  5.2545e+00, -7.5591e-01,  ..., -4.8524e+00,\n",
      "          -1.0162e+00, -5.3019e+00],\n",
      "         ...,\n",
      "         [-8.9729e-01,  4.9355e+00, -2.3809e-01,  ..., -1.0240e+01,\n",
      "          -2.5115e+00, -5.6395e+00],\n",
      "         [ 3.3658e-01,  6.5611e+00, -1.5852e+00,  ..., -7.3489e+00,\n",
      "          -1.4335e+00, -5.4312e+00],\n",
      "         [-9.9242e-01,  8.0866e+00, -2.1800e+00,  ..., -7.5986e+00,\n",
      "           7.7257e-01, -4.1388e+00]],\n",
      "\n",
      "        [[-2.3044e+00,  7.8102e+00, -2.7238e+00,  ..., -6.8177e+00,\n",
      "          -2.6865e+00, -6.1206e+00],\n",
      "         [ 1.1172e+00,  8.1479e+00, -1.1872e+00,  ..., -8.1196e+00,\n",
      "          -2.8723e+00, -4.1640e+00],\n",
      "         [-2.1485e-01,  8.1315e+00, -8.3147e-01,  ..., -9.6407e+00,\n",
      "          -1.3821e+00, -2.9849e+00],\n",
      "         ...,\n",
      "         [ 4.7008e-01,  7.7724e+00, -8.3881e-01,  ..., -9.2907e+00,\n",
      "           9.2495e-01, -5.5415e+00],\n",
      "         [ 3.4800e-02,  1.0403e+01,  1.4461e+00,  ..., -3.7809e+00,\n",
      "          -1.5861e+00, -5.9330e+00],\n",
      "         [-9.7680e-01,  7.2014e+00, -1.3617e+00,  ..., -7.0716e+00,\n",
      "          -2.7003e+00, -6.2493e+00]]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 86, 64]) , torch.Size([512, 8, 86, 64]), torch.Size([512, 8, 86, 64])\n",
      "Score shape -- torch.Size([512, 8, 86, 86])\n",
      "Mask ---> torch.Size([512, 1, 86])\n",
      "Mask new --> torch.Size([512, 1, 1, 86])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 92])\n",
      "Mask ---> torch.Size([512, 92, 92])\n",
      "Mask new --> torch.Size([512, 1, 92, 92])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 86, 64]), torch.Size([512, 8, 86, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 86])\n",
      "Mask ---> torch.Size([512, 1, 86])\n",
      "Mask new --> torch.Size([512, 1, 1, 86])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 92])\n",
      "Mask ---> torch.Size([512, 92, 92])\n",
      "Mask new --> torch.Size([512, 1, 92, 92])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 86, 64]), torch.Size([512, 8, 86, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 86])\n",
      "Mask ---> torch.Size([512, 1, 86])\n",
      "Mask new --> torch.Size([512, 1, 1, 86])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 92])\n",
      "Mask ---> torch.Size([512, 92, 92])\n",
      "Mask new --> torch.Size([512, 1, 92, 92])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 86, 64]), torch.Size([512, 8, 86, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 86])\n",
      "Mask ---> torch.Size([512, 1, 86])\n",
      "Mask new --> torch.Size([512, 1, 1, 86])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 92])\n",
      "Mask ---> torch.Size([512, 92, 92])\n",
      "Mask new --> torch.Size([512, 1, 92, 92])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 86, 64]), torch.Size([512, 8, 86, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 86])\n",
      "Mask ---> torch.Size([512, 1, 86])\n",
      "Mask new --> torch.Size([512, 1, 1, 86])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 92])\n",
      "Mask ---> torch.Size([512, 92, 92])\n",
      "Mask new --> torch.Size([512, 1, 92, 92])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 86, 64]), torch.Size([512, 8, 86, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 86])\n",
      "Mask ---> torch.Size([512, 1, 86])\n",
      "Mask new --> torch.Size([512, 1, 1, 86])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 92, 64]), torch.Size([512, 8, 92, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 92])\n",
      "Mask ---> torch.Size([512, 92, 92])\n",
      "Mask new --> torch.Size([512, 1, 92, 92])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 92, 64]) , torch.Size([512, 8, 86, 64]), torch.Size([512, 8, 86, 64])\n",
      "Score shape -- torch.Size([512, 8, 92, 86])\n",
      "Mask ---> torch.Size([512, 1, 86])\n",
      "Mask new --> torch.Size([512, 1, 1, 86])\n",
      "predictions size : tensor([[-0.7856, -0.7394, -0.2561,  ..., -0.4631, -0.7314, -0.0769],\n",
      "        [-0.7484, -0.7010, -0.4223,  ..., -0.6058, -0.7161, -0.2416],\n",
      "        [-0.7107, -0.6641, -0.3529,  ..., -0.3909, -0.6127, -0.1714],\n",
      "        ...,\n",
      "        [-0.8209, -0.7116, -0.3508,  ..., -0.4459, -0.6074, -0.2134],\n",
      "        [-0.8260, -0.7735, -0.3675,  ..., -0.3367, -0.6901, -0.2211],\n",
      "        [-0.8611, -0.6597, -0.3427,  ..., -0.4206, -0.6456, -0.2617]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "targets size : torch.Size([47104])\n",
      "Loss.data ----> = 8.032599449157715\n",
      "--Encoder x after PE : tensor([[[ 0.2381,  0.8675,  0.2461,  ...,  0.8452, -0.0000,  1.0854],\n",
      "         [ 0.6718,  0.2340,  0.7955,  ...,  0.4836, -0.0000,  0.5309],\n",
      "         [ 0.5736, -0.5449,  0.5783,  ...,  1.1192,  0.4784,  1.0520],\n",
      "         ...,\n",
      "         [ 0.8327,  0.8847,  0.2893,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.2319,  0.5529, -0.4102,  ...,  0.0000,  0.0000,  0.5406],\n",
      "         [-0.8427, -0.0000, -0.2582,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.0686,  1.7068,  0.6376,  ...,  0.0000, -0.5733,  1.2777],\n",
      "         [ 1.3752,  0.6504,  1.0909,  ...,  1.2794, -0.4127,  0.6083],\n",
      "         [ 1.0489,  0.0237,  1.6547,  ...,  0.8239, -0.1712,  1.5432],\n",
      "         ...,\n",
      "         [ 0.8327,  0.8847,  0.2893,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.2319,  0.5529, -0.4102,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.8427, -0.0000, -0.2582,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.0000,  0.8675,  0.2461,  ...,  0.0000, -0.4542,  1.0854],\n",
      "         [ 0.6718,  0.2340,  0.7955,  ...,  0.4836, -0.6014,  0.5309],\n",
      "         [ 0.8475, -0.1122,  1.1237,  ...,  1.7394,  0.0238,  1.3547],\n",
      "         ...,\n",
      "         [ 0.8327,  0.8847,  0.2893,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.2319,  0.5529, -0.0000,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [-0.0000, -0.4381, -0.2582,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.5249,  0.6484,  0.6547,  ...,  1.1667,  0.0561,  1.1618],\n",
      "         [ 0.7879,  0.0000,  0.6345,  ...,  1.2768, -0.0461,  1.4803],\n",
      "         [ 0.0000, -0.5603,  0.9899,  ...,  1.6695,  0.4987,  1.2279],\n",
      "         ...,\n",
      "         [ 0.8327,  0.8847,  0.2893,  ...,  1.0595,  0.1775,  0.0000],\n",
      "         [-0.2319,  0.5529, -0.4102,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.8427, -0.4381, -0.2582,  ...,  0.0000,  0.1775,  0.0000]],\n",
      "\n",
      "        [[-0.5287,  0.9155,  0.4040,  ...,  0.5156, -0.6209,  0.8026],\n",
      "         [ 0.8525,  0.2104,  1.4049,  ...,  1.1829,  0.2810,  0.6269],\n",
      "         [ 1.1034, -0.3820,  1.6113,  ...,  1.3303,  0.4639,  0.5731],\n",
      "         ...,\n",
      "         [ 0.8327,  0.8847,  0.2893,  ...,  1.0595,  0.1775,  0.0000],\n",
      "         [-0.2319,  0.5529, -0.4102,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.8427, -0.4381, -0.2582,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.5287,  0.0000,  0.4040,  ...,  0.5156, -0.6209,  0.8026],\n",
      "         [ 1.5067,  0.0000,  0.6942,  ...,  1.1389, -0.2480,  0.6738],\n",
      "         [ 0.5728, -0.2019,  1.1607,  ...,  0.0000,  0.0357,  0.6599],\n",
      "         ...,\n",
      "         [ 0.0000,  0.8847,  0.2893,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.0000,  0.5529, -0.4102,  ...,  1.0595,  0.1775,  0.0000],\n",
      "         [-0.8427, -0.4381, -0.2582,  ...,  1.0595,  0.1775,  0.5406]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "loop within encoder. Iteration -- 0\n",
      "this is x in EncoderLayer-----> tensor([[[ 0.2381,  0.8675,  0.2461,  ...,  0.8452, -0.0000,  1.0854],\n",
      "         [ 0.6718,  0.2340,  0.7955,  ...,  0.4836, -0.0000,  0.5309],\n",
      "         [ 0.5736, -0.5449,  0.5783,  ...,  1.1192,  0.4784,  1.0520],\n",
      "         ...,\n",
      "         [ 0.8327,  0.8847,  0.2893,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.2319,  0.5529, -0.4102,  ...,  0.0000,  0.0000,  0.5406],\n",
      "         [-0.8427, -0.0000, -0.2582,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.0686,  1.7068,  0.6376,  ...,  0.0000, -0.5733,  1.2777],\n",
      "         [ 1.3752,  0.6504,  1.0909,  ...,  1.2794, -0.4127,  0.6083],\n",
      "         [ 1.0489,  0.0237,  1.6547,  ...,  0.8239, -0.1712,  1.5432],\n",
      "         ...,\n",
      "         [ 0.8327,  0.8847,  0.2893,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.2319,  0.5529, -0.4102,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.8427, -0.0000, -0.2582,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.0000,  0.8675,  0.2461,  ...,  0.0000, -0.4542,  1.0854],\n",
      "         [ 0.6718,  0.2340,  0.7955,  ...,  0.4836, -0.6014,  0.5309],\n",
      "         [ 0.8475, -0.1122,  1.1237,  ...,  1.7394,  0.0238,  1.3547],\n",
      "         ...,\n",
      "         [ 0.8327,  0.8847,  0.2893,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.2319,  0.5529, -0.0000,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [-0.0000, -0.4381, -0.2582,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.5249,  0.6484,  0.6547,  ...,  1.1667,  0.0561,  1.1618],\n",
      "         [ 0.7879,  0.0000,  0.6345,  ...,  1.2768, -0.0461,  1.4803],\n",
      "         [ 0.0000, -0.5603,  0.9899,  ...,  1.6695,  0.4987,  1.2279],\n",
      "         ...,\n",
      "         [ 0.8327,  0.8847,  0.2893,  ...,  1.0595,  0.1775,  0.0000],\n",
      "         [-0.2319,  0.5529, -0.4102,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.8427, -0.4381, -0.2582,  ...,  0.0000,  0.1775,  0.0000]],\n",
      "\n",
      "        [[-0.5287,  0.9155,  0.4040,  ...,  0.5156, -0.6209,  0.8026],\n",
      "         [ 0.8525,  0.2104,  1.4049,  ...,  1.1829,  0.2810,  0.6269],\n",
      "         [ 1.1034, -0.3820,  1.6113,  ...,  1.3303,  0.4639,  0.5731],\n",
      "         ...,\n",
      "         [ 0.8327,  0.8847,  0.2893,  ...,  1.0595,  0.1775,  0.0000],\n",
      "         [-0.2319,  0.5529, -0.4102,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.8427, -0.4381, -0.2582,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.5287,  0.0000,  0.4040,  ...,  0.5156, -0.6209,  0.8026],\n",
      "         [ 1.5067,  0.0000,  0.6942,  ...,  1.1389, -0.2480,  0.6738],\n",
      "         [ 0.5728, -0.2019,  1.1607,  ...,  0.0000,  0.0357,  0.6599],\n",
      "         ...,\n",
      "         [ 0.0000,  0.8847,  0.2893,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.0000,  0.5529, -0.4102,  ...,  1.0595,  0.1775,  0.0000],\n",
      "         [-0.8427, -0.4381, -0.2582,  ...,  1.0595,  0.1775,  0.5406]]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 81, 64]) , torch.Size([512, 8, 81, 64]), torch.Size([512, 8, 81, 64])\n",
      "Score shape -- torch.Size([512, 8, 81, 81])\n",
      "Mask ---> torch.Size([512, 1, 81])\n",
      "Mask new --> torch.Size([512, 1, 1, 81])\n",
      "loop within encoder. Iteration -- 1\n",
      "this is x in EncoderLayer-----> tensor([[[-2.0419,  3.9815, -0.2360,  ..., -1.1338,  1.4594, -0.2515],\n",
      "         [-1.1442,  2.8425,  0.6401,  ..., -2.8283,  3.5570, -1.1334],\n",
      "         [-1.7587,  2.3385, -0.6952,  ..., -2.4235,  4.3995, -0.3795],\n",
      "         ...,\n",
      "         [ 1.4079,  3.2096, -0.2205,  ..., -1.6534,  2.6366, -0.5810],\n",
      "         [-2.2446,  3.3128, -1.0514,  ..., -3.3716,  2.9466, -1.3682],\n",
      "         [-2.4763,  3.4620, -1.2882,  ..., -1.8136,  2.8623, -0.4536]],\n",
      "\n",
      "        [[-2.1825,  5.3771,  0.3891,  ..., -2.8643,  2.2036, -0.9574],\n",
      "         [-1.2655,  3.6055,  0.7777,  ..., -1.0037,  3.2276, -1.5651],\n",
      "         [-1.0119,  2.8212,  1.3036,  ..., -1.5994,  2.9707, -0.3736],\n",
      "         ...,\n",
      "         [-0.1609,  2.3399,  1.1191,  ..., -2.0595,  3.5570, -0.9285],\n",
      "         [-0.0928,  3.8203, -0.5541,  ...,  1.0595,  2.1034, -0.2094],\n",
      "         [-2.5001,  1.4277, -1.2126,  ..., -2.0410,  3.2448, -1.0968]],\n",
      "\n",
      "        [[-1.2633,  3.6968, -0.7441,  ..., -1.9095,  3.0083, -1.5476],\n",
      "         [-0.3367,  3.2207,  0.5582,  ..., -1.6173,  2.8684, -1.7216],\n",
      "         [-0.8439,  1.6060,  0.1235,  ..., -0.3051,  3.4797, -0.3314],\n",
      "         ...,\n",
      "         [-0.2824,  3.5712, -0.5069,  ..., -1.0450,  3.9508, -2.2846],\n",
      "         [-0.8741,  2.4145, -1.2792,  ..., -1.3157,  3.9571, -0.8059],\n",
      "         [-1.3601,  2.3534, -0.9655,  ..., -0.2375,  2.4439, -0.3093]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.1572,  2.6887,  0.3857,  ..., -1.4303,  2.3268,  0.6450],\n",
      "         [-1.6471,  2.7051,  0.0320,  ..., -1.4801,  2.3467,  0.2882],\n",
      "         [-2.1402,  2.7741,  0.6766,  ..., -0.5278,  3.1240,  0.9230],\n",
      "         ...,\n",
      "         [-1.3694,  3.5111, -0.5086,  ..., -1.7020,  2.9955, -0.9069],\n",
      "         [-0.1332,  3.7893, -0.5122,  ...,  1.0595,  2.5078, -1.2040],\n",
      "         [-3.0185,  0.8003, -0.7656,  ..., -3.6560,  1.9951, -1.8700]],\n",
      "\n",
      "        [[-3.3197,  4.0733,  0.3287,  ..., -2.5072,  1.5323,  0.2448],\n",
      "         [-1.7115,  3.2947,  1.0224,  ..., -0.7921,  1.2265, -0.8552],\n",
      "         [-1.5594,  2.4081,  0.7576,  ..., -1.3467,  3.4736, -1.0524],\n",
      "         ...,\n",
      "         [ 1.1637,  3.9414, -0.8303,  ..., -0.6452,  2.6710, -1.7034],\n",
      "         [-1.9426,  3.2273, -1.3515,  ..., -1.2133,  2.0751, -0.1804],\n",
      "         [-3.1122, -0.4381, -1.3361,  ..., -1.0249,  2.2801, -1.2520]],\n",
      "\n",
      "        [[-0.1810,  2.5746,  0.0484,  ..., -1.3287,  0.5182, -1.4070],\n",
      "         [-1.2168,  0.8424, -0.2561,  ..., -0.5877,  2.7612, -0.3601],\n",
      "         [-0.1018,  2.8919,  0.2229,  ..., -2.7745,  1.8934, -0.9911],\n",
      "         ...,\n",
      "         [-2.1765,  4.2258, -0.1773,  ..., -1.6303,  3.3689, -0.9069],\n",
      "         [-2.1507,  3.3659, -0.4926,  ..., -1.3626,  0.1775, -1.4527],\n",
      "         [-3.1294,  2.9438, -0.5736,  ..., -1.9150,  2.8624, -0.9369]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 81, 64]) , torch.Size([512, 8, 81, 64]), torch.Size([512, 8, 81, 64])\n",
      "Score shape -- torch.Size([512, 8, 81, 81])\n",
      "Mask ---> torch.Size([512, 1, 81])\n",
      "Mask new --> torch.Size([512, 1, 1, 81])\n",
      "loop within encoder. Iteration -- 2\n",
      "this is x in EncoderLayer-----> tensor([[[-2.2493,  5.5648, -1.5415,  ..., -3.5963,  1.4932, -0.7092],\n",
      "         [-0.2467,  4.6132, -0.3221,  ..., -3.4376,  2.4074, -2.8129],\n",
      "         [-1.2728,  4.6155, -1.9338,  ..., -5.0722,  4.0270, -2.0601],\n",
      "         ...,\n",
      "         [ 1.4018,  4.9958, -1.5863,  ..., -3.4857,  2.3334, -1.8601],\n",
      "         [-2.2579,  4.8510, -2.3827,  ..., -4.9150,  2.5123, -2.5498],\n",
      "         [-2.4037,  3.3722, -2.0691,  ..., -3.7258,  2.2724, -1.9748]],\n",
      "\n",
      "        [[-1.4081,  7.5188, -0.3452,  ..., -4.9108,  2.2669, -3.5754],\n",
      "         [ 0.3806,  6.0065,  0.0979,  ..., -3.6277,  2.6670, -3.4974],\n",
      "         [-0.3650,  4.2331,  1.0865,  ..., -4.0243,  2.3088, -1.9601],\n",
      "         ...,\n",
      "         [ 0.1502,  4.0776,  0.4762,  ..., -4.4810,  2.5149, -3.1795],\n",
      "         [ 0.6313,  4.4870, -1.9457,  ..., -1.4758,  1.5174, -2.4081],\n",
      "         [-1.9760,  3.2353, -2.3005,  ..., -4.5043,  3.0114, -1.6967]],\n",
      "\n",
      "        [[ 0.4309,  5.6283, -1.3586,  ..., -4.4516,  2.6615, -3.2812],\n",
      "         [ 1.6170,  4.6060,  1.0300,  ..., -3.9196,  2.4283, -3.5542],\n",
      "         [ 1.2939,  2.2477,  0.2588,  ..., -2.7401,  3.4606, -2.2816],\n",
      "         ...,\n",
      "         [ 1.0924,  4.9318, -1.1484,  ..., -3.3860,  4.3600, -3.6194],\n",
      "         [-0.0095,  4.1428, -1.1365,  ..., -3.9492,  4.4387, -1.7174],\n",
      "         [-0.1809,  4.3854, -1.8815,  ..., -0.6084,  2.0909, -1.1738]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.8303,  4.2718,  0.2820,  ..., -4.1659,  1.0533, -1.8095],\n",
      "         [-0.8857,  4.6003, -0.9751,  ..., -4.1167,  1.6734, -2.1173],\n",
      "         [-1.8711,  4.5239, -0.0935,  ..., -3.0294,  2.2273, -0.8691],\n",
      "         ...,\n",
      "         [-1.1870,  5.4379, -1.0233,  ..., -4.2198,  2.1479, -2.8666],\n",
      "         [ 0.2468,  6.0134, -0.9756,  ...,  0.9184,  1.8508, -2.3904],\n",
      "         [-2.7563,  3.5070, -0.6931,  ..., -5.6909,  1.4057, -2.7005]],\n",
      "\n",
      "        [[-2.7048,  5.9535, -0.3466,  ..., -5.6027,  0.3330, -1.5587],\n",
      "         [-1.4837,  3.5758,  0.8108,  ..., -3.3705, -0.2251, -3.4134],\n",
      "         [-1.5949,  4.2118,  0.2537,  ..., -3.9312,  2.6329, -3.7586],\n",
      "         ...,\n",
      "         [ 1.4760,  6.1361, -1.5421,  ..., -0.6449,  2.0799, -3.6413],\n",
      "         [-2.2200,  5.1432, -2.0771,  ..., -4.0723,  0.9891, -1.5763],\n",
      "         [-2.6453,  1.3526, -2.8010,  ..., -3.9629,  1.3943, -3.6566]],\n",
      "\n",
      "        [[-0.0637,  4.5130, -0.6717,  ..., -3.3334, -0.7717, -2.9599],\n",
      "         [-1.4630,  1.6474, -1.1283,  ..., -2.8585,  1.8172, -1.7853],\n",
      "         [-0.0319,  5.8708, -0.8004,  ..., -4.5114,  1.6855, -1.7347],\n",
      "         ...,\n",
      "         [-2.3463,  7.1007, -0.9276,  ..., -3.5115,  2.6444, -1.7698],\n",
      "         [-2.2319,  5.7223, -1.2449,  ..., -3.3930, -0.3265, -2.9069],\n",
      "         [-3.6057,  5.5551, -1.6806,  ..., -3.9751,  2.1483, -2.4074]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 81, 64]) , torch.Size([512, 8, 81, 64]), torch.Size([512, 8, 81, 64])\n",
      "Score shape -- torch.Size([512, 8, 81, 81])\n",
      "Mask ---> torch.Size([512, 1, 81])\n",
      "Mask new --> torch.Size([512, 1, 1, 81])\n",
      "loop within encoder. Iteration -- 3\n",
      "this is x in EncoderLayer-----> tensor([[[-1.3460,  7.6753, -1.4554,  ..., -5.9559,  1.4932, -2.6482],\n",
      "         [-0.1420,  6.1368, -0.3201,  ..., -6.6873,  0.4612, -4.1033],\n",
      "         [-0.9909,  6.5150, -2.0833,  ..., -8.0455,  1.6567, -3.1267],\n",
      "         ...,\n",
      "         [ 1.9004,  6.7494, -1.4270,  ..., -6.7006,  0.4978, -2.8770],\n",
      "         [-1.8045,  4.8510, -2.2884,  ..., -7.8138,  0.4227, -4.0936],\n",
      "         [-2.0883,  5.3390, -1.6001,  ..., -6.5723,  0.2602, -2.9647]],\n",
      "\n",
      "        [[-0.8596,  9.0512, -0.1621,  ..., -8.3744,  0.4163, -5.1212],\n",
      "         [ 1.1816,  7.6980, -0.2684,  ..., -7.0669,  0.7483, -4.7464],\n",
      "         [ 0.3058,  6.2339,  1.2587,  ..., -7.1904,  0.3326, -3.5074],\n",
      "         ...,\n",
      "         [ 0.8287,  5.5482,  0.7681,  ..., -8.3597,  0.4241, -4.5197],\n",
      "         [ 1.2776,  6.1140, -1.6819,  ..., -5.7779, -0.6862, -3.9749],\n",
      "         [-1.9760,  5.2163, -2.3825,  ..., -7.8311,  1.0345, -2.4860]],\n",
      "\n",
      "        [[ 0.5471,  7.0481, -1.2394,  ..., -7.5274,  0.7903, -4.3800],\n",
      "         [ 2.2499,  6.2988,  1.2227,  ..., -7.1249,  0.5176, -4.0185],\n",
      "         [ 2.2367,  3.0021,  0.1332,  ..., -5.9019,  1.2146, -3.3451],\n",
      "         ...,\n",
      "         [ 2.3589,  6.8640, -1.0459,  ..., -7.0410,  2.1416, -4.4735],\n",
      "         [ 1.2644,  5.4657, -0.8935,  ..., -7.5781,  2.6432, -2.5034],\n",
      "         [-0.1063,  5.6840, -2.0966,  ..., -3.9473,  2.1799, -1.7196]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.1681,  5.6642,  0.0569,  ..., -7.2517, -0.3740, -3.4956],\n",
      "         [-0.6722,  5.5553, -0.9902,  ..., -6.4822, -0.2568, -3.9219],\n",
      "         [-1.4128,  5.9731,  0.1344,  ..., -6.1698,  1.1199, -2.8712],\n",
      "         ...,\n",
      "         [-0.8618,  7.4450, -1.5644,  ..., -7.8240,  0.0181, -4.1687],\n",
      "         [ 0.3519,  6.9988, -0.5679,  ..., -1.5933, -0.3607, -3.6664],\n",
      "         [-2.3682,  5.3148, -0.4988,  ..., -9.1105, -0.3006, -3.9836]],\n",
      "\n",
      "        [[-2.4151,  7.2953, -0.8808,  ..., -8.7968, -1.5412, -3.2575],\n",
      "         [-0.5244,  4.6270,  1.0851,  ..., -7.1282, -2.3273, -4.9982],\n",
      "         [-0.5174,  5.4556,  0.5913,  ..., -7.1306,  1.4566, -4.7179],\n",
      "         ...,\n",
      "         [ 1.9419,  8.1749, -1.9210,  ..., -3.0224,  0.5466, -4.4691],\n",
      "         [-1.7234,  7.2255, -2.4024,  ..., -6.9408, -1.7416, -2.4465],\n",
      "         [-2.3903,  3.2586, -3.4282,  ..., -7.3899, -0.9918, -4.2768]],\n",
      "\n",
      "        [[ 0.0897,  6.1760, -1.0081,  ..., -6.1369, -2.6881, -3.6597],\n",
      "         [-0.8788,  2.4915, -0.9507,  ..., -5.6958, -0.1905, -4.1889],\n",
      "         [ 0.5423,  6.0641, -0.7395,  ..., -7.1920, -0.1943, -3.9373],\n",
      "         ...,\n",
      "         [-1.9941,  8.1873, -0.8834,  ..., -6.2793, -0.0127, -3.4155],\n",
      "         [-1.7525,  7.2671, -1.0841,  ..., -6.2055, -2.6077, -4.4166],\n",
      "         [-3.1968,  6.6771, -1.4411,  ..., -6.8628, -0.2456, -3.6966]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 81, 64]) , torch.Size([512, 8, 81, 64]), torch.Size([512, 8, 81, 64])\n",
      "Score shape -- torch.Size([512, 8, 81, 81])\n",
      "Mask ---> torch.Size([512, 1, 81])\n",
      "Mask new --> torch.Size([512, 1, 1, 81])\n",
      "loop within encoder. Iteration -- 4\n",
      "this is x in EncoderLayer-----> tensor([[[-1.8451e+00,  1.0369e+01, -3.9081e+00,  ..., -5.9169e+00,\n",
      "          -2.5256e-03, -6.5457e+00],\n",
      "         [-1.2132e+00,  8.1060e+00, -8.9740e-01,  ..., -6.5003e+00,\n",
      "          -3.8514e-01, -7.1204e+00],\n",
      "         [-1.3921e+00,  8.9127e+00, -4.1315e+00,  ..., -8.0476e+00,\n",
      "           3.0215e+00, -6.5487e+00],\n",
      "         ...,\n",
      "         [ 7.5937e-01,  8.2163e+00, -3.5631e+00,  ..., -7.2516e+00,\n",
      "           4.6499e-01, -6.6895e+00],\n",
      "         [-2.7515e+00,  7.1603e+00, -4.5648e+00,  ..., -8.5904e+00,\n",
      "          -2.1502e-01, -7.5339e+00],\n",
      "         [-3.0169e+00,  7.5358e+00, -2.3504e+00,  ..., -6.7524e+00,\n",
      "          -1.1137e+00, -5.9869e+00]],\n",
      "\n",
      "        [[-1.0595e+00,  1.1124e+01, -2.6021e+00,  ..., -9.0521e+00,\n",
      "          -7.0316e-01, -8.2228e+00],\n",
      "         [ 9.8486e-01,  9.8713e+00, -2.6955e+00,  ..., -8.0379e+00,\n",
      "           1.9796e-02, -6.5553e+00],\n",
      "         [-5.6890e-01,  8.3494e+00, -6.7916e-01,  ..., -7.7747e+00,\n",
      "          -7.2897e-01, -6.4399e+00],\n",
      "         ...,\n",
      "         [ 1.5726e-01,  7.5871e+00, -1.9534e+00,  ..., -9.1756e+00,\n",
      "          -7.7013e-01, -7.4411e+00],\n",
      "         [ 9.5130e-01,  6.9043e+00, -3.3774e+00,  ..., -6.3856e+00,\n",
      "          -2.3903e+00, -6.4114e+00],\n",
      "         [-2.9194e+00,  7.0342e+00, -4.7652e+00,  ..., -8.3806e+00,\n",
      "           2.7022e-01, -5.4516e+00]],\n",
      "\n",
      "        [[ 2.1773e-01,  9.5239e+00, -3.8596e+00,  ..., -7.8745e+00,\n",
      "          -2.4340e-01, -6.8059e+00],\n",
      "         [ 1.4228e+00,  8.8630e+00, -1.2569e+00,  ..., -7.6844e+00,\n",
      "           1.1468e-02, -5.6440e+00],\n",
      "         [ 1.5098e+00,  4.9611e+00, -1.8553e+00,  ..., -6.1071e+00,\n",
      "           6.4784e-01, -5.4032e+00],\n",
      "         ...,\n",
      "         [ 1.9886e+00,  9.6240e+00, -3.6814e+00,  ..., -7.2742e+00,\n",
      "           1.3830e+00, -7.1909e+00],\n",
      "         [ 9.0518e-02,  5.9430e+00, -3.4673e+00,  ..., -7.6496e+00,\n",
      "           2.0868e+00, -5.7215e+00],\n",
      "         [-4.7263e-01,  8.4840e+00, -4.4110e+00,  ..., -4.4906e+00,\n",
      "           1.5440e+00, -4.2874e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.8634e+00,  8.5089e+00, -2.0285e+00,  ..., -7.8792e+00,\n",
      "          -2.2943e+00, -5.3872e+00],\n",
      "         [-1.3694e+00,  5.6880e+00, -3.4386e+00,  ..., -6.6252e+00,\n",
      "          -6.0338e-01, -7.0997e+00],\n",
      "         [-1.6888e+00,  8.0435e+00, -2.0869e+00,  ..., -6.1776e+00,\n",
      "           6.0950e-01, -3.7885e+00],\n",
      "         ...,\n",
      "         [-1.5123e+00,  9.9476e+00, -3.5965e+00,  ..., -8.1086e+00,\n",
      "          -5.1134e-01, -7.5711e+00],\n",
      "         [ 1.5448e-01,  9.4156e+00, -2.9102e+00,  ..., -2.4180e+00,\n",
      "          -1.7607e+00, -6.9951e+00],\n",
      "         [-3.0378e+00,  7.2554e+00, -2.7737e+00,  ..., -9.3136e+00,\n",
      "          -1.4977e+00, -6.7971e+00]],\n",
      "\n",
      "        [[-3.6086e+00,  1.0223e+01, -3.3719e+00,  ..., -9.2375e+00,\n",
      "          -2.0494e+00, -6.4735e+00],\n",
      "         [-1.6343e+00,  6.5587e+00, -9.3592e-01,  ..., -7.3304e+00,\n",
      "          -3.3934e+00, -8.0503e+00],\n",
      "         [ 3.3113e-01,  7.9558e+00, -1.6415e+00,  ..., -7.4508e+00,\n",
      "           9.5400e-01, -7.5733e+00],\n",
      "         ...,\n",
      "         [ 1.3546e+00,  8.7513e+00, -3.9801e+00,  ..., -3.2105e+00,\n",
      "          -5.4873e-01, -6.2130e+00],\n",
      "         [-2.0307e+00,  9.6836e+00, -4.1971e+00,  ..., -7.2089e+00,\n",
      "          -2.0980e+00, -4.5101e+00],\n",
      "         [-3.0503e+00,  6.1562e+00, -5.4066e+00,  ..., -7.8698e+00,\n",
      "          -2.2649e+00, -7.2738e+00]],\n",
      "\n",
      "        [[-5.2612e-01,  7.6360e+00, -3.7546e+00,  ..., -6.7972e+00,\n",
      "          -2.9506e+00, -5.7598e+00],\n",
      "         [-4.6831e-01,  4.5824e+00, -2.8920e+00,  ..., -6.4034e+00,\n",
      "           9.7326e-01, -7.5056e+00],\n",
      "         [-8.1414e-01,  7.4899e+00, -8.7039e-01,  ..., -7.3258e+00,\n",
      "          -6.1540e-01, -7.1049e+00],\n",
      "         ...,\n",
      "         [-2.8824e+00,  1.0120e+01, -2.6140e+00,  ..., -5.9878e+00,\n",
      "          -8.0081e-01, -6.6878e+00],\n",
      "         [-2.5299e+00,  9.4502e+00, -3.0414e+00,  ..., -6.2418e+00,\n",
      "          -4.2887e+00, -7.4506e+00],\n",
      "         [-3.4493e+00,  8.1466e+00, -3.8142e+00,  ..., -6.9859e+00,\n",
      "          -8.5172e-01, -3.6966e+00]]], grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 81, 64]) , torch.Size([512, 8, 81, 64]), torch.Size([512, 8, 81, 64])\n",
      "Score shape -- torch.Size([512, 8, 81, 81])\n",
      "Mask ---> torch.Size([512, 1, 81])\n",
      "Mask new --> torch.Size([512, 1, 1, 81])\n",
      "loop within encoder. Iteration -- 5\n",
      "this is x in EncoderLayer-----> tensor([[[ -1.3318,   9.2575,  -4.4334,  ...,  -7.6610,   0.0412,  -4.4259],\n",
      "         [ -0.2366,   7.4211,   1.3988,  ...,  -8.4377,  -1.2083,  -5.3815],\n",
      "         [ -0.9555,   8.0396,  -1.9746,  ..., -10.0647,   2.7729,  -4.6510],\n",
      "         ...,\n",
      "         [  1.5676,   7.5390,  -1.0065,  ...,  -9.4197,  -0.0220,  -4.8444],\n",
      "         [ -2.3129,   6.2283,  -3.1833,  ..., -10.1370,  -0.7585,  -6.3748],\n",
      "         [ -2.4081,   8.0698,  -2.8562,  ...,  -8.3299,  -1.0806,  -3.9558]],\n",
      "\n",
      "        [[ -0.3795,  10.2566,  -2.8532,  ..., -11.3554,  -0.7211,  -7.3319],\n",
      "         [  2.0612,   9.3682,  -0.5210,  ..., -10.6652,   0.0739,  -4.3997],\n",
      "         [ -0.3325,   7.6666,   0.9576,  ..., -10.0364,  -0.2406,  -4.7481],\n",
      "         ...,\n",
      "         [  1.1448,   7.1501,  -0.1252,  ..., -11.6655,  -1.3081,  -5.7513],\n",
      "         [  2.0750,   5.9665,  -1.5453,  ...,  -8.3856,  -2.3327,  -5.7488],\n",
      "         [ -1.7612,   6.6932,  -2.7242,  ..., -10.2055,   0.3232,  -4.5702]],\n",
      "\n",
      "        [[  1.2925,   8.4712,  -2.5942,  ..., -10.5184,  -0.4712,  -4.5320],\n",
      "         [  1.5575,   8.2030,   0.3956,  ...,  -9.1052,  -0.1546,  -3.9448],\n",
      "         [  2.1679,   4.4691,  -0.6340,  ...,  -7.6926,   1.0205,  -3.5294],\n",
      "         ...,\n",
      "         [  2.3226,   8.8742,  -2.2280,  ...,  -9.2188,   0.8582,  -5.2616],\n",
      "         [  0.8398,   5.1287,  -2.2060,  ...,  -9.7793,   2.6155,  -4.0366],\n",
      "         [  0.5462,   8.2065,  -3.0377,  ...,  -6.7537,   1.3390,  -2.3254]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -1.9976,   8.0578,  -0.2744,  ..., -10.4636,  -2.5753,  -3.4358],\n",
      "         [ -0.4535,   5.6382,  -2.1330,  ...,  -8.6428,  -1.2164,  -5.3017],\n",
      "         [ -0.7039,   7.5704,  -0.6485,  ...,  -6.3517,   0.1323,  -2.3831],\n",
      "         ...,\n",
      "         [ -0.8639,   9.7077,  -1.6857,  ...,  -8.5208,  -0.3441,  -5.8019],\n",
      "         [  0.5367,   9.0119,  -3.1806,  ...,  -4.1109,  -1.9720,  -6.4941],\n",
      "         [ -2.4441,   7.3651,  -1.3748,  ..., -11.2731,  -1.5188,  -5.6630]],\n",
      "\n",
      "        [[ -2.8898,   9.7180,  -1.4511,  ..., -11.6928,  -2.5199,  -5.0450],\n",
      "         [ -1.3432,   6.1902,   0.8396,  ...,  -9.7264,  -2.4429,  -6.2504],\n",
      "         [  1.6797,   7.5154,   0.5470,  ...,  -9.6067,   0.2873,  -5.7370],\n",
      "         ...,\n",
      "         [  2.0342,   7.8958,  -2.4292,  ...,  -5.0634,  -0.7787,  -4.2558],\n",
      "         [ -1.5457,   8.8913,  -2.7123,  ...,  -8.6490,  -2.0908,  -2.7449],\n",
      "         [ -2.6943,   5.5166,  -3.5708,  ..., -10.0922,  -2.6261,  -5.8400]],\n",
      "\n",
      "        [[  0.1895,   6.8421,  -1.6272,  ...,  -8.9841,  -2.6658,  -4.2103],\n",
      "         [  0.0547,   4.1338,  -1.3562,  ...,  -8.5951,   0.9892,  -6.3555],\n",
      "         [ -0.0376,   6.7572,   0.8937,  ...,  -9.5177,  -0.6528,  -5.7149],\n",
      "         ...,\n",
      "         [ -2.5939,   9.7549,  -0.5421,  ...,  -8.2689,  -0.9102,  -5.2850],\n",
      "         [ -2.4657,   9.0067,  -1.6809,  ...,  -7.7206,  -4.5221,  -6.8405],\n",
      "         [ -2.4472,   7.5963,  -1.8850,  ...,  -9.1147,  -0.8517,  -1.9579]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 81, 64]) , torch.Size([512, 8, 81, 64]), torch.Size([512, 8, 81, 64])\n",
      "Score shape -- torch.Size([512, 8, 81, 81])\n",
      "Mask ---> torch.Size([512, 1, 81])\n",
      "Mask new --> torch.Size([512, 1, 1, 81])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 88, 64]) , torch.Size([512, 8, 88, 64]), torch.Size([512, 8, 88, 64])\n",
      "Score shape -- torch.Size([512, 8, 88, 88])\n",
      "Mask ---> torch.Size([512, 88, 88])\n",
      "Mask new --> torch.Size([512, 1, 88, 88])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 88, 64]) , torch.Size([512, 8, 81, 64]), torch.Size([512, 8, 81, 64])\n",
      "Score shape -- torch.Size([512, 8, 88, 81])\n",
      "Mask ---> torch.Size([512, 1, 81])\n",
      "Mask new --> torch.Size([512, 1, 1, 81])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 88, 64]) , torch.Size([512, 8, 88, 64]), torch.Size([512, 8, 88, 64])\n",
      "Score shape -- torch.Size([512, 8, 88, 88])\n",
      "Mask ---> torch.Size([512, 88, 88])\n",
      "Mask new --> torch.Size([512, 1, 88, 88])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 88, 64]) , torch.Size([512, 8, 81, 64]), torch.Size([512, 8, 81, 64])\n",
      "Score shape -- torch.Size([512, 8, 88, 81])\n",
      "Mask ---> torch.Size([512, 1, 81])\n",
      "Mask new --> torch.Size([512, 1, 1, 81])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 88, 64]) , torch.Size([512, 8, 88, 64]), torch.Size([512, 8, 88, 64])\n",
      "Score shape -- torch.Size([512, 8, 88, 88])\n",
      "Mask ---> torch.Size([512, 88, 88])\n",
      "Mask new --> torch.Size([512, 1, 88, 88])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 88, 64]) , torch.Size([512, 8, 81, 64]), torch.Size([512, 8, 81, 64])\n",
      "Score shape -- torch.Size([512, 8, 88, 81])\n",
      "Mask ---> torch.Size([512, 1, 81])\n",
      "Mask new --> torch.Size([512, 1, 1, 81])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 88, 64]) , torch.Size([512, 8, 88, 64]), torch.Size([512, 8, 88, 64])\n",
      "Score shape -- torch.Size([512, 8, 88, 88])\n",
      "Mask ---> torch.Size([512, 88, 88])\n",
      "Mask new --> torch.Size([512, 1, 88, 88])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 88, 64]) , torch.Size([512, 8, 81, 64]), torch.Size([512, 8, 81, 64])\n",
      "Score shape -- torch.Size([512, 8, 88, 81])\n",
      "Mask ---> torch.Size([512, 1, 81])\n",
      "Mask new --> torch.Size([512, 1, 1, 81])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 88, 64]) , torch.Size([512, 8, 88, 64]), torch.Size([512, 8, 88, 64])\n",
      "Score shape -- torch.Size([512, 8, 88, 88])\n",
      "Mask ---> torch.Size([512, 88, 88])\n",
      "Mask new --> torch.Size([512, 1, 88, 88])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 88, 64]) , torch.Size([512, 8, 81, 64]), torch.Size([512, 8, 81, 64])\n",
      "Score shape -- torch.Size([512, 8, 88, 81])\n",
      "Mask ---> torch.Size([512, 1, 81])\n",
      "Mask new --> torch.Size([512, 1, 1, 81])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 88, 64]) , torch.Size([512, 8, 88, 64]), torch.Size([512, 8, 88, 64])\n",
      "Score shape -- torch.Size([512, 8, 88, 88])\n",
      "Mask ---> torch.Size([512, 88, 88])\n",
      "Mask new --> torch.Size([512, 1, 88, 88])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 88, 64]) , torch.Size([512, 8, 81, 64]), torch.Size([512, 8, 81, 64])\n",
      "Score shape -- torch.Size([512, 8, 88, 81])\n",
      "Mask ---> torch.Size([512, 1, 81])\n",
      "Mask new --> torch.Size([512, 1, 1, 81])\n",
      "predictions size : tensor([[-0.7811, -0.7613, -0.3682,  ..., -0.4793, -0.7178, -0.3439],\n",
      "        [-0.8584, -0.8037, -0.3997,  ..., -0.5458, -0.6733, -0.2914],\n",
      "        [-0.7787, -0.7989, -0.3597,  ..., -0.5273, -0.6723, -0.3315],\n",
      "        ...,\n",
      "        [-0.7898, -0.7164, -0.4297,  ..., -0.4441, -0.6232, -0.3209],\n",
      "        [-0.7200, -0.7531, -0.3506,  ..., -0.4185, -0.6936, -0.3215],\n",
      "        [-0.8240, -0.8118, -0.2719,  ..., -0.4716, -0.6765, -0.3088]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "targets size : torch.Size([45056])\n",
      "Loss.data ----> = 7.971858978271484\n",
      "--Encoder x after PE : tensor([[[ 0.0084,  1.3121, -0.6325,  ...,  0.7441, -0.6117,  0.5498],\n",
      "         [ 1.4703,  0.9737,  0.5630,  ...,  0.8543, -0.3035,  1.3268],\n",
      "         [ 0.8969, -0.8072,  1.0597,  ...,  0.0000, -0.0000,  0.8444],\n",
      "         ...,\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.5759,  1.2765,  0.1934,  ...,  0.8996, -0.2406,  0.5430],\n",
      "         [ 1.5355,  0.5547,  1.2518,  ...,  0.6127,  0.1813,  0.4537],\n",
      "         [ 0.4630, -0.5600,  0.9899,  ...,  1.6686,  0.4991,  1.2277],\n",
      "         ...,\n",
      "         [ 1.0763,  0.0000,  1.0508,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.0000]],\n",
      "\n",
      "        [[-0.0201,  1.6933, -0.0278,  ...,  0.7474, -0.1264,  0.0000],\n",
      "         [ 0.7386,  0.0176,  1.0511,  ...,  1.7500,  0.0495,  1.6327],\n",
      "         [ 0.9956,  0.1660,  1.1572,  ...,  1.1781,  0.1743,  1.1253],\n",
      "         ...,\n",
      "         [ 0.0000,  0.6715,  1.0508,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.5290,  0.9154,  0.4037,  ...,  0.5152, -0.6201,  0.8037],\n",
      "         [ 0.3617,  1.1229,  1.1812,  ...,  0.4679, -0.4765,  1.0208],\n",
      "         [ 1.1029, -0.3815,  1.6113,  ...,  1.3301,  0.4645,  0.5728],\n",
      "         ...,\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0000,  ...,  1.0595,  0.0000,  0.0000],\n",
      "         [-0.7645,  0.1060, -0.0000,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.5621,  1.7614,  0.0911,  ...,  0.0000,  0.4850,  1.2043],\n",
      "         [ 0.9662,  0.0000,  0.8455,  ...,  1.3924, -0.5008,  1.0126],\n",
      "         [ 0.8277, -0.9976,  0.0000,  ...,  1.2187,  0.1696,  1.1469],\n",
      "         ...,\n",
      "         [ 1.0763,  0.6715,  0.0000,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.0000,  0.0581,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.0000,  0.5406]],\n",
      "\n",
      "        [[-0.3034,  1.3393, -0.0343,  ...,  0.5699, -0.4315,  0.8667],\n",
      "         [ 1.2916,  0.0796,  1.0507,  ...,  1.1277, -0.0997,  0.7559],\n",
      "         [ 0.7467, -0.7882,  0.9684,  ...,  0.4837, -0.6016,  0.5303],\n",
      "         ...,\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  0.0000,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  0.0000,  0.0000,  0.5406],\n",
      "         [-0.0000,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.0000]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "loop within encoder. Iteration -- 0\n",
      "this is x in EncoderLayer-----> tensor([[[ 0.0084,  1.3121, -0.6325,  ...,  0.7441, -0.6117,  0.5498],\n",
      "         [ 1.4703,  0.9737,  0.5630,  ...,  0.8543, -0.3035,  1.3268],\n",
      "         [ 0.8969, -0.8072,  1.0597,  ...,  0.0000, -0.0000,  0.8444],\n",
      "         ...,\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.5759,  1.2765,  0.1934,  ...,  0.8996, -0.2406,  0.5430],\n",
      "         [ 1.5355,  0.5547,  1.2518,  ...,  0.6127,  0.1813,  0.4537],\n",
      "         [ 0.4630, -0.5600,  0.9899,  ...,  1.6686,  0.4991,  1.2277],\n",
      "         ...,\n",
      "         [ 1.0763,  0.0000,  1.0508,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.0000]],\n",
      "\n",
      "        [[-0.0201,  1.6933, -0.0278,  ...,  0.7474, -0.1264,  0.0000],\n",
      "         [ 0.7386,  0.0176,  1.0511,  ...,  1.7500,  0.0495,  1.6327],\n",
      "         [ 0.9956,  0.1660,  1.1572,  ...,  1.1781,  0.1743,  1.1253],\n",
      "         ...,\n",
      "         [ 0.0000,  0.6715,  1.0508,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.5290,  0.9154,  0.4037,  ...,  0.5152, -0.6201,  0.8037],\n",
      "         [ 0.3617,  1.1229,  1.1812,  ...,  0.4679, -0.4765,  1.0208],\n",
      "         [ 1.1029, -0.3815,  1.6113,  ...,  1.3301,  0.4645,  0.5728],\n",
      "         ...,\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0000,  ...,  1.0595,  0.0000,  0.0000],\n",
      "         [-0.7645,  0.1060, -0.0000,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.5621,  1.7614,  0.0911,  ...,  0.0000,  0.4850,  1.2043],\n",
      "         [ 0.9662,  0.0000,  0.8455,  ...,  1.3924, -0.5008,  1.0126],\n",
      "         [ 0.8277, -0.9976,  0.0000,  ...,  1.2187,  0.1696,  1.1469],\n",
      "         ...,\n",
      "         [ 1.0763,  0.6715,  0.0000,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.0000,  0.0581,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [-0.7645,  0.1060, -0.4602,  ...,  1.0595,  0.0000,  0.5406]],\n",
      "\n",
      "        [[-0.3034,  1.3393, -0.0343,  ...,  0.5699, -0.4315,  0.8667],\n",
      "         [ 1.2916,  0.0796,  1.0507,  ...,  1.1277, -0.0997,  0.7559],\n",
      "         [ 0.7467, -0.7882,  0.9684,  ...,  0.4837, -0.6016,  0.5303],\n",
      "         ...,\n",
      "         [ 1.0763,  0.6715,  1.0508,  ...,  0.0000,  0.1775,  0.5406],\n",
      "         [ 0.0660,  0.8434,  0.0581,  ...,  0.0000,  0.0000,  0.5406],\n",
      "         [-0.0000,  0.1060, -0.4602,  ...,  1.0595,  0.1775,  0.0000]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop within encoder. Iteration -- 1\n",
      "this is x in EncoderLayer-----> tensor([[[ 0.0084,  2.8232, -1.0755,  ..., -2.8687,  1.7354,  0.1416],\n",
      "         [-0.6254,  3.6351, -0.5473,  ..., -2.2876,  2.4121, -0.4240],\n",
      "         [-1.5210,  0.3798, -0.4451,  ..., -3.2654,  3.8527, -0.5071],\n",
      "         ...,\n",
      "         [-0.4385,  3.6921,  0.4902,  ..., -1.7264,  2.5072, -1.2673],\n",
      "         [ 0.0660,  3.2967, -0.5366,  ..., -1.5814,  2.7425, -0.7737],\n",
      "         [-2.8068,  1.8081, -0.8008,  ..., -0.8910,  2.3511, -0.3533]],\n",
      "\n",
      "        [[-1.0291,  3.9112, -1.1216,  ..., -2.1113,  3.0937, -1.1448],\n",
      "         [-0.5831,  4.2026,  1.3910,  ..., -1.3356,  3.0821, -1.0080],\n",
      "         [-1.5293,  3.1737,  0.3857,  ..., -0.8122,  4.4894, -0.1521],\n",
      "         ...,\n",
      "         [-0.4043,  3.6340,  0.6489,  ..., -1.7954,  4.0369, -0.0728],\n",
      "         [-1.6148,  3.8397, -0.8891,  ..., -1.6617,  3.2306, -1.2735],\n",
      "         [-2.0064,  2.1160, -1.5851,  ..., -2.0451,  0.9496, -0.5718]],\n",
      "\n",
      "        [[-2.7727,  4.9227, -0.4013,  ..., -2.2423,  0.9266, -1.4975],\n",
      "         [-1.8489,  2.7558,  0.6129,  ..., -1.0330,  2.8413,  0.3142],\n",
      "         [-2.0405,  1.7814, -0.1545,  ...,  0.4888,  3.0370, -0.0265],\n",
      "         ...,\n",
      "         [-2.4274,  3.7638,  0.9251,  ..., -0.7412,  2.3921, -0.9070],\n",
      "         [ 0.9114,  3.9595, -0.7842,  ..., -1.5777,  2.4023, -1.7291],\n",
      "         [-2.6870,  3.4218, -1.2618,  ..., -1.3905,  2.7840, -1.1055]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.8613,  4.5954,  1.0449,  ..., -2.1400,  1.8019, -1.0483],\n",
      "         [-1.8206,  4.3043,  0.8630,  ..., -2.4102,  2.9454,  0.2447],\n",
      "         [-1.5380,  2.9641,  1.1997,  ..., -1.5724,  3.9049, -1.3527],\n",
      "         ...,\n",
      "         [-1.5176,  4.0776,  0.5501,  ..., -1.7841,  2.1641, -1.7395],\n",
      "         [ 0.7592,  2.5520, -1.0651,  ..., -2.2589,  2.3082, -0.7411],\n",
      "         [-2.4173,  1.4422, -0.0662,  ..., -2.0531,  2.6583, -1.5646]],\n",
      "\n",
      "        [[-3.2022,  2.6202, -0.8745,  ..., -2.1073,  3.9184,  0.9058],\n",
      "         [ 0.7601,  2.9630,  0.6084,  ..., -0.1640,  2.6559, -0.0577],\n",
      "         [-1.0054,  0.1527, -0.4634,  ..., -0.4773,  1.8448,  0.4166],\n",
      "         ...,\n",
      "         [-0.8099,  3.4104, -0.9798,  ..., -1.0508,  1.1604, -0.5646],\n",
      "         [-1.1423,  3.0363, -0.0991,  ..., -1.3913,  2.4185, -1.1867],\n",
      "         [-1.8101,  2.6705, -1.4957,  ..., -1.6501,  2.9224, -1.3223]],\n",
      "\n",
      "        [[-1.7669,  3.0305, -0.3461,  ..., -2.1707,  3.0116, -0.1334],\n",
      "         [ 0.7147,  2.0022,  0.8376,  ...,  0.1106,  3.9206,  0.1639],\n",
      "         [ 0.0790,  1.6875,  0.6901,  ..., -0.8570,  3.4048, -0.3504],\n",
      "         ...,\n",
      "         [ 1.1190,  2.8692,  0.5056,  ..., -2.0372,  4.1429, -0.8382],\n",
      "         [-0.3429,  3.1244, -0.1288,  ..., -2.4020,  3.4002,  0.5435],\n",
      "         [-0.4270,  1.7674, -0.4170,  ..., -2.1683,  2.9145, -0.9971]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "loop within encoder. Iteration -- 2\n",
      "this is x in EncoderLayer-----> tensor([[[ 3.0934e-01,  4.9148e+00, -1.9249e+00,  ..., -5.2427e+00,\n",
      "           1.3719e+00, -1.7158e+00],\n",
      "         [ 1.5457e-01,  6.0641e+00, -1.2057e+00,  ..., -4.5546e+00,\n",
      "           1.4746e+00, -2.4024e+00],\n",
      "         [-1.1773e+00,  2.5108e+00, -1.1011e+00,  ..., -6.5280e+00,\n",
      "           3.4576e+00, -2.4952e+00],\n",
      "         ...,\n",
      "         [ 6.9454e-01,  5.3971e+00, -5.3974e-01,  ..., -4.3252e+00,\n",
      "           1.3056e+00, -2.7654e+00],\n",
      "         [ 9.0828e-01,  5.8832e+00, -1.8653e+00,  ..., -4.4914e+00,\n",
      "           1.8364e+00, -8.7145e-01],\n",
      "         [-1.6637e+00,  3.6400e+00, -2.0162e+00,  ..., -3.1795e+00,\n",
      "           1.5617e+00, -1.5422e+00]],\n",
      "\n",
      "        [[-7.8536e-01,  5.7485e+00, -2.0775e+00,  ..., -2.7007e+00,\n",
      "           2.7236e+00, -3.1971e+00],\n",
      "         [-2.9302e-01,  6.5737e+00,  5.3885e-02,  ..., -3.3338e+00,\n",
      "           2.5471e+00, -2.3759e+00],\n",
      "         [-1.2400e+00,  5.2995e+00, -8.5578e-01,  ..., -2.8513e+00,\n",
      "           3.4250e+00, -2.5356e+00],\n",
      "         ...,\n",
      "         [ 1.4076e-01,  5.7098e+00, -1.7130e-01,  ..., -4.4026e+00,\n",
      "           3.6386e+00, -1.8328e+00],\n",
      "         [-1.4621e+00,  5.4034e+00, -2.1234e+00,  ..., -3.8824e+00,\n",
      "           2.7445e+00, -2.9365e+00],\n",
      "         [-1.7443e+00,  3.7589e+00, -2.6734e+00,  ..., -4.1438e+00,\n",
      "           6.2513e-01, -2.8960e+00]],\n",
      "\n",
      "        [[-2.5989e+00,  4.9480e+00, -1.0951e+00,  ..., -5.2710e+00,\n",
      "          -5.5997e-02, -2.3682e+00],\n",
      "         [-1.9766e+00,  4.6330e+00, -3.1587e-01,  ..., -3.9086e+00,\n",
      "           1.5632e+00, -1.1034e+00],\n",
      "         [-1.6826e+00,  3.5333e+00, -1.5521e+00,  ..., -2.0037e+00,\n",
      "           2.9388e+00, -1.9715e+00],\n",
      "         ...,\n",
      "         [-2.8530e+00,  5.9348e+00,  2.7553e-03,  ..., -3.2249e+00,\n",
      "           1.4189e+00, -2.2927e+00],\n",
      "         [ 1.0907e+00,  5.9418e+00, -1.8768e+00,  ..., -4.1751e+00,\n",
      "           1.3572e+00, -4.1368e+00],\n",
      "         [-2.7104e+00,  5.3698e+00, -2.7609e+00,  ..., -4.0196e+00,\n",
      "           1.4842e+00, -3.0216e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.6879e+00,  5.5727e+00,  1.9020e-01,  ..., -4.2408e+00,\n",
      "           5.3871e-01, -3.7439e+00],\n",
      "         [-1.1982e+00,  6.0817e+00,  1.1350e+00,  ..., -4.2792e+00,\n",
      "           2.1348e+00, -1.9162e+00],\n",
      "         [-2.0990e-01,  3.6368e+00, -9.5643e-02,  ..., -4.0234e+00,\n",
      "           2.7908e+00, -3.9496e+00],\n",
      "         ...,\n",
      "         [-9.9243e-01,  6.4230e+00, -8.1500e-02,  ..., -4.1047e+00,\n",
      "           8.0788e-01, -4.0943e+00],\n",
      "         [ 8.8367e-01,  3.8191e+00, -2.2913e+00,  ..., -4.1339e+00,\n",
      "           1.4789e+00, -2.8377e+00],\n",
      "         [-1.7659e+00,  3.3367e+00, -1.6866e+00,  ..., -4.5225e+00,\n",
      "           2.2304e+00, -3.2197e+00]],\n",
      "\n",
      "        [[-2.8300e+00,  4.8627e+00, -1.7568e+00,  ..., -4.9467e+00,\n",
      "           2.6087e+00,  3.2051e-01],\n",
      "         [ 6.4291e-01,  5.7706e+00, -2.4197e-01,  ..., -2.5653e+00,\n",
      "           1.2365e+00, -1.3918e+00],\n",
      "         [-1.0068e+00,  2.3393e+00, -1.0779e+00,  ..., -3.0807e+00,\n",
      "           2.3055e+00, -2.4851e-01],\n",
      "         ...,\n",
      "         [-6.8076e-01,  6.2141e+00, -1.9406e+00,  ..., -2.8386e+00,\n",
      "           4.5511e-01, -5.6461e-01],\n",
      "         [-9.8950e-01,  5.8685e+00, -8.0165e-01,  ..., -4.0000e+00,\n",
      "           1.4073e+00, -2.7077e+00],\n",
      "         [-1.5643e+00,  5.2237e+00, -2.1830e+00,  ..., -1.7218e+00,\n",
      "           1.5091e+00, -1.9127e+00]],\n",
      "\n",
      "        [[-1.1467e+00,  3.2841e+00, -6.3355e-01,  ..., -5.0771e+00,\n",
      "           3.2922e+00, -3.0176e+00],\n",
      "         [ 1.3849e+00,  3.1194e+00,  7.7129e-01,  ..., -3.5624e+00,\n",
      "           3.1484e+00, -4.6746e-01],\n",
      "         [ 1.5246e+00,  3.0777e+00,  5.2293e-01,  ..., -3.6162e+00,\n",
      "           2.3473e+00, -3.2495e+00],\n",
      "         ...,\n",
      "         [ 2.3223e+00,  3.3180e+00,  2.5164e-01,  ..., -4.8172e+00,\n",
      "           3.3454e+00, -3.5343e+00],\n",
      "         [ 4.5577e-01,  3.7938e+00,  1.8525e-01,  ..., -5.0852e+00,\n",
      "           2.3409e+00, -2.1227e+00],\n",
      "         [ 5.1242e-01,  3.6541e+00, -1.0075e+00,  ..., -5.4991e+00,\n",
      "           1.3443e+00, -3.2632e+00]]], grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "loop within encoder. Iteration -- 3\n",
      "this is x in EncoderLayer-----> tensor([[[ 7.6342e-01,  6.8726e+00, -1.7094e+00,  ..., -7.8219e+00,\n",
      "          -4.0012e-01, -3.1030e+00],\n",
      "         [ 1.1562e+00,  8.0421e+00, -1.4474e+00,  ..., -7.1120e+00,\n",
      "           1.4343e+00, -4.0466e+00],\n",
      "         [-6.7453e-01,  4.1165e+00, -9.7159e-01,  ..., -9.9157e+00,\n",
      "           1.1895e+00, -3.9471e+00],\n",
      "         ...,\n",
      "         [ 1.0907e+00,  6.6056e+00, -2.3660e-01,  ..., -7.7823e+00,\n",
      "          -7.7457e-01, -4.1714e+00],\n",
      "         [ 9.1587e-01,  7.2687e+00, -1.7942e+00,  ..., -7.8262e+00,\n",
      "          -5.5139e-01, -1.7200e+00],\n",
      "         [-1.0168e+00,  3.6502e+00, -1.8409e+00,  ..., -6.6676e+00,\n",
      "           1.0772e+00, -2.3933e+00]],\n",
      "\n",
      "        [[ 1.3018e-01,  7.2720e+00, -1.9152e+00,  ..., -6.4025e+00,\n",
      "           3.1192e+00, -4.4464e+00],\n",
      "         [ 5.5081e-01,  7.9513e+00,  3.9262e-01,  ..., -7.0412e+00,\n",
      "           1.0821e-01, -3.7514e+00],\n",
      "         [-3.8295e-01,  6.7891e+00, -3.6424e-01,  ..., -6.9760e+00,\n",
      "           1.4106e+00, -4.0072e+00],\n",
      "         ...,\n",
      "         [ 7.9910e-01,  7.0089e+00,  2.1391e-01,  ..., -7.3684e+00,\n",
      "           1.1100e+00, -3.0245e+00],\n",
      "         [-1.1740e+00,  6.9861e+00, -1.8799e+00,  ..., -8.1195e+00,\n",
      "          -3.7150e-01, -3.4619e+00],\n",
      "         [-8.8693e-01,  5.3479e+00, -2.2487e+00,  ..., -7.9919e+00,\n",
      "          -2.2506e+00, -3.8991e+00]],\n",
      "\n",
      "        [[-1.9824e+00,  6.7436e+00, -9.7044e-01,  ..., -7.8436e+00,\n",
      "           2.4592e-01, -3.0794e+00],\n",
      "         [-1.6825e+00,  6.7068e+00, -6.4464e-01,  ..., -7.1474e+00,\n",
      "           3.0931e-01, -2.5031e+00],\n",
      "         [-1.0298e+00,  4.7585e+00, -2.0127e+00,  ..., -5.2663e+00,\n",
      "           5.5888e-01, -3.8839e+00],\n",
      "         ...,\n",
      "         [-1.8313e+00,  7.6185e+00,  2.3953e-03,  ..., -6.8177e+00,\n",
      "          -8.2523e-02, -3.7802e+00],\n",
      "         [ 1.2174e+00,  7.2806e+00, -1.9572e+00,  ..., -7.5933e+00,\n",
      "          -7.0211e-01, -4.9333e+00],\n",
      "         [-2.4068e+00,  6.5424e+00, -2.7411e+00,  ..., -7.0255e+00,\n",
      "          -2.5335e-01, -4.0747e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.1059e+00,  6.9573e+00,  5.3779e-01,  ..., -7.5611e+00,\n",
      "          -1.5496e+00, -5.0290e+00],\n",
      "         [-1.4900e-01,  7.2645e+00,  1.5140e+00,  ..., -6.5872e+00,\n",
      "          -4.9228e-02, -3.1601e+00],\n",
      "         [ 1.5693e-01,  5.2535e+00,  1.0708e+00,  ..., -7.0902e+00,\n",
      "           2.8064e-01, -4.8082e+00],\n",
      "         ...,\n",
      "         [-3.7034e-01,  8.0843e+00,  6.8794e-01,  ..., -7.9252e+00,\n",
      "          -1.6619e+00, -4.7704e+00],\n",
      "         [ 2.1414e+00,  5.9143e+00, -1.3353e+00,  ..., -7.4991e+00,\n",
      "          -9.1670e-01, -3.6183e+00],\n",
      "         [-1.5159e+00,  5.3694e+00, -1.2863e+00,  ..., -7.7140e+00,\n",
      "           2.4743e-01, -4.7439e+00]],\n",
      "\n",
      "        [[-1.8644e+00,  6.0838e+00, -2.2362e+00,  ..., -5.3356e+00,\n",
      "           9.5618e-01, -8.9866e-01],\n",
      "         [ 1.1600e+00,  6.7921e+00,  1.5195e-01,  ..., -5.7051e+00,\n",
      "          -1.0070e+00, -3.6311e+00],\n",
      "         [-3.8285e-02,  2.6723e+00, -9.3519e-01,  ..., -5.3166e+00,\n",
      "           2.0593e-01, -2.3878e+00],\n",
      "         ...,\n",
      "         [ 5.6013e-01,  7.4597e+00, -1.8781e+00,  ..., -6.5176e+00,\n",
      "          -1.7331e+00, -2.3845e+00],\n",
      "         [-1.3565e-01,  7.0037e+00,  2.2820e-01,  ..., -7.0084e+00,\n",
      "          -7.3639e-01, -4.7264e+00],\n",
      "         [-4.3492e-01,  5.5237e+00, -1.7525e+00,  ..., -4.4367e+00,\n",
      "          -8.5499e-01, -3.2111e+00]],\n",
      "\n",
      "        [[-2.4310e-01,  4.9922e+00,  4.9777e-02,  ..., -8.3324e+00,\n",
      "           2.3603e+00, -3.8303e+00],\n",
      "         [ 2.1849e+00,  3.6806e+00,  1.7780e+00,  ..., -6.2736e+00,\n",
      "           1.6000e+00, -1.7240e+00],\n",
      "         [ 1.7229e+00,  4.0237e+00,  1.6746e+00,  ..., -6.6225e+00,\n",
      "           3.6774e-01, -4.1969e+00],\n",
      "         ...,\n",
      "         [ 2.8209e+00,  3.9040e+00,  1.7104e+00,  ..., -8.3405e+00,\n",
      "           1.8637e+00, -4.1494e+00],\n",
      "         [ 9.3302e-01,  4.7507e+00,  9.8002e-01,  ..., -8.3059e+00,\n",
      "           1.0671e+00, -2.7035e+00],\n",
      "         [ 1.4697e+00,  4.7792e+00, -8.6373e-02,  ..., -8.7389e+00,\n",
      "           1.3443e+00, -4.1609e+00]]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "loop within encoder. Iteration -- 4\n",
      "this is x in EncoderLayer-----> tensor([[[-7.4129e-01,  9.2650e+00, -2.6889e+00,  ..., -8.5543e+00,\n",
      "          -1.3876e+00, -6.0387e+00],\n",
      "         [ 2.7539e-01,  1.0774e+01, -3.7933e+00,  ..., -7.2091e+00,\n",
      "           8.0265e-01, -7.3942e+00],\n",
      "         [-1.6493e+00,  6.4160e+00, -3.3589e+00,  ..., -1.0230e+01,\n",
      "           6.3865e-02, -7.4399e+00],\n",
      "         ...,\n",
      "         [ 9.6786e-03,  8.9863e+00, -2.3740e+00,  ..., -8.1008e+00,\n",
      "          -1.3254e+00, -7.1479e+00],\n",
      "         [ 4.3467e-01,  9.8898e+00, -4.0513e+00,  ..., -7.5778e+00,\n",
      "          -1.1391e+00, -4.7385e+00],\n",
      "         [-4.9800e-01,  5.4470e+00, -2.0796e+00,  ..., -6.9329e+00,\n",
      "           2.0740e+00, -5.1602e+00]],\n",
      "\n",
      "        [[ 1.0762e-01,  9.4679e+00, -3.9569e+00,  ..., -6.7164e+00,\n",
      "           4.0471e+00, -5.6917e+00],\n",
      "         [-6.1714e-01,  1.0096e+01, -2.0746e+00,  ..., -7.4314e+00,\n",
      "          -8.2305e-01, -5.1299e+00],\n",
      "         [-6.2072e-01,  9.0821e+00, -1.7919e+00,  ..., -7.4906e+00,\n",
      "           2.2457e-01, -6.6840e+00],\n",
      "         ...,\n",
      "         [ 2.1522e-01,  9.1623e+00, -1.9685e+00,  ..., -8.0504e+00,\n",
      "          -2.3641e-01, -5.7903e+00],\n",
      "         [-1.4644e+00,  8.8558e+00, -4.1692e+00,  ..., -8.9229e+00,\n",
      "          -2.0583e+00, -5.1939e+00],\n",
      "         [-1.3374e+00,  8.2006e+00, -4.1385e+00,  ..., -7.6523e+00,\n",
      "          -3.5072e+00, -6.9279e+00]],\n",
      "\n",
      "        [[-2.6900e+00,  8.6847e+00, -2.8994e+00,  ..., -8.1864e+00,\n",
      "          -1.1678e+00, -6.1563e+00],\n",
      "         [-2.8289e+00,  6.9477e+00, -3.0061e+00,  ..., -7.6834e+00,\n",
      "          -7.0510e-01, -5.4900e+00],\n",
      "         [-2.5388e+00,  7.0188e+00, -4.2951e+00,  ..., -5.4047e+00,\n",
      "           1.8108e+00, -6.8700e+00],\n",
      "         ...,\n",
      "         [-2.8210e+00,  7.9070e+00, -1.6662e+00,  ..., -7.3951e+00,\n",
      "          -1.4337e+00, -6.4665e+00],\n",
      "         [-2.5428e-01,  9.0612e+00, -4.3622e+00,  ..., -7.5838e+00,\n",
      "          -2.0025e+00, -6.1566e+00],\n",
      "         [-3.4589e+00,  8.3238e+00, -4.4294e+00,  ..., -7.5124e+00,\n",
      "          -1.5648e+00, -7.5287e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.3835e+00,  9.5340e+00, -2.2105e+00,  ..., -8.2272e+00,\n",
      "          -2.6030e+00, -7.4963e+00],\n",
      "         [-6.6061e-01,  9.6045e+00, -1.2598e+00,  ..., -7.4057e+00,\n",
      "          -1.2121e+00, -5.8653e+00],\n",
      "         [-1.1477e+00,  7.6265e+00,  1.9395e-01,  ..., -7.7414e+00,\n",
      "          -1.5140e+00, -7.7212e+00],\n",
      "         ...,\n",
      "         [-4.8816e-01,  9.9892e+00, -1.7251e+00,  ..., -8.4311e+00,\n",
      "          -2.9951e+00, -7.8378e+00],\n",
      "         [ 2.0007e+00,  7.9185e+00, -3.6671e+00,  ..., -8.1438e+00,\n",
      "          -2.4661e+00, -6.4480e+00],\n",
      "         [-2.7140e+00,  7.0704e+00, -4.1544e+00,  ..., -7.6741e+00,\n",
      "          -1.0236e+00, -7.6227e+00]],\n",
      "\n",
      "        [[-2.4534e+00,  8.2423e+00, -4.4908e+00,  ..., -4.9520e+00,\n",
      "          -6.2269e-01, -3.7376e+00],\n",
      "         [ 1.4761e+00,  8.7662e+00, -1.7728e+00,  ..., -5.8443e+00,\n",
      "          -2.3835e+00, -7.0968e+00],\n",
      "         [-1.6344e+00,  4.3554e+00, -3.2970e+00,  ..., -5.0314e+00,\n",
      "          -1.1940e+00, -4.2993e+00],\n",
      "         ...,\n",
      "         [-5.6296e-01,  8.1182e+00, -2.3057e+00,  ..., -6.6085e+00,\n",
      "          -2.8981e+00, -5.4524e+00],\n",
      "         [-1.1043e+00,  7.3812e+00, -1.6170e+00,  ..., -6.7846e+00,\n",
      "          -2.3427e+00, -8.1503e+00],\n",
      "         [-1.1028e+00,  5.9089e+00, -2.0652e+00,  ..., -4.0719e+00,\n",
      "          -2.1848e+00, -5.7245e+00]],\n",
      "\n",
      "        [[-2.7432e-01,  7.1221e+00, -1.8357e+00,  ..., -7.9956e+00,\n",
      "           1.8491e+00, -4.7732e+00],\n",
      "         [ 1.4359e+00,  5.2321e+00, -4.5220e-01,  ..., -6.6743e+00,\n",
      "           4.9589e-01, -4.1367e+00],\n",
      "         [ 1.5958e+00,  6.0112e+00,  1.2562e+00,  ..., -7.0128e+00,\n",
      "          -4.4745e-01, -5.8387e+00],\n",
      "         ...,\n",
      "         [ 3.0710e+00,  5.5392e+00, -6.3696e-01,  ..., -8.5778e+00,\n",
      "           3.4938e-01, -6.7078e+00],\n",
      "         [ 1.0142e+00,  6.1324e+00, -1.1705e+00,  ..., -8.0527e+00,\n",
      "          -8.0933e-01, -4.6504e+00],\n",
      "         [ 9.7119e-01,  5.4008e+00, -1.8776e+00,  ..., -8.3240e+00,\n",
      "           3.5161e-01, -6.7385e+00]]], grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "loop within encoder. Iteration -- 5\n",
      "this is x in EncoderLayer-----> tensor([[[-3.0969e-01,  8.4286e+00, -7.7384e-01,  ..., -1.0245e+01,\n",
      "          -1.6019e+00, -3.9699e+00],\n",
      "         [ 2.7539e-01,  1.0128e+01, -2.0296e+00,  ..., -9.4845e+00,\n",
      "           5.5050e-01, -5.3929e+00],\n",
      "         [-1.1183e+00,  5.2882e+00, -1.6282e+00,  ..., -1.2238e+01,\n",
      "          -1.7243e-01, -5.8450e+00],\n",
      "         ...,\n",
      "         [ 5.1337e-01,  8.1600e+00, -7.1955e-01,  ..., -1.0623e+01,\n",
      "          -1.4113e+00, -5.3304e+00],\n",
      "         [ 1.1926e+00,  9.2660e+00, -2.4866e+00,  ..., -9.9141e+00,\n",
      "          -1.9893e+00, -2.7738e+00],\n",
      "         [-3.7394e-02,  5.8178e+00, -2.0796e+00,  ..., -8.8258e+00,\n",
      "           1.5747e+00, -3.3475e+00]],\n",
      "\n",
      "        [[ 8.7928e-01,  8.8427e+00, -4.9072e+00,  ..., -9.3373e+00,\n",
      "           3.5078e+00, -4.1994e+00],\n",
      "         [-2.0257e-02,  9.7841e+00, -7.3091e-01,  ..., -1.0037e+01,\n",
      "          -7.9758e-01, -2.7396e+00],\n",
      "         [ 7.0343e-01,  8.4361e+00, -1.2205e-01,  ..., -9.5750e+00,\n",
      "           7.2110e-01, -4.4674e+00],\n",
      "         ...,\n",
      "         [ 1.1185e+00,  8.2104e+00, -5.1543e-01,  ..., -1.0411e+01,\n",
      "          -1.2470e+00, -3.7963e+00],\n",
      "         [-6.3199e-01,  9.1640e+00, -2.6460e+00,  ..., -1.1026e+01,\n",
      "          -2.4170e+00, -2.6785e+00],\n",
      "         [-1.0810e+00,  8.4140e+00, -2.0611e+00,  ..., -9.9145e+00,\n",
      "          -3.3373e+00, -4.7587e+00]],\n",
      "\n",
      "        [[-2.2174e+00,  7.7583e+00, -1.8216e+00,  ..., -8.6779e+00,\n",
      "          -1.0145e+00, -4.5192e+00],\n",
      "         [-1.7444e+00,  7.2495e+00, -1.4268e+00,  ..., -9.1731e+00,\n",
      "          -1.1488e+00, -3.7583e+00],\n",
      "         [-1.7616e+00,  6.0125e+00, -2.3306e+00,  ..., -6.8286e+00,\n",
      "           1.4593e+00, -5.0606e+00],\n",
      "         ...,\n",
      "         [-1.9481e+00,  7.1786e+00,  1.6578e-01,  ..., -7.8016e+00,\n",
      "          -1.8565e+00, -5.2467e+00],\n",
      "         [ 5.9899e-01,  9.4212e+00, -2.6122e+00,  ..., -9.6562e+00,\n",
      "          -2.5850e+00, -5.4004e+00],\n",
      "         [-3.0915e+00,  7.7024e+00, -4.8957e+00,  ..., -8.3235e+00,\n",
      "          -2.1488e+00, -5.5934e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.8073e-01,  8.7920e+00, -1.1046e+00,  ..., -1.0371e+01,\n",
      "          -1.5649e+00, -5.8420e+00],\n",
      "         [ 3.6393e-01,  8.7662e+00, -7.6624e-02,  ..., -9.7180e+00,\n",
      "          -1.8225e+00, -3.2747e+00],\n",
      "         [-6.8309e-01,  7.3693e+00,  1.8898e+00,  ..., -9.6190e+00,\n",
      "          -1.5962e+00, -5.4043e+00],\n",
      "         ...,\n",
      "         [ 6.5445e-01,  1.0219e+01,  3.2213e-01,  ..., -1.0570e+01,\n",
      "          -3.4262e+00, -5.6231e+00],\n",
      "         [ 2.8827e+00,  7.5846e+00, -2.1270e+00,  ..., -9.5940e+00,\n",
      "          -3.1828e+00, -4.3068e+00],\n",
      "         [-2.2602e+00,  5.9891e+00, -2.5933e+00,  ..., -1.0206e+01,\n",
      "          -1.1408e+00, -5.9442e+00]],\n",
      "\n",
      "        [[-1.8166e+00,  8.2136e+00, -2.6893e+00,  ..., -6.6058e+00,\n",
      "          -6.6186e-01, -1.9667e+00],\n",
      "         [ 1.7116e+00,  8.1475e+00, -2.6929e-01,  ..., -7.7086e+00,\n",
      "          -2.7778e+00, -5.6518e+00],\n",
      "         [-1.3128e+00,  3.7749e+00, -1.8428e+00,  ..., -6.9072e+00,\n",
      "          -1.5531e+00, -2.1532e+00],\n",
      "         ...,\n",
      "         [-3.0890e-01,  7.5104e+00, -5.0216e-01,  ..., -7.9886e+00,\n",
      "          -3.5493e+00, -4.2841e+00],\n",
      "         [-1.0281e+00,  7.0535e+00,  4.4907e-01,  ..., -8.8121e+00,\n",
      "          -1.5653e+00, -6.4368e+00],\n",
      "         [-5.4087e-01,  5.4595e+00, -6.7063e-01,  ..., -6.1054e+00,\n",
      "          -2.0393e+00, -5.0146e+00]],\n",
      "\n",
      "        [[-1.5477e-01,  6.2275e+00, -4.8930e-01,  ..., -9.3658e+00,\n",
      "           1.6936e+00, -3.6007e+00],\n",
      "         [ 2.3987e+00,  5.1109e+00,  8.3431e-01,  ..., -8.1127e+00,\n",
      "           1.5806e+00, -2.3006e+00],\n",
      "         [ 2.4533e+00,  5.5626e+00,  2.0401e+00,  ..., -8.7500e+00,\n",
      "          -1.1774e+00, -3.5820e+00],\n",
      "         ...,\n",
      "         [ 3.9139e+00,  4.9264e+00,  9.2206e-01,  ..., -9.6266e+00,\n",
      "          -1.0933e-01, -4.8578e+00],\n",
      "         [ 1.6055e+00,  4.9489e+00,  1.0268e-02,  ..., -9.4155e+00,\n",
      "          -1.3594e+00, -3.9894e+00],\n",
      "         [ 1.7615e+00,  5.0180e+00, -1.0255e-01,  ..., -9.7642e+00,\n",
      "          -5.1699e-01, -5.3268e+00]]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 91])\n",
      "Mask ---> torch.Size([512, 91, 91])\n",
      "Mask new --> torch.Size([512, 1, 91, 91])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 91])\n",
      "Mask ---> torch.Size([512, 91, 91])\n",
      "Mask new --> torch.Size([512, 1, 91, 91])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 91])\n",
      "Mask ---> torch.Size([512, 91, 91])\n",
      "Mask new --> torch.Size([512, 1, 91, 91])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 91])\n",
      "Mask ---> torch.Size([512, 91, 91])\n",
      "Mask new --> torch.Size([512, 1, 91, 91])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 91])\n",
      "Mask ---> torch.Size([512, 91, 91])\n",
      "Mask new --> torch.Size([512, 1, 91, 91])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 91, 64]), torch.Size([512, 8, 91, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 91])\n",
      "Mask ---> torch.Size([512, 91, 91])\n",
      "Mask new --> torch.Size([512, 1, 91, 91])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 91, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 91, 87])\n",
      "Mask ---> torch.Size([512, 1, 87])\n",
      "Mask new --> torch.Size([512, 1, 1, 87])\n",
      "predictions size : tensor([[-0.7636, -1.0322, -0.4928,  ..., -0.5639, -0.8633, -0.3071],\n",
      "        [-0.9123, -0.8010, -0.3723,  ..., -0.5253, -0.7562, -0.3165],\n",
      "        [-0.8399, -0.9108, -0.3883,  ..., -0.5143, -0.7004, -0.2641],\n",
      "        ...,\n",
      "        [-0.8129, -0.8085, -0.3857,  ..., -0.4350, -0.7331, -0.3925],\n",
      "        [-0.9568, -0.8453, -0.3984,  ..., -0.5816, -0.6240, -0.3845],\n",
      "        [-0.8097, -0.8257, -0.4926,  ..., -0.4499, -0.7031, -0.3605]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "targets size : torch.Size([46592])\n",
      "Loss.data ----> = 7.911253929138184\n",
      "--Encoder x after PE : tensor([[[ 0.3690,  0.5211, -0.4435,  ...,  1.5757, -0.3155,  0.8434],\n",
      "         [ 1.2478,  1.0460,  1.4179,  ...,  0.9550, -0.0245,  0.0000],\n",
      "         [ 1.0723, -0.5517,  1.2218,  ...,  1.7218, -0.3893,  1.5142],\n",
      "         ...,\n",
      "         [-0.2142, -0.9917,  1.6632,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.8404, -1.3082,  1.6148,  ...,  1.0595,  0.1775,  0.0000],\n",
      "         [-0.4534, -0.6822,  0.7872,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.0000,  0.0000,  0.6546,  ...,  0.0000,  0.0564,  1.1609],\n",
      "         [ 1.1855,  0.0000,  0.0000,  ...,  1.0012, -0.5767,  0.8772],\n",
      "         [ 1.1024, -0.3810,  1.6112,  ...,  0.0000,  0.4650,  0.5726],\n",
      "         ...,\n",
      "         [-0.2142, -0.9917,  1.6632,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.8404, -0.0000,  1.6148,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.4534, -0.6822,  0.7872,  ...,  1.0595,  0.1775,  0.0000]],\n",
      "\n",
      "        [[-0.6298,  1.5944, -0.6041,  ...,  1.2135, -0.6315,  1.6894],\n",
      "         [ 0.7405,  0.3321,  1.1891,  ...,  0.4924, -0.2768,  1.1776],\n",
      "         [ 0.8275, -0.9969,  0.6986,  ...,  0.0000,  0.1694,  1.1462],\n",
      "         ...,\n",
      "         [ 0.1220, -0.9810,  0.5497,  ...,  1.4116,  0.6198,  0.6509],\n",
      "         [-0.6641, -1.2017,  1.4595,  ...,  1.2817, -0.0362,  1.5405],\n",
      "         [-1.1778, -0.2086,  0.2547,  ...,  0.0000, -0.5850,  0.7090]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "loop within encoder. Iteration -- 0\n",
      "this is x in EncoderLayer-----> tensor([[[ 0.3690,  0.5211, -0.4435,  ...,  1.5757, -0.3155,  0.8434],\n",
      "         [ 1.2478,  1.0460,  1.4179,  ...,  0.9550, -0.0245,  0.0000],\n",
      "         [ 1.0723, -0.5517,  1.2218,  ...,  1.7218, -0.3893,  1.5142],\n",
      "         ...,\n",
      "         [-0.2142, -0.9917,  1.6632,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.8404, -1.3082,  1.6148,  ...,  1.0595,  0.1775,  0.0000],\n",
      "         [-0.4534, -0.6822,  0.7872,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.0000,  0.0000,  0.6546,  ...,  0.0000,  0.0564,  1.1609],\n",
      "         [ 1.1855,  0.0000,  0.0000,  ...,  1.0012, -0.5767,  0.8772],\n",
      "         [ 1.1024, -0.3810,  1.6112,  ...,  0.0000,  0.4650,  0.5726],\n",
      "         ...,\n",
      "         [-0.2142, -0.9917,  1.6632,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.8404, -0.0000,  1.6148,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.4534, -0.6822,  0.7872,  ...,  1.0595,  0.1775,  0.0000]],\n",
      "\n",
      "        [[-0.6298,  1.5944, -0.6041,  ...,  1.2135, -0.6315,  1.6894],\n",
      "         [ 0.7405,  0.3321,  1.1891,  ...,  0.4924, -0.2768,  1.1776],\n",
      "         [ 0.8275, -0.9969,  0.6986,  ...,  0.0000,  0.1694,  1.1462],\n",
      "         ...,\n",
      "         [ 0.1220, -0.9810,  0.5497,  ...,  1.4116,  0.6198,  0.6509],\n",
      "         [-0.6641, -1.2017,  1.4595,  ...,  1.2817, -0.0362,  1.5405],\n",
      "         [-1.1778, -0.2086,  0.2547,  ...,  0.0000, -0.5850,  0.7090]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 38, 64]) , torch.Size([3, 8, 38, 64]), torch.Size([3, 8, 38, 64])\n",
      "Score shape -- torch.Size([3, 8, 38, 38])\n",
      "Mask ---> torch.Size([3, 1, 38])\n",
      "Mask new --> torch.Size([3, 1, 1, 38])\n",
      "loop within encoder. Iteration -- 1\n",
      "this is x in EncoderLayer-----> tensor([[[-2.1714,  3.1742, -1.6585,  ..., -0.5350,  2.1388, -0.9868],\n",
      "         [-1.5354,  3.4302,  0.1774,  ..., -1.2592,  2.5133, -1.5596],\n",
      "         [-1.4151,  0.6238,  0.3179,  ..., -2.2399,  2.0781, -0.5200],\n",
      "         ...,\n",
      "         [-2.2119,  1.6766,  0.7938,  ..., -2.2037,  3.0664, -1.2303],\n",
      "         [-0.6907,  1.3627,  0.0120,  ..., -2.2930,  1.8672, -2.2675],\n",
      "         [-2.9705,  2.0193, -0.7823,  ..., -2.5782,  3.1692, -0.9183]],\n",
      "\n",
      "        [[-1.7217,  1.1439, -0.3059,  ..., -1.8795,  1.0118, -0.4551],\n",
      "         [-0.6396,  2.0433, -1.0107,  ..., -1.9259,  1.9836, -1.0939],\n",
      "         [-1.5902,  2.7998,  0.2900,  ..., -0.3250,  3.1638, -0.7203],\n",
      "         ...,\n",
      "         [-2.5706, -0.0323,  0.3035,  ..., -1.8907,  3.4118, -1.1488],\n",
      "         [-2.5174,  2.8085,  0.7700,  ..., -1.5869,  2.4252,  0.1520],\n",
      "         [ 0.1973,  1.8874, -0.6617,  ..., -0.4676,  0.1775, -2.1461]],\n",
      "\n",
      "        [[-3.3339,  4.2069, -0.5158,  ..., -1.1058,  1.8147,  0.9149],\n",
      "         [-1.8972,  3.5374,  0.6154,  ..., -2.0379,  2.4119,  0.2799],\n",
      "         [-1.8047,  1.9745,  0.3110,  ..., -0.8242,  3.7218, -0.5799],\n",
      "         ...,\n",
      "         [-2.1090,  1.7201, -0.8391,  ..., -1.1104,  3.2739, -0.7317],\n",
      "         [-3.3053,  1.2511, -0.2078,  ..., -0.5029,  2.3860, -0.1066],\n",
      "         [-3.6793,  3.2358,  1.2262,  ..., -2.5319,  2.6072, -0.3643]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 38, 64]) , torch.Size([3, 8, 38, 64]), torch.Size([3, 8, 38, 64])\n",
      "Score shape -- torch.Size([3, 8, 38, 38])\n",
      "Mask ---> torch.Size([3, 1, 38])\n",
      "Mask new --> torch.Size([3, 1, 1, 38])\n",
      "loop within encoder. Iteration -- 2\n",
      "this is x in EncoderLayer-----> tensor([[[-2.2146,  5.2564, -2.3519,  ..., -3.3935,  1.4426, -3.1450],\n",
      "         [-1.5354,  5.1376, -0.5049,  ..., -3.9534,  1.3664, -4.0126],\n",
      "         [-1.0514,  2.4789, -0.1359,  ..., -4.6808,  1.1141, -2.3794],\n",
      "         ...,\n",
      "         [-1.3259,  3.9891,  0.2631,  ..., -5.4834,  1.5034, -2.7232],\n",
      "         [ 0.0330,  3.3020, -0.4477,  ..., -5.1689,  0.9574, -3.7935],\n",
      "         [-2.6321,  4.6332, -0.9572,  ..., -4.8998,  2.0153, -1.2333]],\n",
      "\n",
      "        [[-0.5484,  3.1714, -1.1478,  ..., -4.4510,  0.3972, -1.1706],\n",
      "         [-0.4929,  3.9220, -2.4894,  ..., -4.8165,  1.1762, -2.8069],\n",
      "         [-1.1262,  5.2885, -0.6449,  ..., -2.8939,  2.2391, -2.4811],\n",
      "         ...,\n",
      "         [-2.0533,  2.2170, -0.9727,  ..., -4.3301,  2.4036, -2.8744],\n",
      "         [-2.3984,  5.0837,  0.3404,  ..., -4.1954,  1.5696, -1.8378],\n",
      "         [ 0.6570,  3.8396, -1.2583,  ..., -2.4515, -0.3793, -3.8350]],\n",
      "\n",
      "        [[-3.7699,  6.3823, -0.9152,  ..., -3.9900,  0.1216, -0.2784],\n",
      "         [-2.3527,  5.2608, -0.0350,  ..., -5.0469,  1.7949, -1.4704],\n",
      "         [-2.0924,  3.9279, -0.8748,  ..., -3.3899,  2.4808, -2.5438],\n",
      "         ...,\n",
      "         [-1.4326,  3.9003, -1.3726,  ..., -3.6574,  2.3517, -1.8794],\n",
      "         [-3.2230,  3.7201, -1.3000,  ..., -0.6612,  1.4685, -1.2657],\n",
      "         [-3.8806,  4.9128,  0.7374,  ..., -4.8431,  2.2004, -1.4129]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 38, 64]) , torch.Size([3, 8, 38, 64]), torch.Size([3, 8, 38, 64])\n",
      "Score shape -- torch.Size([3, 8, 38, 38])\n",
      "Mask ---> torch.Size([3, 1, 38])\n",
      "Mask new --> torch.Size([3, 1, 1, 38])\n",
      "loop within encoder. Iteration -- 3\n",
      "this is x in EncoderLayer-----> tensor([[[-1.3509e+00,  6.9511e+00, -2.7858e+00,  ..., -6.6391e+00,\n",
      "          -7.8846e-02, -4.1970e+00],\n",
      "         [-7.9935e-01,  7.0943e+00, -1.4479e-01,  ..., -6.4486e+00,\n",
      "          -4.5602e-01, -4.5860e+00],\n",
      "         [-8.7537e-01,  3.7537e+00,  1.6434e-02,  ..., -7.7123e+00,\n",
      "          -9.1259e-01, -3.4114e+00],\n",
      "         ...,\n",
      "         [-5.7951e-01,  4.6289e+00,  3.7387e-01,  ..., -8.7091e+00,\n",
      "          -8.8594e-01, -4.0798e+00],\n",
      "         [ 7.4328e-01,  4.5786e+00, -3.6039e-01,  ..., -8.2407e+00,\n",
      "          -1.6378e+00, -5.2001e+00],\n",
      "         [-1.4979e+00,  6.3737e+00, -1.2979e+00,  ..., -7.7245e+00,\n",
      "           2.9897e-01, -2.9922e+00]],\n",
      "\n",
      "        [[ 2.3274e-01,  4.2679e+00, -1.2638e+00,  ..., -7.6267e+00,\n",
      "          -1.0058e+00, -2.7579e+00],\n",
      "         [-5.0904e-01,  5.7358e+00, -2.5649e+00,  ..., -7.7587e+00,\n",
      "          -6.4116e-01, -3.9047e+00],\n",
      "         [-8.3631e-02,  6.6494e+00, -1.0703e-01,  ..., -5.4832e+00,\n",
      "           3.7264e-01, -4.2391e+00],\n",
      "         ...,\n",
      "         [-1.0725e+00,  3.6965e+00, -8.2746e-01,  ..., -7.1767e+00,\n",
      "           6.1979e-01, -4.3026e+00],\n",
      "         [-1.4534e+00,  5.3412e+00,  7.0728e-01,  ..., -7.5294e+00,\n",
      "          -4.3294e-01, -2.7590e+00],\n",
      "         [ 2.2037e+00,  5.0180e+00, -1.8075e+00,  ..., -6.0244e+00,\n",
      "          -2.5025e+00, -4.6649e+00]],\n",
      "\n",
      "        [[-2.9291e+00,  7.7070e+00, -8.6800e-01,  ..., -4.4738e+00,\n",
      "          -2.5310e+00, -1.9792e+00],\n",
      "         [-1.9109e+00,  7.1556e+00, -7.7567e-01,  ..., -7.8598e+00,\n",
      "          -2.6469e-03, -2.5908e+00],\n",
      "         [-1.3261e+00,  5.1952e+00, -1.0881e+00,  ..., -6.5125e+00,\n",
      "           4.4258e-01, -4.5606e+00],\n",
      "         ...,\n",
      "         [-7.3417e-01,  5.7419e+00, -2.0303e+00,  ..., -5.8305e+00,\n",
      "           1.8541e-01, -3.5941e+00],\n",
      "         [-2.7295e+00,  5.8493e+00, -1.8192e+00,  ..., -3.9547e+00,\n",
      "          -3.2560e-01, -2.1235e+00],\n",
      "         [-2.7542e+00,  5.7376e+00,  3.4384e-01,  ..., -5.6679e+00,\n",
      "          -2.8970e-02, -2.9182e+00]]], grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 38, 64]) , torch.Size([3, 8, 38, 64]), torch.Size([3, 8, 38, 64])\n",
      "Score shape -- torch.Size([3, 8, 38, 38])\n",
      "Mask ---> torch.Size([3, 1, 38])\n",
      "Mask new --> torch.Size([3, 1, 1, 38])\n",
      "loop within encoder. Iteration -- 4\n",
      "this is x in EncoderLayer-----> tensor([[[-1.9518,  7.4087, -4.9394,  ..., -7.1748, -1.3018, -7.5920],\n",
      "         [-1.8483,  9.4030, -1.7840,  ..., -6.9776, -2.2192, -7.7183],\n",
      "         [-1.4408,  6.2317, -2.0566,  ..., -8.1054, -1.7014, -6.4577],\n",
      "         ...,\n",
      "         [-1.6362,  7.1397, -2.1512,  ..., -9.0708, -1.8850, -6.9544],\n",
      "         [-0.5080,  6.8496, -2.7561,  ..., -8.4872, -2.6762, -8.1509],\n",
      "         [-2.8694,  8.9031, -1.8921,  ..., -7.5399, -1.8030, -6.6155]],\n",
      "\n",
      "        [[-0.4536,  6.0142, -3.5517,  ..., -8.0386, -2.5002, -5.7841],\n",
      "         [-0.5090,  6.2801, -4.4863,  ..., -8.0530, -1.7684, -7.0677],\n",
      "         [-1.5569,  8.9121, -2.4116,  ..., -6.2284,  1.6775, -7.8684],\n",
      "         ...,\n",
      "         [-1.7315,  6.3999, -3.5081,  ..., -6.8328, -0.5031, -7.3598],\n",
      "         [-2.4193,  7.1100, -1.0721,  ..., -7.5781, -1.5424, -6.1551],\n",
      "         [ 1.2778,  7.5287, -3.9539,  ..., -6.5481, -3.4836, -7.8131]],\n",
      "\n",
      "        [[-4.4242,  9.9651, -3.0152,  ..., -4.6983, -3.6309, -5.1589],\n",
      "         [-2.8347,  8.8420, -2.7948,  ..., -8.3799, -0.8611, -4.6438],\n",
      "         [-2.3990,  7.4387, -2.9210,  ..., -6.1880, -0.2515, -7.9777],\n",
      "         ...,\n",
      "         [-1.9168,  7.7533, -3.7113,  ..., -6.3272,  0.0384, -6.5700],\n",
      "         [-3.6663,  8.9403, -3.9937,  ..., -4.2055,  0.8087, -5.6618],\n",
      "         [-3.8517,  8.0496, -1.4146,  ..., -5.3812, -1.2597, -5.0692]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 38, 64]) , torch.Size([3, 8, 38, 64]), torch.Size([3, 8, 38, 64])\n",
      "Score shape -- torch.Size([3, 8, 38, 38])\n",
      "Mask ---> torch.Size([3, 1, 38])\n",
      "Mask new --> torch.Size([3, 1, 1, 38])\n",
      "loop within encoder. Iteration -- 5\n",
      "this is x in EncoderLayer-----> tensor([[[ -1.3066,   7.8354,  -5.2702,  ...,  -9.4309,  -1.9679,  -5.2105],\n",
      "         [ -1.0592,   8.8089,  -0.0803,  ...,  -8.7398,  -2.4429,  -5.8264],\n",
      "         [ -0.8459,   6.5539,   0.1073,  ...,  -9.8252,  -2.0084,  -5.4489],\n",
      "         ...,\n",
      "         [ -0.8516,   6.7686,  -0.3846,  ..., -10.9512,  -2.1223,  -4.6421],\n",
      "         [ -0.0635,   6.1216,  -1.2643,  ..., -10.3000,  -2.8119,  -6.8494],\n",
      "         [ -2.1827,   8.2108,  -0.0680,  ...,  -8.8838,  -2.6333,  -5.0271]],\n",
      "\n",
      "        [[  0.1156,   5.4210,  -1.7493,  ..., -10.5344,  -3.4305,  -4.0709],\n",
      "         [ -0.0415,   5.7328,  -2.7007,  ..., -10.5960,  -2.3234,  -5.0669],\n",
      "         [ -1.0692,   7.9792,  -0.1479,  ...,  -7.9506,   0.8314,  -6.1243],\n",
      "         ...,\n",
      "         [ -1.3851,   5.7802,  -1.9954,  ...,  -9.1715,  -0.8371,  -5.8494],\n",
      "         [ -1.6091,   6.9038,   1.0283,  ...,  -9.9456,  -1.8841,  -4.6679],\n",
      "         [  1.6828,   6.5621,  -1.9708,  ...,  -8.9305,  -3.6629,  -5.9934]],\n",
      "\n",
      "        [[ -3.4316,  10.2232,  -0.5505,  ...,  -6.9949,  -4.3021,  -3.2596],\n",
      "         [ -2.0563,   8.2821,  -1.3436,  ..., -10.6662,  -1.9344,  -2.9723],\n",
      "         [ -1.5737,   6.9626,  -0.7605,  ...,  -8.5298,  -0.5655,  -6.1743],\n",
      "         ...,\n",
      "         [ -1.3935,   7.5031,  -1.5569,  ...,  -8.2687,  -0.6813,  -4.6025],\n",
      "         [ -3.3880,   8.5803,  -1.8810,  ...,  -6.1014,   0.0470,  -4.9277],\n",
      "         [ -3.3992,   6.8745,   0.0902,  ...,  -6.0990,  -1.9746,  -3.1136]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 38, 64]) , torch.Size([3, 8, 38, 64]), torch.Size([3, 8, 38, 64])\n",
      "Score shape -- torch.Size([3, 8, 38, 38])\n",
      "Mask ---> torch.Size([3, 1, 38])\n",
      "Mask new --> torch.Size([3, 1, 1, 38])\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 47, 64]) , torch.Size([3, 8, 47, 64]), torch.Size([3, 8, 47, 64])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score shape -- torch.Size([3, 8, 47, 47])\n",
      "Mask ---> torch.Size([3, 47, 47])\n",
      "Mask new --> torch.Size([3, 1, 47, 47])\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 47, 64]) , torch.Size([3, 8, 38, 64]), torch.Size([3, 8, 38, 64])\n",
      "Score shape -- torch.Size([3, 8, 47, 38])\n",
      "Mask ---> torch.Size([3, 1, 38])\n",
      "Mask new --> torch.Size([3, 1, 1, 38])\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 47, 64]) , torch.Size([3, 8, 47, 64]), torch.Size([3, 8, 47, 64])\n",
      "Score shape -- torch.Size([3, 8, 47, 47])\n",
      "Mask ---> torch.Size([3, 47, 47])\n",
      "Mask new --> torch.Size([3, 1, 47, 47])\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 47, 64]) , torch.Size([3, 8, 38, 64]), torch.Size([3, 8, 38, 64])\n",
      "Score shape -- torch.Size([3, 8, 47, 38])\n",
      "Mask ---> torch.Size([3, 1, 38])\n",
      "Mask new --> torch.Size([3, 1, 1, 38])\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 47, 64]) , torch.Size([3, 8, 47, 64]), torch.Size([3, 8, 47, 64])\n",
      "Score shape -- torch.Size([3, 8, 47, 47])\n",
      "Mask ---> torch.Size([3, 47, 47])\n",
      "Mask new --> torch.Size([3, 1, 47, 47])\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 47, 64]) , torch.Size([3, 8, 38, 64]), torch.Size([3, 8, 38, 64])\n",
      "Score shape -- torch.Size([3, 8, 47, 38])\n",
      "Mask ---> torch.Size([3, 1, 38])\n",
      "Mask new --> torch.Size([3, 1, 1, 38])\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 47, 64]) , torch.Size([3, 8, 47, 64]), torch.Size([3, 8, 47, 64])\n",
      "Score shape -- torch.Size([3, 8, 47, 47])\n",
      "Mask ---> torch.Size([3, 47, 47])\n",
      "Mask new --> torch.Size([3, 1, 47, 47])\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 47, 64]) , torch.Size([3, 8, 38, 64]), torch.Size([3, 8, 38, 64])\n",
      "Score shape -- torch.Size([3, 8, 47, 38])\n",
      "Mask ---> torch.Size([3, 1, 38])\n",
      "Mask new --> torch.Size([3, 1, 1, 38])\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 47, 64]) , torch.Size([3, 8, 47, 64]), torch.Size([3, 8, 47, 64])\n",
      "Score shape -- torch.Size([3, 8, 47, 47])\n",
      "Mask ---> torch.Size([3, 47, 47])\n",
      "Mask new --> torch.Size([3, 1, 47, 47])\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 47, 64]) , torch.Size([3, 8, 38, 64]), torch.Size([3, 8, 38, 64])\n",
      "Score shape -- torch.Size([3, 8, 47, 38])\n",
      "Mask ---> torch.Size([3, 1, 38])\n",
      "Mask new --> torch.Size([3, 1, 1, 38])\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 47, 64]) , torch.Size([3, 8, 47, 64]), torch.Size([3, 8, 47, 64])\n",
      "Score shape -- torch.Size([3, 8, 47, 47])\n",
      "Mask ---> torch.Size([3, 47, 47])\n",
      "Mask new --> torch.Size([3, 1, 47, 47])\n",
      "d_k value 64\n",
      "torch.Size([3, 8, 47, 64]) , torch.Size([3, 8, 38, 64]), torch.Size([3, 8, 38, 64])\n",
      "Score shape -- torch.Size([3, 8, 47, 38])\n",
      "Mask ---> torch.Size([3, 1, 38])\n",
      "Mask new --> torch.Size([3, 1, 1, 38])\n",
      "predictions size : tensor([[-0.8722, -1.0118, -0.5086,  ..., -0.5006, -0.7954, -0.3946],\n",
      "        [-0.9195, -0.8904, -0.4606,  ..., -0.6096, -0.7881, -0.3510],\n",
      "        [-0.9376, -0.9969, -0.4173,  ..., -0.5514, -0.7442, -0.3266],\n",
      "        ...,\n",
      "        [-0.9121, -0.8677, -0.3944,  ..., -0.4418, -0.6660, -0.4419],\n",
      "        [-0.8767, -0.8957, -0.4428,  ..., -0.5292, -0.7969, -0.3140],\n",
      "        [-0.9450, -0.8445, -0.4814,  ..., -0.6237, -0.8291, -0.4172]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "targets size : torch.Size([141])\n",
      "Loss.data ----> = 7.863412380218506\n",
      "Epoch - 2\n",
      "--Encoder x after PE : tensor([[[-0.6241,  0.0000, -0.0179,  ...,  0.7065, -0.1573,  0.5090],\n",
      "         [ 0.9894,  0.1932,  0.6550,  ...,  1.3589,  0.0968,  0.6021],\n",
      "         [ 1.0334, -0.8907,  0.5876,  ...,  1.4834,  0.4228,  0.0000],\n",
      "         ...,\n",
      "         [-0.0000, -0.4381, -0.2582,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.4383, -1.2356,  0.6229,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.6096, -1.1531,  1.5235,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.2371,  0.8662,  0.2476,  ...,  0.8441, -0.4524,  1.0854],\n",
      "         [ 0.6709,  0.2362,  0.7929,  ...,  0.4841, -0.6022,  0.5292],\n",
      "         [ 0.4785, -0.0841,  1.2508,  ...,  1.3897, -0.0659,  1.5151],\n",
      "         ...,\n",
      "         [-0.8427, -0.4381, -0.2582,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.4383, -0.0000,  0.0000,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.6096, -1.1531,  1.5235,  ...,  0.0000,  0.1775,  0.0000]],\n",
      "\n",
      "        [[ 0.2330,  0.5411,  0.0636,  ...,  0.5480, -0.2878,  0.0000],\n",
      "         [ 1.3036,  0.5981,  0.4842,  ...,  1.5101,  0.0000,  1.4781],\n",
      "         [ 1.5173, -0.8170,  0.5552,  ...,  0.6638,  0.1957,  1.0247],\n",
      "         ...,\n",
      "         [-0.8427, -0.4381, -0.2582,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.4383, -0.0000,  0.6229,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [ 0.6096, -1.1531,  1.5235,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.3693,  0.5222, -0.4431,  ...,  1.5747, -0.3148,  0.8440],\n",
      "         [ 1.4385,  0.0076,  1.4702,  ...,  0.0000,  0.1059,  1.2775],\n",
      "         [ 0.5961, -0.2941,  1.6184,  ...,  1.6418,  0.2674,  1.6135],\n",
      "         ...,\n",
      "         [-0.8427, -0.0000, -0.2582,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [-0.4383, -1.2356,  0.6229,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.6096, -1.1531,  0.0000,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.5010,  1.7207, -0.4073,  ...,  1.2820,  0.3096,  0.6887],\n",
      "         [ 0.7524,  0.0267,  0.5240,  ...,  1.2195,  0.1691,  1.1458],\n",
      "         [ 0.4484,  0.2625,  1.1551,  ...,  0.0000,  0.4839,  1.2038],\n",
      "         ...,\n",
      "         [-0.8427, -0.4381, -0.0000,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.4383, -1.2356,  0.6229,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.6096, -1.1531,  1.5235,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.5769,  1.2770,  0.1930,  ...,  0.9000, -0.2406,  0.5414],\n",
      "         [ 0.3408,  0.4753,  0.4616,  ...,  1.1237,  0.5168,  1.6573],\n",
      "         [ 0.5767,  0.0605,  1.5316,  ...,  0.0000, -0.6311,  0.6149],\n",
      "         ...,\n",
      "         [-0.8427, -0.4381, -0.2582,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.0000, -1.2356,  0.6229,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.6096, -1.1531,  1.5235,  ...,  1.0595,  0.1775,  0.5406]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "loop within encoder. Iteration -- 0\n",
      "this is x in EncoderLayer-----> tensor([[[-0.6241,  0.0000, -0.0179,  ...,  0.7065, -0.1573,  0.5090],\n",
      "         [ 0.9894,  0.1932,  0.6550,  ...,  1.3589,  0.0968,  0.6021],\n",
      "         [ 1.0334, -0.8907,  0.5876,  ...,  1.4834,  0.4228,  0.0000],\n",
      "         ...,\n",
      "         [-0.0000, -0.4381, -0.2582,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.4383, -1.2356,  0.6229,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.6096, -1.1531,  1.5235,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.2371,  0.8662,  0.2476,  ...,  0.8441, -0.4524,  1.0854],\n",
      "         [ 0.6709,  0.2362,  0.7929,  ...,  0.4841, -0.6022,  0.5292],\n",
      "         [ 0.4785, -0.0841,  1.2508,  ...,  1.3897, -0.0659,  1.5151],\n",
      "         ...,\n",
      "         [-0.8427, -0.4381, -0.2582,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.4383, -0.0000,  0.0000,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.6096, -1.1531,  1.5235,  ...,  0.0000,  0.1775,  0.0000]],\n",
      "\n",
      "        [[ 0.2330,  0.5411,  0.0636,  ...,  0.5480, -0.2878,  0.0000],\n",
      "         [ 1.3036,  0.5981,  0.4842,  ...,  1.5101,  0.0000,  1.4781],\n",
      "         [ 1.5173, -0.8170,  0.5552,  ...,  0.6638,  0.1957,  1.0247],\n",
      "         ...,\n",
      "         [-0.8427, -0.4381, -0.2582,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.4383, -0.0000,  0.6229,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [ 0.6096, -1.1531,  1.5235,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.3693,  0.5222, -0.4431,  ...,  1.5747, -0.3148,  0.8440],\n",
      "         [ 1.4385,  0.0076,  1.4702,  ...,  0.0000,  0.1059,  1.2775],\n",
      "         [ 0.5961, -0.2941,  1.6184,  ...,  1.6418,  0.2674,  1.6135],\n",
      "         ...,\n",
      "         [-0.8427, -0.0000, -0.2582,  ...,  1.0595,  0.0000,  0.5406],\n",
      "         [-0.4383, -1.2356,  0.6229,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.6096, -1.1531,  0.0000,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[-0.5010,  1.7207, -0.4073,  ...,  1.2820,  0.3096,  0.6887],\n",
      "         [ 0.7524,  0.0267,  0.5240,  ...,  1.2195,  0.1691,  1.1458],\n",
      "         [ 0.4484,  0.2625,  1.1551,  ...,  0.0000,  0.4839,  1.2038],\n",
      "         ...,\n",
      "         [-0.8427, -0.4381, -0.0000,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.4383, -1.2356,  0.6229,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.6096, -1.1531,  1.5235,  ...,  1.0595,  0.1775,  0.5406]],\n",
      "\n",
      "        [[ 0.5769,  1.2770,  0.1930,  ...,  0.9000, -0.2406,  0.5414],\n",
      "         [ 0.3408,  0.4753,  0.4616,  ...,  1.1237,  0.5168,  1.6573],\n",
      "         [ 0.5767,  0.0605,  1.5316,  ...,  0.0000, -0.6311,  0.6149],\n",
      "         ...,\n",
      "         [-0.8427, -0.4381, -0.2582,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [-0.0000, -1.2356,  0.6229,  ...,  1.0595,  0.1775,  0.5406],\n",
      "         [ 0.6096, -1.1531,  1.5235,  ...,  1.0595,  0.1775,  0.5406]]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 83, 64]) , torch.Size([512, 8, 83, 64]), torch.Size([512, 8, 83, 64])\n",
      "Score shape -- torch.Size([512, 8, 83, 83])\n",
      "Mask ---> torch.Size([512, 1, 83])\n",
      "Mask new --> torch.Size([512, 1, 1, 83])\n",
      "loop within encoder. Iteration -- 1\n",
      "this is x in EncoderLayer-----> tensor([[[-3.2083,  2.7163, -0.4514,  ..., -1.0945,  2.0085, -0.7440],\n",
      "         [-1.2089,  3.4290, -0.2336,  ...,  0.2839,  3.2408, -0.1589],\n",
      "         [-1.2459, -0.0802, -0.2212,  ..., -0.1571,  3.2763, -1.8929],\n",
      "         ...,\n",
      "         [-2.6418,  3.2105, -1.0993,  ..., -1.9193,  1.5238, -0.5554],\n",
      "         [-2.4292,  2.1361,  1.5128,  ..., -0.0404,  2.7486, -1.6413],\n",
      "         [-0.9099,  1.7086,  0.5694,  ..., -2.0088,  2.3590, -1.0589]],\n",
      "\n",
      "        [[-1.7956,  4.3440, -0.3535,  ..., -0.6036,  2.4987,  0.8666],\n",
      "         [-1.6941,  3.1758,  0.5202,  ..., -1.4637,  2.5755, -0.5400],\n",
      "         [-1.1819,  2.0917,  0.9725,  ..., -1.1468,  3.0812,  0.3517],\n",
      "         ...,\n",
      "         [-1.9340,  3.0544, -0.8645,  ..., -1.5586,  2.5835, -1.3558],\n",
      "         [-1.5230,  3.1271, -0.8385,  ..., -1.3804,  2.9460, -0.4824],\n",
      "         [-0.8734,  2.5303,  0.5105,  ..., -2.1170,  2.6883, -1.3228]],\n",
      "\n",
      "        [[-2.0600,  3.9350, -0.6268,  ..., -2.0691,  1.9280, -1.2624],\n",
      "         [-0.9188,  3.9038, -0.5340,  ...,  1.1744,  1.7247, -0.1836],\n",
      "         [-0.9217,  1.8364, -1.1732,  ..., -1.7863,  3.6257, -1.0129],\n",
      "         ...,\n",
      "         [-2.5896,  2.5058, -1.8722,  ..., -2.3122,  2.9840, -1.0877],\n",
      "         [-2.3439,  1.9645, -0.2657,  ..., -2.3870,  2.1074, -0.7588],\n",
      "         [-1.2908,  2.4157,  0.4079,  ..., -2.5289,  2.7657, -1.7394]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.3768,  4.1028, -1.4350,  ..., -0.7887,  3.4373, -1.2884],\n",
      "         [-0.9120,  2.6758,  1.8954,  ..., -2.8979,  3.3634, -0.3457],\n",
      "         [-1.8560,  1.2381, -0.0207,  ..., -1.3608,  3.9399, -0.9046],\n",
      "         ...,\n",
      "         [-2.3355,  1.5415, -0.9308,  ..., -2.0108,  3.4973, -1.1702],\n",
      "         [-1.7526,  1.5742, -0.4969,  ..., -2.4170,  3.0664, -0.7904],\n",
      "         [-1.1788,  2.0002, -1.0749,  ...,  0.2454,  2.0049, -1.4624]],\n",
      "\n",
      "        [[-2.6833,  4.6293, -1.0441,  ..., -0.9214,  2.6170, -0.9250],\n",
      "         [-1.4797,  2.7839, -0.6048,  ..., -0.9855,  2.9279, -0.0436],\n",
      "         [-1.7892,  3.5532,  1.1571,  ..., -2.9646,  1.3784,  0.6058],\n",
      "         ...,\n",
      "         [-3.3369, -0.4381, -1.0830,  ..., -1.2499,  1.7092, -1.3741],\n",
      "         [-1.9628,  2.2028,  1.1740,  ..., -1.8150,  2.3935, -1.5357],\n",
      "         [-1.3920, -0.0418,  2.2097,  ..., -2.0074,  1.5876, -1.2985]],\n",
      "\n",
      "        [[-1.0872,  3.4318, -1.3668,  ..., -1.6790,  2.0573, -0.2660],\n",
      "         [-1.3891,  3.0887, -0.6262,  ..., -1.6279,  3.6696,  0.1484],\n",
      "         [-1.2425,  2.9680,  0.7300,  ..., -2.4100,  2.6094, -0.6056],\n",
      "         ...,\n",
      "         [-2.2325,  1.9984, -0.2582,  ..., -0.5915,  3.4494, -0.5203],\n",
      "         [-1.5412,  1.7104, -1.2678,  ..., -1.8977,  2.1182, -0.5702],\n",
      "         [-1.2190,  1.6426,  0.6023,  ..., -3.1850,  2.5696, -1.7672]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 83, 64]) , torch.Size([512, 8, 83, 64]), torch.Size([512, 8, 83, 64])\n",
      "Score shape -- torch.Size([512, 8, 83, 83])\n",
      "Mask ---> torch.Size([512, 1, 83])\n",
      "Mask new --> torch.Size([512, 1, 1, 83])\n",
      "loop within encoder. Iteration -- 2\n",
      "this is x in EncoderLayer-----> tensor([[[-3.5476e+00,  4.7707e+00, -1.1624e+00,  ..., -4.7061e+00,\n",
      "           1.3777e+00, -1.7210e+00],\n",
      "         [-1.1261e+00,  5.5252e+00, -6.9465e-01,  ..., -2.6010e+00,\n",
      "           2.0105e+00, -1.3985e+00],\n",
      "         [-8.8956e-01,  1.7613e+00, -1.4399e+00,  ..., -2.7348e+00,\n",
      "           2.4349e+00, -3.6434e+00],\n",
      "         ...,\n",
      "         [-2.6418e+00,  5.6959e+00, -2.0450e+00,  ..., -4.0724e+00,\n",
      "           6.3440e-01, -2.8566e+00],\n",
      "         [-2.3079e+00,  4.6695e+00,  1.9818e-02,  ..., -2.7835e+00,\n",
      "           1.9373e+00, -3.1317e+00],\n",
      "         [-6.0835e-01,  4.2752e+00,  2.9327e-01,  ..., -4.5957e+00,\n",
      "           1.2000e+00, -2.4753e+00]],\n",
      "\n",
      "        [[-8.9337e-01,  6.1728e+00, -6.3480e-01,  ..., -3.0413e+00,\n",
      "           1.2140e+00, -1.7693e+00],\n",
      "         [-3.5329e-01,  5.1465e+00,  2.5933e-01,  ..., -4.1017e+00,\n",
      "           8.4042e-01, -3.2863e+00],\n",
      "         [-9.0967e-02,  4.5593e+00,  7.6402e-01,  ..., -3.4541e+00,\n",
      "           2.2152e+00, -2.2382e+00],\n",
      "         ...,\n",
      "         [-1.2493e+00,  4.8087e+00, -1.7076e+00,  ..., -3.6354e+00,\n",
      "           8.6663e-01, -3.7359e+00],\n",
      "         [-6.3348e-01,  5.0239e+00, -1.5167e+00,  ..., -4.0408e+00,\n",
      "           1.6936e+00, -2.5679e+00],\n",
      "         [-8.4953e-01,  4.8437e+00, -1.3259e-01,  ..., -4.8653e+00,\n",
      "           1.1907e+00, -3.4679e+00]],\n",
      "\n",
      "        [[-1.2394e+00,  5.3728e+00, -1.4611e+00,  ..., -4.1572e+00,\n",
      "           5.2694e-01, -2.5723e+00],\n",
      "         [-5.4953e-01,  5.5303e+00, -1.2292e+00,  ...,  9.1442e-01,\n",
      "           6.6380e-01, -2.1195e+00],\n",
      "         [-9.9538e-01,  2.2373e+00, -2.2526e+00,  ..., -2.2488e+00,\n",
      "           2.8142e+00, -2.1492e+00],\n",
      "         ...,\n",
      "         [-2.5433e+00,  4.8548e+00, -2.9346e+00,  ..., -4.4804e+00,\n",
      "           2.0273e+00, -2.8979e+00],\n",
      "         [-2.4464e+00,  4.9517e+00, -9.9814e-01,  ..., -4.4020e+00,\n",
      "           6.0730e-01, -1.7900e+00],\n",
      "         [-7.8612e-01,  4.1236e+00,  4.0789e-01,  ..., -4.3994e+00,\n",
      "           1.6610e+00, -2.7318e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.0703e+00,  6.8499e+00, -2.4517e+00,  ..., -3.3906e+00,\n",
      "           3.5351e+00, -4.2652e+00],\n",
      "         [-1.0014e+00,  4.8589e+00,  1.0081e+00,  ..., -5.8060e+00,\n",
      "           1.6291e+00, -1.6123e+00],\n",
      "         [-1.9270e+00,  3.1388e+00, -1.0860e+00,  ..., -5.0630e+00,\n",
      "           2.5820e+00, -3.0020e+00],\n",
      "         ...,\n",
      "         [-2.1365e+00,  3.8179e+00, -2.1845e+00,  ..., -4.5682e+00,\n",
      "           1.9489e+00, -3.4559e+00],\n",
      "         [-1.1303e+00,  3.8704e+00, -1.4179e+00,  ..., -4.4753e+00,\n",
      "           2.7828e+00, -1.8644e+00],\n",
      "         [-2.3838e-01,  3.8613e+00, -1.8681e+00,  ..., -2.6441e+00,\n",
      "           2.5081e+00, -4.0356e+00]],\n",
      "\n",
      "        [[-2.1771e+00,  4.6293e+00, -1.6978e+00,  ..., -3.6229e+00,\n",
      "           1.1114e+00, -2.1295e+00],\n",
      "         [-1.7897e+00,  5.1692e+00, -1.4117e+00,  ..., -3.0506e+00,\n",
      "           1.5032e+00, -1.8937e+00],\n",
      "         [-1.8281e+00,  6.1022e+00,  8.7930e-01,  ..., -4.8392e+00,\n",
      "           3.7726e-01, -8.7500e-01],\n",
      "         ...,\n",
      "         [-3.5791e+00,  1.7861e+00, -2.3615e+00,  ..., -3.7537e+00,\n",
      "           6.1113e-01, -2.9619e+00],\n",
      "         [-2.2501e+00,  4.0849e+00, -3.8371e-02,  ..., -4.4204e+00,\n",
      "           1.2794e+00, -3.0313e+00],\n",
      "         [-1.3920e+00,  2.0948e+00,  1.4242e+00,  ..., -4.5690e+00,\n",
      "           3.7630e-01, -2.3400e+00]],\n",
      "\n",
      "        [[ 4.8507e-01,  5.1494e+00, -2.2610e+00,  ..., -4.8735e+00,\n",
      "           1.9702e+00, -1.7767e+00],\n",
      "         [-1.1343e+00,  5.5345e+00, -1.1875e+00,  ..., -5.1910e+00,\n",
      "           2.9479e+00, -2.4534e+00],\n",
      "         [-1.6225e-01,  5.7665e+00,  5.0458e-01,  ..., -5.5789e+00,\n",
      "           1.5897e+00, -1.3119e+00],\n",
      "         ...,\n",
      "         [-7.1795e-01,  3.5429e+00, -6.4722e-01,  ..., -3.9618e+00,\n",
      "           2.7377e+00, -2.6268e+00],\n",
      "         [-6.1267e-01,  3.4479e+00, -2.7059e+00,  ..., -5.0683e+00,\n",
      "           1.3589e+00, -2.6871e+00],\n",
      "         [-1.7618e-03,  1.6701e+00, -7.5528e-01,  ..., -6.8686e+00,\n",
      "           1.9179e+00, -4.4619e+00]]], grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 83, 64]) , torch.Size([512, 8, 83, 64]), torch.Size([512, 8, 83, 64])\n",
      "Score shape -- torch.Size([512, 8, 83, 83])\n",
      "Mask ---> torch.Size([512, 1, 83])\n",
      "Mask new --> torch.Size([512, 1, 1, 83])\n",
      "loop within encoder. Iteration -- 3\n",
      "this is x in EncoderLayer-----> tensor([[[-2.6958,  5.7409, -1.3836,  ..., -7.0688, -0.1041, -3.5808],\n",
      "         [-0.8842,  6.9200, -1.2476,  ..., -3.2562, -0.0978, -3.0429],\n",
      "         [-0.3282,  2.9253, -1.8866,  ..., -5.8119,  0.6494, -4.8001],\n",
      "         ...,\n",
      "         [-1.6950,  7.4641, -2.2318,  ..., -7.1195, -1.4021, -4.1971],\n",
      "         [-1.6682,  6.1060, -0.6271,  ..., -5.9019,  0.0407, -3.8914],\n",
      "         [ 0.0460,  5.9837,  0.2154,  ..., -8.1152, -0.8746, -3.7702]],\n",
      "\n",
      "        [[-0.0113,  7.3461, -0.3965,  ..., -4.9703, -0.9980, -2.5701],\n",
      "         [-0.1462,  6.1329,  0.3651,  ..., -6.3894,  0.4291, -4.0309],\n",
      "         [ 0.2660,  6.1633,  1.0792,  ..., -6.6409, -0.0312, -2.9102],\n",
      "         ...,\n",
      "         [-0.9598,  6.5612, -1.7959,  ..., -6.5733, -1.4796, -4.3886],\n",
      "         [-0.0796,  5.9541, -1.1934,  ..., -7.2891, -0.5435, -3.0010],\n",
      "         [-0.4282,  5.5861, -0.0601,  ..., -7.9355, -1.4838, -3.7226]],\n",
      "\n",
      "        [[-0.9789,  6.5549, -0.9559,  ..., -4.8906,  0.7225, -3.9293],\n",
      "         [-0.8560,  7.2302, -0.9018,  ..., -2.4824, -1.5390, -2.8547],\n",
      "         [-0.5478,  3.9706, -2.2968,  ..., -5.0939,  0.3340, -3.7491],\n",
      "         ...,\n",
      "         [-2.4305,  5.6143, -3.2159,  ..., -5.3691, -0.6495, -3.3642],\n",
      "         [-1.7681,  6.7225, -0.8081,  ..., -8.0657, -1.6541, -3.1088],\n",
      "         [-0.4437,  5.8837,  0.6991,  ..., -7.6157, -0.5081, -2.9202]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.0889,  6.6531, -2.0415,  ..., -4.3168,  1.4589, -5.0574],\n",
      "         [-0.5762,  5.8488,  1.3555,  ..., -8.9255, -0.7596, -2.3510],\n",
      "         [-1.6595,  4.4996, -1.1751,  ..., -8.0572,  0.4492, -3.2075],\n",
      "         ...,\n",
      "         [-1.4972,  5.2808, -2.1670,  ..., -8.0156, -0.0321, -4.1355],\n",
      "         [-0.8308,  5.5075, -1.6588,  ..., -7.2083,  0.6835, -2.4640],\n",
      "         [ 0.3633,  5.5176, -1.2576,  ..., -3.9176, -0.1598, -4.7944]],\n",
      "\n",
      "        [[-2.2442,  6.0572, -1.9330,  ..., -7.2838, -1.7663, -2.7065],\n",
      "         [-1.0446,  7.0544, -1.5055,  ..., -3.6861, -0.7900, -3.4963],\n",
      "         [-1.4216,  7.7204,  0.7616,  ..., -8.3193, -1.3326, -2.5964],\n",
      "         ...,\n",
      "         [-3.0057,  3.5443, -2.3744,  ..., -6.7086,  0.4940, -4.7313],\n",
      "         [-1.0786,  5.7172,  0.3807,  ..., -7.4484,  1.0891, -4.2876],\n",
      "         [-0.8597,  3.5047,  1.8718,  ..., -7.6921, -1.8857, -4.0224]],\n",
      "\n",
      "        [[ 0.7397,  6.8570, -2.4360,  ..., -7.6091,  0.0749, -2.4330],\n",
      "         [-0.8814,  6.6170, -1.3312,  ..., -7.8598,  0.6637, -4.0344],\n",
      "         [ 0.6634,  7.9912,  0.1912,  ..., -6.5739,  1.8852, -2.6619],\n",
      "         ...,\n",
      "         [-0.4426,  5.6802, -0.8560,  ..., -6.4343,  0.5520, -3.1665],\n",
      "         [-0.3577,  5.2237, -2.1941,  ..., -8.2828, -1.2363, -3.2712],\n",
      "         [ 0.7014,  3.0514, -0.7553,  ..., -9.6835, -0.4673, -5.2695]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 83, 64]) , torch.Size([512, 8, 83, 64]), torch.Size([512, 8, 83, 64])\n",
      "Score shape -- torch.Size([512, 8, 83, 83])\n",
      "Mask ---> torch.Size([512, 1, 83])\n",
      "Mask new --> torch.Size([512, 1, 1, 83])\n",
      "loop within encoder. Iteration -- 4\n",
      "this is x in EncoderLayer-----> tensor([[[-4.1193,  6.6429, -3.8450,  ..., -7.2528, -1.2976, -6.2127],\n",
      "         [-2.1995,  9.5656, -3.7744,  ..., -3.4927, -1.5488, -5.9292],\n",
      "         [ 0.1318,  5.3354, -2.0962,  ..., -6.0749,  1.8140, -7.6801],\n",
      "         ...,\n",
      "         [-2.5728, 10.1480, -2.2318,  ..., -6.7148, -3.0298, -6.0873],\n",
      "         [-1.9343,  8.2127, -1.1278,  ..., -5.7940, -0.7903, -6.3595],\n",
      "         [-1.2767,  7.9044, -2.0837,  ..., -8.1152, -2.0378, -6.9550]],\n",
      "\n",
      "        [[ 0.4073,  9.8701, -2.8329,  ..., -5.2840, -2.0701, -5.7113],\n",
      "         [-0.8818,  7.9978, -1.6759,  ..., -7.1254, -0.9227, -7.2638],\n",
      "         [ 0.5060,  8.1224, -1.2687,  ..., -6.8281, -0.8565, -5.6385],\n",
      "         ...,\n",
      "         [-0.0898,  9.0096, -4.4428,  ..., -7.3649, -0.9929, -7.4834],\n",
      "         [-0.9214,  8.4222, -3.3803,  ..., -8.1118, -1.3233, -6.0251],\n",
      "         [-0.6361,  8.1053, -2.9789,  ..., -8.2595, -2.6995, -6.8344]],\n",
      "\n",
      "        [[-2.3603,  8.2779, -3.2141,  ..., -4.8906, -0.4037, -7.7461],\n",
      "         [-2.2994,  7.9548, -3.2354,  ..., -2.5883, -1.0656, -6.2782],\n",
      "         [-1.3214,  5.5355, -4.3126,  ..., -5.6130, -0.7284, -6.8893],\n",
      "         ...,\n",
      "         [-3.9832,  7.9769, -5.7391,  ..., -5.0588, -2.1750, -6.5466],\n",
      "         [-2.3846,  9.3750, -3.1958,  ..., -8.1131, -3.3657, -6.2511],\n",
      "         [ 0.3843,  8.0507, -1.7499,  ..., -8.2620, -1.7454, -6.1648]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.1318,  8.5702, -2.4538,  ..., -4.7335,  0.7998, -7.6980],\n",
      "         [-1.5811,  7.9730,  0.8835,  ..., -9.1163, -2.5461, -3.5727],\n",
      "         [-2.3920,  5.0547, -3.4556,  ..., -8.1339,  0.0843, -4.2120],\n",
      "         ...,\n",
      "         [-2.7426,  7.3549, -4.0311,  ..., -8.4406, -1.6922, -6.9845],\n",
      "         [-1.4058,  8.1553, -4.1548,  ..., -7.7251, -1.0721, -5.5007],\n",
      "         [ 0.4842,  7.9406, -2.9961,  ..., -3.8738, -1.5986, -8.3726]],\n",
      "\n",
      "        [[-2.8019,  8.2095, -4.1698,  ..., -7.6827, -2.9314, -3.9944],\n",
      "         [-2.4224,  7.0544, -3.3816,  ..., -3.3240, -1.9645, -6.3467],\n",
      "         [-2.4505,  9.7754, -1.6023,  ..., -9.1097, -2.6497, -5.4736],\n",
      "         ...,\n",
      "         [-4.2830,  6.1547, -4.5494,  ..., -6.2212, -1.3385, -7.6302],\n",
      "         [-1.7855,  7.9329, -1.4816,  ..., -7.4256, -0.2907, -7.4974],\n",
      "         [-0.3984,  6.1007, -0.4623,  ..., -7.3590, -1.3302, -7.3839]],\n",
      "\n",
      "        [[ 0.3181,  9.3682, -4.9480,  ..., -7.7571, -0.8309, -5.2788],\n",
      "         [-1.8373,  8.2208, -3.0921,  ..., -7.7652, -0.4960, -5.8135],\n",
      "         [-0.2718,  9.3800, -1.3885,  ..., -6.9928,  1.1114, -5.3784],\n",
      "         ...,\n",
      "         [-1.5786,  8.0361, -3.7688,  ..., -6.5899, -0.4249, -5.5168],\n",
      "         [-0.4235,  6.7134, -4.3659,  ..., -8.6162, -0.5268, -5.6739],\n",
      "         [-0.0314,  5.1303, -2.8980,  ..., -9.0749, -1.3700, -8.2859]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 83, 64]) , torch.Size([512, 8, 83, 64]), torch.Size([512, 8, 83, 64])\n",
      "Score shape -- torch.Size([512, 8, 83, 83])\n",
      "Mask ---> torch.Size([512, 1, 83])\n",
      "Mask new --> torch.Size([512, 1, 1, 83])\n",
      "loop within encoder. Iteration -- 5\n",
      "this is x in EncoderLayer-----> tensor([[[ -3.3950,   6.4571,  -2.1944,  ...,  -9.2822,  -2.0923,  -4.3244],\n",
      "         [ -1.8284,   9.4269,  -2.3417,  ...,  -3.4927,  -1.6473,  -3.7173],\n",
      "         [  0.8850,   5.3852,  -0.5604,  ...,  -7.8353,   1.5960,  -5.8186],\n",
      "         ...,\n",
      "         [ -1.6732,   9.8169,  -0.5735,  ...,  -8.5341,  -3.4061,  -5.3623],\n",
      "         [ -1.7486,   7.7279,   0.9151,  ...,  -7.2579,  -1.4604,  -4.2418],\n",
      "         [ -1.3499,   7.5387,  -0.3185,  ...,  -9.6893,  -1.6468,  -4.8849]],\n",
      "\n",
      "        [[  1.1480,   9.3232,  -3.8347,  ...,  -7.0633,  -2.5832,  -4.5473],\n",
      "         [  0.3380,   7.1552,  -0.1220,  ...,  -8.8648,  -1.3248,  -5.3427],\n",
      "         [  1.7869,   7.7094,  -0.3129,  ...,  -8.6985,  -1.1387,  -3.8135],\n",
      "         ...,\n",
      "         [  1.2675,   8.5677,  -3.1623,  ...,  -9.2989,  -1.0843,  -5.1503],\n",
      "         [  0.0300,   7.5662,  -1.8987,  ...,  -8.8230,  -2.4001,  -3.7037],\n",
      "         [  0.6299,   7.0896,  -1.5835,  ..., -10.2703,  -3.0828,  -4.5869]],\n",
      "\n",
      "        [[ -1.6522,   8.1976,  -3.5842,  ...,  -6.8136,  -1.2755,  -5.5157],\n",
      "         [ -1.9837,   8.4824,  -1.5737,  ...,  -4.2940,  -1.3481,  -4.0027],\n",
      "         [ -1.3214,   5.5220,  -2.9605,  ...,  -7.0095,  -1.4133,  -4.7690],\n",
      "         ...,\n",
      "         [ -3.4413,   7.9562,  -6.2517,  ...,  -6.7042,  -3.0661,  -4.5841],\n",
      "         [ -1.7663,   9.1831,  -1.5036,  ...,  -8.9434,  -2.5410,  -5.5089],\n",
      "         [  0.9658,   7.4475,  -0.7139,  ...,  -9.5664,  -2.2196,  -4.1089]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -1.4655,   7.4394,  -1.0150,  ...,  -6.7222,   0.3663,  -5.6408],\n",
      "         [ -1.1439,   7.1204,   3.1026,  ..., -10.9903,  -2.6735,  -0.7738],\n",
      "         [ -1.3777,   4.5923,  -1.9293,  ...,  -8.1339,  -0.4751,  -1.7536],\n",
      "         ...,\n",
      "         [ -1.6182,   8.2655,  -1.9957,  ..., -10.4029,  -2.4400,  -4.9421],\n",
      "         [ -0.8454,   7.9866,  -2.4213,  ...,  -9.6170,  -1.4477,  -5.5007],\n",
      "         [  1.4151,   7.3664,  -1.0826,  ...,  -5.8953,  -1.6457,  -6.4443]],\n",
      "\n",
      "        [[ -2.0391,   8.3133,  -2.2637,  ...,  -9.5083,  -2.8925,  -3.0948],\n",
      "         [ -2.2528,   6.6281,  -1.9706,  ...,  -4.9473,  -2.3656,  -5.4707],\n",
      "         [ -1.9937,  10.0191,   0.0482,  ..., -10.9847,  -3.6511,  -3.6402],\n",
      "         ...,\n",
      "         [ -3.1291,   5.8523,  -2.8100,  ...,  -8.3932,  -2.0106,  -5.7900],\n",
      "         [ -1.0745,   7.5990,   0.2173,  ...,  -9.4361,  -1.4631,  -5.3252],\n",
      "         [  0.2792,   5.8004,   1.3795,  ...,  -8.8291,  -1.6999,  -5.3850]],\n",
      "\n",
      "        [[  0.8133,   9.1893,  -5.7591,  ...,  -9.7079,  -1.0181,  -2.8314],\n",
      "         [ -1.7307,   8.0929,  -1.4047,  ...,  -9.3153,  -0.6983,  -2.9205],\n",
      "         [  0.4890,   8.6603,  -0.3528,  ...,  -8.7172,   1.0411,  -4.3827],\n",
      "         ...,\n",
      "         [ -1.3548,   7.6897,  -2.8299,  ...,  -8.7646,  -0.0738,  -3.2315],\n",
      "         [ -0.1423,   6.4728,  -2.6260,  ..., -10.5962,  -0.7834,  -3.2425],\n",
      "         [  1.1905,   4.8428,  -1.6249,  ...,  -9.1254,  -1.5328,  -5.7037]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 83, 64]) , torch.Size([512, 8, 83, 64]), torch.Size([512, 8, 83, 64])\n",
      "Score shape -- torch.Size([512, 8, 83, 83])\n",
      "Mask ---> torch.Size([512, 1, 83])\n",
      "Mask new --> torch.Size([512, 1, 1, 83])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 87])\n",
      "Mask ---> torch.Size([512, 87, 87])\n",
      "Mask new --> torch.Size([512, 1, 87, 87])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 83, 64]), torch.Size([512, 8, 83, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 83])\n",
      "Mask ---> torch.Size([512, 1, 83])\n",
      "Mask new --> torch.Size([512, 1, 1, 83])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 87])\n",
      "Mask ---> torch.Size([512, 87, 87])\n",
      "Mask new --> torch.Size([512, 1, 87, 87])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 83, 64]), torch.Size([512, 8, 83, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 83])\n",
      "Mask ---> torch.Size([512, 1, 83])\n",
      "Mask new --> torch.Size([512, 1, 1, 83])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 87])\n",
      "Mask ---> torch.Size([512, 87, 87])\n",
      "Mask new --> torch.Size([512, 1, 87, 87])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 83, 64]), torch.Size([512, 8, 83, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 83])\n",
      "Mask ---> torch.Size([512, 1, 83])\n",
      "Mask new --> torch.Size([512, 1, 1, 83])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 87])\n",
      "Mask ---> torch.Size([512, 87, 87])\n",
      "Mask new --> torch.Size([512, 1, 87, 87])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 83, 64]), torch.Size([512, 8, 83, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 83])\n",
      "Mask ---> torch.Size([512, 1, 83])\n",
      "Mask new --> torch.Size([512, 1, 1, 83])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 87])\n",
      "Mask ---> torch.Size([512, 87, 87])\n",
      "Mask new --> torch.Size([512, 1, 87, 87])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 83, 64]), torch.Size([512, 8, 83, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 83])\n",
      "Mask ---> torch.Size([512, 1, 83])\n",
      "Mask new --> torch.Size([512, 1, 1, 83])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 87, 64]), torch.Size([512, 8, 87, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 87])\n",
      "Mask ---> torch.Size([512, 87, 87])\n",
      "Mask new --> torch.Size([512, 1, 87, 87])\n",
      "d_k value 64\n",
      "torch.Size([512, 8, 87, 64]) , torch.Size([512, 8, 83, 64]), torch.Size([512, 8, 83, 64])\n",
      "Score shape -- torch.Size([512, 8, 87, 83])\n",
      "Mask ---> torch.Size([512, 1, 83])\n",
      "Mask new --> torch.Size([512, 1, 1, 83])\n",
      "predictions size : tensor([[-0.9196, -1.0088, -0.5155,  ..., -0.6532, -0.7871, -0.2975],\n",
      "        [-0.9782, -0.8772, -0.5623,  ..., -0.5225, -0.8594, -0.4762],\n",
      "        [-1.0119, -0.9256, -0.5424,  ..., -0.6764, -0.8432, -0.3516],\n",
      "        ...,\n",
      "        [-1.0203, -0.9361, -0.5488,  ..., -0.4481, -0.8050, -0.5032],\n",
      "        [-1.0689, -0.8872, -0.5305,  ..., -0.5185, -0.7758, -0.4931],\n",
      "        [-1.0157, -1.0270, -0.5254,  ..., -0.5326, -0.7395, -0.5310]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "targets size : torch.Size([44544])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-3f2a643e28f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-a58b676df0da>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(epochs, print_every)\u001b[0m\n\u001b[1;32m     44\u001b[0m             loss = F.cross_entropy(preds.view(-1, preds.size(-1)), targets, \n\u001b[1;32m     45\u001b[0m                                    ignore_index=target_pad)\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Loss.data ----> = {loss.item()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = torch.randn(1,16).reshape(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_2 = matrix.unsqueeze(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_2.size()  # 4 batches, 1 row, 4 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_3 = matrix.unsqueeze(-1); matrix_3.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_3  # 4 batches, 4 rows, 1 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.unsqueeze(-3).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-venv",
   "language": "python",
   "name": "tensorflow-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "426.656px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
